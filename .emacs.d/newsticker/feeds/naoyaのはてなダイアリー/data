;; -*- coding: utf-8 -*-
(("naoyaのはてなダイアリー" "naoyaのはてなダイアリー" "http://d.hatena.ne.jp/naoya/" (20813 17237 335433 418000) feed 0 nil nil ((title nil "naoyaのはてなダイアリー") (link nil "http://d.hatena.ne.jp/naoya/") (description nil "naoyaのはてなダイアリー") (dc:creator nil "naoya") (dc:date nil "2013-03-23T07:36:16+09:00") (items nil (rdf:Seq nil (rdf:li ((rdf:resource . "http://d.hatena.ne.jp/naoya/20130322/1363946401"))) (rdf:li ((rdf:resource . "http://d.hatena.ne.jp/naoya/20130322/1363921458"))) (rdf:li ((rdf:resource . "http://d.hatena.ne.jp/naoya/20130321/1363838408"))) (rdf:li ((rdf:resource . "http://d.hatena.ne.jp/naoya/20130318/1363578062"))) (rdf:li ((rdf:resource . "http://d.hatena.ne.jp/naoya/20130315/1363340698"))) (rdf:li ((rdf:resource . "http://d.hatena.ne.jp/naoya/20130313/1363129532"))))))) ("Treasure Data" "少し前にログの話を書いた http://d.hatena.ne.jp/naoya/20130219/1361262854 ときに、Treasure Data については後日にもう少し詳細に書くと言ったので書くとしよう。 近頃 Treasure Data (以下、時折 TD) という名前をちらほら聞いたことがある人は多いのではないかと思い" "http://d.hatena.ne.jp/naoya/20130322/1363946401" (20812 11169) new 1 nil nil ((title nil " Treasure Data") (link nil "http://d.hatena.ne.jp/naoya/20130322/1363946401") (description nil " 少し前にログの話を書いた http://d.hatena.ne.jp/naoya/20130219/1361262854 ときに、Treasure Data については後日にもう少し詳細に書くと言ったので書くとしよう。 近頃 Treasure Data (以下、時折 TD) という名前をちらほら聞いたことがある人は多いのではないかと思い") (content:encoded nil "
<div class=\"section\"><p>少し前にログの話を書いた <a href=\"http://d.hatena.ne.jp/naoya/20130219/1361262854\" target=\"_blank\">http://d.hatena.ne.jp/naoya/20130219/1361262854</a> ときに、<a href=\"http://www.treasure-data.com/\">Treasure Data</a> については後日にもう少し詳細に書くと言ったので書くとしよう。</p><p><a href=\"http://www.treasure-data.com/\"><img width=\"800\" src=\"http://cdn.bloghackers.net/images/20130322_165640.png\"></a></p><p>近頃 Treasure Data (以下、時折 TD) という名前をちらほら聞いたことがある人は多いのではないかと思います。「ビッグデータのクラウドサービスである」とか「日本人が創業したシリコンバレーのベンチャー」、あるいは Yahoo! 創業者の Jerry Yang が投資したとか、<a href=\"http://fluentd.org/\">Fluentd</a> と何か関係があるといった文脈などなど。</p><p>けど、具体的に Treasure Data がどういうサービスで、どういう機能を持っていて、どんな場面で利用されるものなのかはまだあまり良く知られていないかもしれない・・・ようにも見える。今日はその辺から少し紹介していこうかなと思う。</p><h4> Treasure Data が提供するサービス</h4><p>本当にごくごく単純化して言うとTDは「手元のサーバーとかからログをどんどん送りつけておくとそれを保存しといてくれて、SQL を投げると <a href=\"http://d.hatena.ne.jp/naoya/20080511/1210506301\">MapReduce</a> で大規模並列にそれを実行して結果だけ返してくれるクラウドなサービス」です。</p><p>自分は個人でも TD を利用しているのだけど、例えば amazlet というずいぶん昔に作ったウェブアプリケーションのログ、アクセスログにすこし情報を加えたものなんかを TD に送り続けている。OSX にインストールした td コマンドで、TD のサーバーにステータスを問い合わせる。</p><pre>
% td tables nginx
+----------+--------+------+---------+--------+---------------------------+--------+
| Database | Table  | Type | Count   | Size   | Last import               | Schema |
+----------+--------+------+---------+--------+---------------------------+--------+
| nginx    | access | log  | 2649812 | 0.1 GB | 2013-03-22 17:01:57 +0900 |        |
+----------+--------+------+---------+--------+---------------------------+--------+
</pre><p>ま、そんなに大した規模のデータではないけど。とはいえこれでも月間数万人くらいのユーザーはいる。</p><p>さて、この送り続けたログから直近一ヶ月くらいの間に、amazlet で紹介された Amazon の商品を計算してみよう。</p><pre>
% td query -w -d nginx &#34;select v&#91;&#39;asin&#39;] as asin, count(1) as cnt from access group by v&#91;&#39;asin&#39;] order by cnt desc limit 100&#34;
</pre><p>td コマンドで SQL (っぽい) クエリを送信する。すると</p><pre>
Job 2131709 is queued.
Use &#39;td job:show 2131709&#39; to show the status.
queued...
  started at 2013-03-22T08:07:49Z
  Hive history file=/mnt/hive/tmp/1624/hive_job_log__1111533064.txt
  Total MapReduce jobs = 2
  Launching Job 1 out of 2
  Number of reduce tasks not specified. Defaulting to jobconf value of: 12
  In order to change the average load for a reducer (in bytes):
    set hive.exec.reducers.bytes.per.reducer=&#60;number&#62;
  In order to limit the maximum number of reducers:
    set hive.exec.reducers.max=&#60;number&#62;
  In order to set a constant number of reducers:
    set mapred.reduce.tasks=&#60;number&#62;
  Starting Job = job_201301150013_218289, Tracking URL = …
  2013-03-22 08:08:18,702 Stage-1 map = 0%,  reduce = 0%
  2013-03-22 08:08:26,779 Stage-1 map = 26%,  reduce = 0%
  2013-03-22 08:08:29,814 Stage-1 map = 41%,  reduce = 0%
  2013-03-22 08:08:32,858 Stage-1 map = 58%,  reduce = 0%
  2013-03-22 08:08:35,907 Stage-1 map = 72%,  reduce = 0%
  2013-03-22 08:08:38,935 Stage-1 map = 83%,  reduce = 0%
</pre><p>こんな感じでネットワークの向こう側で MapReduce 計算が始まって処理が行われる。初めて実行したときは手元のOSXからコマンドを送るだけで、インターネットを通じて MapReduce を実行してるなんて・・・! とちょっとした高揚感があったりした。</p><p>で、結果はそのまま標準出力に返ってくる。</p><pre>
| B00BHAF688 | 307 | ⇒ ジョジョ (PlayStation 3)
| B00BHO0FK8 | 274 | ⇒ Evangelion Q の Blu-ray
| B009GSX0A4 | 147 | ⇒ 閃乱カグラ (PSP Vita)
| B00A64CFIK | 136 | ⇒ 初音ミク (PlayStation 3)
| B00APVDHLI | 134 | ⇒ ジョジョ (PlayStation 3)
| B0095D6I86 | 128 | ⇒ メタルギア ライジング (PlayStation 3)
| B00BIYSEFA | 123 | ⇒ 真・女神転生IV (Nintendo 3DS)
| B00AHA5OCC | 113 | ⇒ SOUL SACRIFICE (PlayStaion 3)
| B00BIYSF7C | 112 | ⇒ サモンナイト5
</pre><p>矢印以降は自分が補ったもの。どうやら amazlet はゲームソフトを紹介するのなんかによく使われて、直近一ヶ月くらいは PS3 のジョジョやエヴァンゲリオンの映画の Blu-ray が人気だった・・・なんてことがわかった。ここでは割と単純なクエリを投げているけど、いろんなデータと紐づけてもっと複雑なクエリを実行させたとしても、そこは MapReduce なんで I/O リソースも CPU リソースもリニアにスケールするようになっている。</p><p>この例のケースの場合、送っているデータはせいぜいまだ数百MB程度なので何も Treasure Data を頼らなくても MySQL や MongoDB でも十分処理できる。でもポイントはそこではなく、たとえデータが 数百GB や TB オーダーになってもオペレーションとしては何らかわらない、つまりスケーラブルである、というところなのはいわずもがな。</p><p>途中、ジョブの経過出力に Hadoop や Hive なんて単語がちらほら見える通り、TD は MapReduce の実行基盤としての Hadoop、それから SQL 風の言語 (HiveQL) で Hadoop 上のデータを操作できる Hive、それらを使って構築されている。また後でもうすこし触れるけれども、実際には単なる Hadoop + Hive のホスティングではなくデータを受け付ける部分、データを保存するストレージ、マルチテナントのジョブを分配するスケジューラ、あるいは結果を返す各種 API などは TD 社が独自に開発したものでまかない全体を統合し、この「ログをがんがん送りつけておいて好きなときに SQL で MapReduceできる」というユースケースを提供する。</p><p>これが Treasure Data というサービス・・・ということになります。</p><h4> 実際どんな場面で使われるのか</h4><p>大規模に SQL 的にデータ解析ができたとして、実際にどんな場面で使われるの? というのが次に気になるところでしょう。</p><p>ソーシャルゲームをはじめとする最近のWebサービスではログ解析が重要な役割を占める・・・という話は聞いたことがある人も多いと思います。TD のようなソリューションが使われるのは、まさにそこです。最近は広告なんかも技術革新が進んでかなり大規模なデータを処理するようになってきていて、そこでも使われている。<a href=\"http://repeatedly.github.com/ja/2013/03/the-architecture-of-data-analytics-paas-on-aws-jaws-days-2013-day2/\">中の人のプレゼン</a> にある事例だとクックパッド、MobFox なんかが有名どころです。資料には載ってないけど、割と国内のソーシャルゲームデベロッパー各社ではかなり導入が進んでいると聞いてます。</p><p>そもそも何でそんなことになっているの? という点について少し捕捉しておきたい。</p><p>もともとウェブシステムのデータ解析といったらもっぱらそれはウェブサーバーのアクセスログのことだった。Apache の access_log、あれ。アクセスログに関しては、最近はログから PV や UU を計算するくらいだったら Google Analytics なんかを最初から使ってる、という事例のほうが多いかもしれない。いずれにしても本質的にはHTTPリクエストから得られる情報だけで分析しているということで得られる情報は一緒です。</p><p>このアクセスログ分析では、どのURLにどの程度のアクセスがあったかとか、だいたい日や月にどれくらいの UU があったかといったことはわかる。でも、それ以上はわからない。アクセスしたユーザーの性別や年齢といった個別の属性、トランザクションID、購入しようとした商品・・・みたいなウェブサーバーが感知しようのないデータは含まれていないので、それ以上のことを調べようと思っても調べようがない。</p><p>「詳細なデータが取れないなら取れるようにすればいいじゃない」ということで、アプリケーションのロジックから色々とその辺を紐づけたログを吐くようにしてやればいい・・・みんな当然そうするわけです。</p><p>どういうコードで例を書いたらいいかちょっと微妙だけども</p><pre class=\"syntax-highlight\"><span class=\"synComment\"># 商品購入画面</span>
post <span class=\"synConstant\">'/purchase'</span>  =&#62;<span class=\"synIdentifier\"></span><span class=\"synStatement\">sub</span><span class=\"synIdentifier\"></span>{
    <span class=\"synStatement\">my</span><span class=\"synIdentifier\">$self</span> = <span class=\"synStatement\">shift</span>;
    <span class=\"synStatement\">my</span><span class=\"synIdentifier\">$item</span> = My::Item-&#62;find(…);
    <span class=\"synStatement\">my</span><span class=\"synIdentifier\">$user</span> = My::User-&#62;purchase( <span class=\"synIdentifier\">$item</span> );
    
    <span class=\"synComment\"># インタラクションログを出力する</span><span class=\"synIdentifier\">$self</span>-&#62;logger-&#62;emit(
        <span class=\"synConstant\">user_hash </span>=&#62; <span class=\"synIdentifier\">$user</span>-&#62;hash,
        <span class=\"synConstant\">age </span>=&#62; <span class=\"synIdentifier\">$user</span>-&#62;age,
        <span class=\"synConstant\">sex </span>=&#62; <span class=\"synIdentifier\">$user</span>-&#62;sex,
        <span class=\"synConstant\">session </span>=&#62; <span class=\"synIdentifier\">$user</span>-&#62;session_id,
        <span class=\"synConstant\">item </span>=&#62; <span class=\"synIdentifier\">$item</span>-&#62;id,
        …   
    );
    
    <span class=\"synIdentifier\">$self</span>-&#62;render;
};
</pre><p>こんな感じで、とあるイベントに対してアクセスログだけでは捕捉しようがないデータをログとして書き出してやる。この手のログをあちこちでとっておいて後から解析すれば、例えば「商品購買前の画面で何%がドロップしているけどそれがどんな属性のユーザーだった」とか「一ヶ月に数回以上訪れるユーザーとそうでないユーザーのコンバージョンの程度がこのぐらい違った」なんていう分析が可能になる。このデータを使って意志決定をすれば、やみくもにサイトを改善するよりはずっと確度の高い施策を打つことができるし、A/B テストなんかでの評価にも利用しやすい。</p><p>・・・解析できるようになるのはいいんだけど、そんなにうまい話はない。当然いろいろ悩ましい問題がでてくる。特にサイトの規模が大きくなればなるほど。</p><ul><li> そのログってどうやって収集するの?</li><li> そんなでかいデータどこにストアするの?</li><li> そんなでかいデータどうやって計算するの?</li><li> ログのフォーマット変更にどう対応するの?</li><li> 計算結果はどうやって参照するの?</li></ul><p>ローカルに吐き出したログは、どうにかして解析用のストレージに集めてこないといけない。イベントログという性格上、それはなるべくリアルタイムで収集しておきたい。集めたデータを保存するとして、日に数百GBになるようなデータをいったいどこに保存しつづけるというのか。MySQL? MongoDB? うーん。集めたはいいけど、データがでかすぎて集計のバッチが一日で終わらない・・・!! 計算できるのはいいけど、毎回エンジニアにお願いしないといけない、でもエンジニアが忙しくてやってくれない! ログに新しい属性を追加したい! え、なにあんな巨大な MySQL のテーブルを alter table するわけ? ハードディスクが壊れました! ネットワーク帯域が溢れました・・・!</p><p>「ぎゃー」</p><p>なーんてことが起こって、まあなかなか、そんなに高度な分析がしたいわけじゃなかったとしても、それなりにここのシステム構築と運用維持は骨の折れる話・・・だった。だからみんなアクセスログ程度の分析で妥協していた。ところが、そこのところを頑張ってきちんとやって、データ分析をもとにした意志決定を可能にしたのが Zynga なんかが有名にし今では一般的になりつつあるかの手法です。</p><p>Webサービスのようなスタート小規模B2Cで始まるような世界では、このデータ解析周りというのはここ数年の間に急激に盛り上がった分野だけれども、エンタープライズシステムでは (自分もあんまりよくわかってないけど) ERM やら SCM やらその辺の基幹統合システムから集めた大量のデータを格納し、分析、表示する一連のシステムは DWH (データウェアハウス) と言われて、それはそれはいろんなエンタープライジーなハードやソフトによって実現されてきた・・・らしい。</p><p>先日も、とあるエンタープライズな基幹業務に携わっている友人が「基幹のバッチを一日で終わらせないと行けないんだけど、データが多すぎて終わらなくって大変。そのために結構な性能の商用製品を買ってる。そのうち Hadoop とか分散システムでやれるといいんだけどね」と言ってました。</p><blockquote title=\"「ビッグデータですべてが解決できる」は誤解--Teradata ブロブストCTO - ZDNet Japan\" cite=\"http://japan.zdnet.com/cio/sp_12executive/35029722/\"><p>ビッグデータの活用は、3つの段階に分けられると考えています。第1段階はウェブログデータが対象で、主にドットコム企業がこれらのデータを解析していました。特に、トランザクションデータの部分に焦点を当てていたのです。しかしビッグデータの到来によって、トランザクションよりもう一段階詳細なレベルであるインタラクションデータ、つまり、やり取りされるデータの中身が解析されるようになりました。</p><p>第2段階は、解析の対象がソーシャルメディアに移ってきました。FacebookやTwitter、ブログなどに書かれるテキストを対象としたものです。現在はこの第2段階にあります。</p><cite><a href=\"http://japan.zdnet.com/cio/sp_12executive/35029722/\" target=\"_blank\">「ビッグデータですべてが解決できる」は誤解--Teradata ブロブストCTO - ZDNet Japan</a></cite></blockquote><p>と、この DWH 企業の Teradata の CTO が言うようにただのアクセスデータから一歩進んで「インタラクションデータ」を分析・活用するようになったというのが大きな流れでその背後にはビッグデータ(にまつわるハードウェアの進化やソフトウェア技術の登場)があった、というのが近年です。</p><p>それを、一部の開発力のある企業は自社のエンジニアががんばったり、あるいは資金力のある企業は専業ベンダーと組んでそいういったものを構築してきたのだけど、AWS が仮想化技術をはじめとして大規模インフラをコモディティ化したように、データ解析システムをクラウドによってコモディティ化しようとする試みる人たちがここ最近でてきた。Treasure Data 社はそんな野心溢れるベンチャー企業のひとつ、なんでしょう。</p><h4> Treasure Data のアーキテクチャ (ざっくり)</h4><p>より具体的に Treasure Data は先ほどの大規模ログ解析にまつわる各種問題にどう対応するのか。</p><p>この辺は <a href=\"http://repeatedly.github.com/ja/2013/03/the-architecture-of-data-analytics-paas-on-aws-jaws-days-2013-day2/\">先日の JAWS DAYS 2013 での @repeatedly のプレゼンが詳しい。</a></p><p><a href=\"http://cdn.bloghackers.net/images/20130322_184841.png\" class=\"http-image\" target=\"_blank\"><img src=\"http://cdn.bloghackers.net/images/20130322_184841.png\" class=\"http-image\" alt=\"http://cdn.bloghackers.net/images/20130322_184841.png\" width=\"600\"></a></p><p>ログの収集は、Treasure Data がスポンサーになって開発されている OSS の Fluentd で行う。より正確にはその OSS の Fluentd を、Treasure Data 向けに使う前提にパッケージングした td-agent (<a href=\"https://github.com/treasure-data/td-agent\" target=\"_blank\">https://github.com/treasure-data/td-agent</a>) を使う。API キーを入力してちょちょいと入出力の設定をしてやるだけで TD にデータを送ることができるようになっている。Fluentd そのものは非常にスケーラブルな作りになっているし、実績面も(よく知られているように) LINE のバックエンドなんかにも使われていたりして十分。プラガブルなアーキテクチャによってログそのほかの入力を多種多様なフォーマットに対応し、それを JSON という変化に強い柔軟な形に変換して取り扱う。プログラム内から Fluentd にログを飛ばすためのロガーライブラリも、各種言語に対応した実装が用意されている。</p><p>データストアは TD 社が独自に開発したカラムナーストレージが使われる。独自に開発したといっても実際には S3 上に構築されたソフトウェアのようで、99.999999999% の堅牢性と 99.99% の可用性を謳う S3 の上に、HDFS の弱点を克服するため(+ そのほか幾つかの目的のため)カラムナー形式のインタフェースを実現したものになっている。S3 なので増え続けるデータに対してスケーラブルだし、カラムナー形式なので特定のデータだけを処理したい、なんてときに余計な I/O が発生しない作りになっているので効率的。</p><p>大規模データに対してスケールするための計算基盤は Hive + Hadoop。で、Hadoop を先のカラムナーストレージに対応させている。</p><p>計算結果の受け取り方・・・ここは TD のウリの一つでもあって、Web API や MySQL や S3 などいろんな形式で受け取れるようになっている。それらと自社のグラフ化ツール・・・この分野では BI (Business Intelligence) なんて言ったりするけども、そこに流し込んでやることで TD で計算した各種指標を定点観測したりすることなんかもできる。</p><p>・・・というデータ収集から出力までの一連のシステムを構築することで「デベロッパーの苦痛」を肩代わりして、またそれをオールインワン、クラウドサービスとしてで提供することによって件の問題を解決している。</p><h4> Treasure Data vs ...</h4><p>Bigdata as a Service の流れは何も Treasure Data だけが進めている分野というわけではなく、他にもいろんな競合がいる。特に比較されやすいのは TD のバックエンドにもなっている Amazon が、AWSの一環として提供するデータ解析用の各種サービス。<span class=\"footnote\"><a href=\"/naoya/#f1\" name=\"fn1\" title=\"若干書き方が紛らわしいですがTDがEMRやRedshiftをバックエンドにしているわけではないです。TDはAWSのうちS3、ERB、EC2、RDS程度のみ利用しているとのこと\">*1</a></span> より具体的には</p><ul><li> Amazon Elastic MapReduce (EMR)</li><li> Amazon Redshift</li></ul><p>あたりがそれに相当する。</p><p>EMR はその名の通り AWS における MapReduce のサービスで、Hive を使うオプションもある。S3 にストアしたデータを読み込んで任意の MapReduce 処理を実行させることができる。Redshift にいたってはまさに DWH そのものです。</p><p>それに対して Treasure Data が提供するものはいったい? それも先のプレゼンをみるといい。動画の最後では、まさにそれその通りの質疑応答があったりする。</p><p>それに対する答えは、普通に EMR や Redshift を使うだけなら同じだけれど、実際には Treasure Data は収集から出力までを統合的にまとめて面倒を見ていること、そこに豊富な API を用意することでデベロッパーフレンドリーに仕上げていることが大きな差別化ポイントになっている。誤解を恐れずに言ってみれば、生の AWS に対する Heroku、みたいなものだと見てもいいかもしれない。DWH は運用がとにかく面倒なのを我々が面倒見るぜ! というのがこの手のソリューションのスタンスだし、その顧客がいちばんやって欲しい部分に特にフォーカスすることで差別化しているという意味で Treasure Data の戦略は結構筋がいい・・・と自分も思うし方々でもそう見られているようだ。</p><h4> TD の使用感</h4><p>実際 TD が解決するのは大規模ログ解析なわけだけれども、自分のように小規模に使うというのでも全く問題ない。というか TD はそれも想定している。</p><p>この辺は <a href=\"http://d.hatena.ne.jp/naoya/20130219/1361262854\" target=\"_blank\">http://d.hatena.ne.jp/naoya/20130219/1361262854</a> でも書いた通り今後もずっと増え続けるログをただただ TD に送り続けるだけで良いとう使い勝手の良さ。そのマネジメントをしなくてという精神的安心が得られる。先のも述べた通り、デベロッパーフレンドリーであることをウリにしていることもあって、煩雑な設定もいらないし、凝ったことをしようと思ったらだいたいやりたいことに相当する API が用意されている。その API も Restful でシンプルなアーキテクチャになってて学習コストは低い。</p><p>なお、自分は Fluentd を使って出力を2方向にコピーして、生ログは保存目的で S3 に直接転送して、分析向けのいろんなデータをくっつけたものを TD に送りつけるなどして使っています。</p><h4> どんな風にみえているか</h4><p>Treasure Data のいまや今後がどんな風に見えるかというのは、携わるシステム大小の視点によって変わってくると思う。</p><p>エンタープライズな人や大規模Web屋にとっては既存のDWHあるいは自社で開発したログ解析システムを置き換えるもの、つまり Treasure Data が想定するユーザー像の通りにそれを認識すると思います。実際、クックパッド社なんかは自分たちで Hadoop を運用していたけれどもその運用コストが高くつく、というので Treasure Data に移行したというし、エンタープライズ領域に関しては先に述べた通りバッチに使われる大規模データベースなんかが必要だった部分の置換を想像するところだと思う。「エンタープライズ領域はデータをクラウドに預けられるか問題」といういつもの課題があるのでなかなかスムーズに浸透していかないとは思うが、先進的なユーザーはすでに導入を開始しているということもあって、案外楽観的な未来が待っているかもしれない。</p><p>一方、これは個人的な妄想でもあるのだけど、スタートアップや小規模なデベロッパーからは AWS が個人に対しても仮想化サーバーやロードバランサーそのほかを組み合わせたシステムをコモディティ化したように見えたのと同じで、TD社あるいは同社の競合が、これから先データ解析基盤 (DWH) をコモディティ化していくことを期待したい。クラウドはある意味、個人やスタートアップのような小規模なチームをエンパワーメントするツールでもあり、わずか 4人の会社で 1,000 万ユーザーをさばききった Instagram の成功なんかは AWS がそういうサービスなんだということを世の中に知らしめた。TD も同じように、巨人と戦おうとするそんな小さなチームの新しい武器になればいいし、そうなったら楽しい。</p><p>・・・というわけでなんか色々書いてたら熱くなってしまって書きすぎましたが Treasure Data の紹介でした。</p><p>自分がなんでこんなに Treasure Data 推しかというと、まあ正直に言って CTO の @kzk_mover を知っているから応援したいという個人的な気持ちが結構あるのは隠さない。でも、実際に自分で使ってみたら見事に自分の抱えていた問題を解決してくれたし、技術的も真っ当で、なによりその個人的展望みたいなのを実現してくれる可能性がありそうだから、ついつい期待しちゃったんである。</p><p>この記事が結構読まれてさらに将来 TD 社がもっと大きくなってサクセス (!) した日には、特上寿司でも奢ってもらうことにするということで本稿を締めたいと思います。</p></div><div class=\"footnote\"><p class=\"footnote\"><a href=\"/naoya/#fn1\" name=\"f1\">*1</a>：若干書き方が紛らわしいですがTDがEMRやRedshiftをバックエンドにしているわけではないです。TDはAWSのうちS3、ERB、EC2、RDS程度のみ利用しているとのこと</p></div>
") (dc:creator nil "naoya") (dc:date nil "2013-03-22T19:00:01+09:00"))) ("motion-mode.el : RubyMotion の補完を Emacs で" "みなさん RubyMotion 書いてますか! 僕は上々です! 最近は割とまっとうに活動しているのでドラゴンクエスト10バージョン1.3 の新職業は全然レベルが上がりません。バトルマスターはまだレベル 53 です。仕事とゲームの両立って難しいですね、参っちゃいますね。 それはそう" "http://d.hatena.ne.jp/naoya/20130322/1363921458" (20811 51762) new 2 nil nil ((title nil " motion-mode.el : RubyMotion の補完を Emacs で") (link nil "http://d.hatena.ne.jp/naoya/20130322/1363921458") (description nil " みなさん RubyMotion 書いてますか! 僕は上々です! 最近は割とまっとうに活動しているのでドラゴンクエスト10バージョン1.3 の新職業は全然レベルが上がりません。バトルマスターはまだレベル 53 です。仕事とゲームの両立って難しいですね、参っちゃいますね。 それはそう") (content:encoded nil "
<div class=\"section\"><p>みなさん RubyMotion 書いてますか! 僕は上々です! </p><p>最近は割とまっとうに活動しているのでドラゴンクエスト10バージョン1.3 の新職業は全然レベルが上がりません。バトルマスターはまだレベル 53 です。仕事とゲームの両立って難しいですね、参っちゃいますね。</p><p>それはそうと、<a href=\"http://d.hatena.ne.jp/naoya/20120831/1346409758\">RubyMotion</a> は Xcode を使わなくても iOS 開発ができるというのが非常に嬉しいところなのですが、Emacs であの長ったらしい Cocoa API の補完をどうするかというのは積年の悩みでした。いちおう gtags を使って補完するみたいなバッドノウハウがあったりしますが、うまく動かなかったりで結局ちゃんと補完できてる人は周りにはいなかった。挙げ句には RubyMotion の補完それだけのために Sublime Text 2 に浮気する連中まで出る始末。</p><p>Emacs 界の終わりや！「誰か！救世主はよ！！ (他力本願寺)」と言っていたら現れました、救世主ことメシア。</p><ul><li><a href=\"http://blog.ainam.me/2013/03/21/rubymotion-motion-mode-el-emacs/\" target=\"_blank\">RubyMotion用のmotion-mode.elを作ったましましブログ | ましましブログ</a></li></ul><p><a href=\"https://twitter.com/ainame\">@ainame</a> さん。あんたは神や、後光が差してるで・・・</p><p>なんだかおかしなテンションになってしまいましたが、気を取り直してインストールしてみました。motion-mode.el は auto-complete を使って RubyMotion の API を補完してくれる。</p><p><a href=\"http://cdn.bloghackers.net/images/20130322_112430.png\" class=\"http-image\" target=\"_blank\"><img src=\"http://cdn.bloghackers.net/images/20130322_112430.png\" class=\"http-image\" alt=\"http://cdn.bloghackers.net/images/20130322_112430.png\" width=\"600\"></a></p><p>ばっちりじゃないですか。補完が効かないせいでよく大文字小文字やスペルミスしてはまっていたのでこれでだいぶ捗る！ありがとう @ainame さん！アンタの事は忘れないよ!! 昨日会ったし!!</p><p>えー、インストールには辞書の生成などちょっと下準備があるので github の README.md をちゃんと読みましょう。</p><ul><li><a href=\"https://github.com/ainame/motion-mode\" target=\"_blank\">https://github.com/ainame/motion-mode</a></li></ul><p>なお、昨日の RubyMotion もくもく会で他にも何人か導入を試みていましたが、auto-complete をちゃんと設定できてないとかではまってる人多数。motion-mode.el を入れる前に一度 auto-complete がきちんと動くように設定を見直してみることをオススメいたします。</p><p>今後はキーバインドでビルドやテストが走る追加機能を予定している、とのこと。</p><p>これでバーボン片手に「Sublime Text 2 のヤツに Emacs の変わりは重荷だぜ・・・俺の体が覚えたキーバインドがそれを許さねえ。はぁ? vim ? 100万回消滅しろ!!」とか言ってる連中も安泰です。ちなみに自分はそんなに過激派ではないです。</p><h4> RubyMotion Kaigi 2013 開催</h4><p>・・・と、Sublime Text や Emacs あるいは RubyMine など周辺ツールも揃ってきて盛り上がりを見せている RubyMotion ですが <a href=\"http://rubykaigi.org/2013\">Ruby Kagii 2013</a> ではなんと開発者の Laurent Sansonetti さんのトークがあるそうです。そして、Laurent さんが来日するなら併せて \"RubyMotion\" Kaigi をやろう、といったらほんとに実現してしまいました。もちろん Laurent さんの基調講演もあるよ。ワー、パチパチ。</p><ul><li><a href=\"http://connpass.com/event/2095/\" target=\"_blank\">RubyMotion Kaigi 2013 - connpass</a></li></ul><p>どしどしご応募ください! と思って書いてたのにすでに定員が埋まっていた!! そして定員枠を広げたとおもったらそれも埋まっていた!!! な、なんだってー。RubyMotion の＜鼓動＞を感じるぜ・・・。</p><div class=\"ascii-art\">
　　　　　　　　 ,. -‐&#39;&#39;&#39;&#39;&#39;&#34;&#34;¨¨¨ヽ <br>
　　　　 　 　 (.＿＿_,,,... -ァァフ|　　　　　　　　　　あ…ありのまま 今日　起こった事を話すぜ！ <br>
　 　 　 　 　 |i i|　 　 }!　}} /／| <br>
　　　　 　 　 |l、{　 　j}　/,,ィ//｜　　　　　　　『RubyMotion Kaigi を募集開始したと思ったら締め切っていた』 <br>
　　　　　　　 i|:!ヾ、_ノ／ u {:}//ヘ　　　　　　　　　　　 <br>
　　　　　　　 |リ u&#39; }　 ,ノ　_,!V,ハ |　　 <br>
　　 　 　 ／´fト、_{ル{,ィ&#39;ｅラ　, タ人　　　　　　　　な…　何を言ってるのか　わからねーと思うが <br>
　　　　 /&#39; 　 ヾ|宀| {´,)⌒`/ |&#60;ヽトiゝ　　　　　　　　おれも何をされたのかわからなかった… <br>
　　　　,゛　 ／ )ヽ iLレ 　u&#39; |　| ヾｌトハ〉 <br>
　　 　 |／_／　 ハ !ニ⊇　&#39;／:} 　V:::::ヽ　　　　　　　　頭がどうにかなりそうだった… <br>
　　　 /／ 二二二7&#39;T&#39;&#39; ／u&#39;　__ /:::::::/｀ヽ <br>
　　　/&#39;´r　-―一ァ‐゛Ｔ´　&#39;&#34;´ ／::::／-‐ 　＼　　　　　 いつまで経っても定員に到達しない某勉強会とか某勉強会とか<br>
　　 / // 　 广¨´ 　/&#39;　　 ／:::::／´￣｀ヽ ⌒ヽ　　　　　そんなチャチなもんじゃあ　断じてねえ <br>
　　ノ &#39; /　 ノ:::::`ー-、___／:::::／/ 　 　 　 ヽ　　}　　　　　 　 <br>
_／｀丶　/::::::::::::::::::::::::::￣`ー-{:::...　　　 　　　イ　 　　もっと恐ろしい、RubyMotionの胎動を味わったぜ…  <br></div><p>・・・すいません、すいません。間に合わなかった皆様方におかれましてはぜひキャンセルをお待ちいただければと思います・・・。</p></div>
") (dc:creator nil "naoya") (dc:date nil "2013-03-22T12:04:18+09:00"))) ("宮川さんPodcast ep6、KDP での本の作り方" "第６回は伊藤直也さん (@naoya_ito) をゲストに迎えて、Kindle 出版、GitHub、Google Reader などについて話しました。 ep6 ゲスト: Naoya Ito - Tatsuhiko Miyagawa's Podcast ほぼ週一くらいで配信されている @miyagawa さんの Podcast、第6回目のゲストで出演しまし" "http://d.hatena.ne.jp/naoya/20130321/1363838408" (20810 34248) new 3 nil nil ((title nil " 宮川さんPodcast ep6、KDP での本の作り方") (link nil "http://d.hatena.ne.jp/naoya/20130321/1363838408") (description nil " 第６回は伊藤直也さん (@naoya_ito) をゲストに迎えて、Kindle 出版、GitHub、Google Reader などについて話しました。 ep6 ゲスト: Naoya Ito - Tatsuhiko Miyagawa's Podcast ほぼ週一くらいで配信されている @miyagawa さんの Podcast、第6回目のゲストで出演しまし") (content:encoded nil "
<div class=\"section\"><blockquote title=\"ep6 ゲスト\" cite=\"http://podcast.bulknews.net/post/45880418516/podcast-ep6-naoya-ito\"><p>第６回は伊藤直也さん (@naoya_ito) をゲストに迎えて、Kindle 出版、GitHub、Google Reader などについて話しました。</p><cite><a href=\"http://podcast.bulknews.net/post/45880418516/podcast-ep6-naoya-ito\" target=\"_blank\">ep6 ゲスト: Naoya Ito - Tatsuhiko Miyagawa&#39;s Podcast</a></cite></blockquote><p>ほぼ週一くらいで配信されている @miyagawa さんの Podcast、第6回目のゲストで出演しました。第1回目に続き、これで自分は2回目ですね。だんだん往年のいいともみたいになっていくのだろうか。</p><p>それはともかく、内容は先日だした Kindle の <a href=\"http://www.amazon.co.jp/dp/B00BSPH158\">入門 Chef Solo</a> に絡めて KDP (Kindle Direct Publishing) の話、それから Google Reader にまつわる RSS の話に関して。二人とも KDP での出版経験があるのと、RSS に関しては昔二人で本を書いたりした当時のホットな話題でお互い良く知ってるしというので、面白く話せました。</p><p>Chef 本が実際 KDP でどのくらいダウンロードされているかとか、KDP の実際のところみたいな話も交えていますのでその辺りが気になる方も是非聴いてみてください。ちなみにいっとき Kindle 総合 (技術書じゃないですよ) ランキングで 2位になりました。</p><p><a href=\"http://cdn.bloghackers.net/images/20130321_125721.png\" class=\"http-image\" target=\"_blank\"><img src=\"http://cdn.bloghackers.net/images/20130321_125721.png\" class=\"http-image\" alt=\"http://cdn.bloghackers.net/images/20130321_125721.png\" width=\"600\"></a></p><p>KDP で本を作るにあたっては、@miyagawa さんに <a href=\"http://handbook.plackperl.org/\" target=\"_blank\">Plack Handbook</a> を作ったときのやり方を教えてもらったのですが、その際いっしょにもらった変換スクリプトを公開しても構わないと Podcast 内で許可をいただいたので、Podcast へのトラフィック誘導も含め以下 KDP How To を詳解いたします。</p><h4>  Kindle 向け書籍ができるまで</h4><p>大まかな流れとしては</p><ul><li> Markdown で原稿を書く</li><li> 変換スクリプトで html として出力する</li><li> その html を入力に calibre についてくる ebook-convert で epub に変換する</li><li> Sigil で html 目次を追加する</li><li> 実機で確認した後、Kindle 管理画面からアップロード</li></ul><p>という作業になります。</p><p>KDP では epub 以外にもいくつかのフォーマットをサポートしていますが、自分は無難に epub を選択しました。</p><h4> Markdown で原稿を書く</h4><p>原稿は Markdown で書きました。最近は技術評論社向けの雑誌原稿なんかも Markdown で書いてます (<a href=\"http://d.hatena.ne.jp/naoya/20130303/1362299005\" target=\"_blank\"> Markdown to Inao - naoyaのはてなダイアリー</a> とか参照) が、書籍や雑誌原稿のために使う記法は見出し、リスト、コードブロックとあとちょっとくらいなので Markdown で十分に事足りる。</p><pre>
## #0 はじめに

近頃のクラウドの本格的普及もあってか、サーバー管理の自動化に注目が集まっています。&#91;Chef](http://www.opscode.com/chef/) はそのツール/フレームワークのひとつです。

Chef への注目が集まっているにも関わらず Chef に関するある程度まとまった体系的な情報はまだまだ不足している、というのが現状です。また Chef は実際には同類のツールに比べてシンプルで分かりやすいのですが、公式ドキュメントがあまりにしっかりと書かれすぎていることもあって「はじめの一歩」としてどの辺りを知ればいいのか、つまり「普通に使う分にはこの程度知っていればOK」というのがどの辺りなのかを掴むのが難しい・・・というのが筆者の個人的な印象です。
</pre><p>Markdown のプレビューには自分は <a href=\"http://markedapp.com/\" target=\"_blank\">marked</a>  という OSX のアプリを使ってます。作りがミニマムで、ファイルの更新を検知してリロードしてれたり、シンタックスハイライトがあったりと使い勝手がよろしい。</p><p><a href=\"http://cdn.bloghackers.net/images/20130321_115312.png\" class=\"http-image\" target=\"_blank\"><img src=\"http://cdn.bloghackers.net/images/20130321_115312.png\" class=\"http-image\" alt=\"http://cdn.bloghackers.net/images/20130321_115312.png\" width=\"600\"></a></p><p>marked は有料アプリですが、フリーのがいいなという人は <a href=\"http://kobito.qiita.com/\" target=\"_blank\">Kobito</a> なんかもリアルタイムプレビューの機能を持っているのでいいと思われます。</p><p>作ったファイルはもちろん git で管理して、github に push。</p><p><a href=\"http://cdn.bloghackers.net/images/20130321_115558.png\" class=\"http-image\" target=\"_blank\"><img src=\"http://cdn.bloghackers.net/images/20130321_115558.png\" class=\"http-image\" alt=\"http://cdn.bloghackers.net/images/20130321_115558.png\" width=\"300\"></a></p><p>自分は Plack Handbook に倣い章ごとにファイルを分割して管理しました。</p><h4> 変換スクリプトで html として出力する</h4><p>できあがった原稿は Markdown を適当な Markdown パーサーで html にする。この html を calibre に渡して epub を作ります。ここは @miyagawa さんからもらったスクリプトをほぼそのまま使いました。Markdown parser の redcarpet が必要です。</p><pre class=\"syntax-highlight\"><span class=\"synPreProc\">#!/usr/bin/env ruby</span><span class=\"synComment\"># -*- coding: utf-8 -*-</span><span class=\"synComment\"># by Tatsuhiko Miyagawa</span><span class=\"synPreProc\">require</span><span class=\"synSpecial\">'</span><span class=\"synConstant\">redcarpet</span><span class=\"synSpecial\">'</span><span class=\"synIdentifier\">HEADER</span> = &#60;&#60;<span class=\"synSpecial\">HEAD</span><span class=\"synConstant\">&#60;html&#62;</span><span class=\"synConstant\">&#60;head&#62;</span><span class=\"synConstant\">&#60;title&#62;入門Chef Solo - Infrastructure as Code&#60;/title&#62;</span><span class=\"synConstant\">&#60;meta name=&#34;Author&#34; content=&#34;Naoya Ito&#34;&#62;</span><span class=\"synConstant\">&#60;meta name=&#34;DC.date.publication&#34; content=&#34;2013-03&#34;&#62;</span><span class=\"synConstant\">&#60;meta name=&#34;DC.rights&#34; content=&#34;2013 Naoya Ito&#34;&#62;</span><span class=\"synConstant\">&#60;link rel=&#34;stylesheet&#34; href=&#34;styles/epub.css&#34; type=&#34;text/css&#34; class=&#34;horizontal&#34; title=&#34;Horizontal Layout&#34; /&#62;</span><span class=\"synConstant\">&#60;/head&#62;</span><span class=\"synConstant\">&#60;body&#62;</span><span class=\"synSpecial\">HEAD</span><span class=\"synPreProc\">def </span><span class=\"synIdentifier\">munge</span>(html)
  html.gsub <span class=\"synSpecial\">/</span><span class=\"synConstant\">&#60;h2&#62;</span><span class=\"synSpecial\">/</span>, <span class=\"synSpecial\">'</span><span class=\"synConstant\">&#60;h2 class=&#34;chapter&#34;&#62;</span><span class=\"synSpecial\">'</span><span class=\"synPreProc\">end</span>

markdown = <span class=\"synIdentifier\">Redcarpet</span>::<span class=\"synIdentifier\">Markdown</span>.new(<span class=\"synIdentifier\">Redcarpet</span>::<span class=\"synIdentifier\">Render</span>::<span class=\"synIdentifier\">HTML</span>, <span class=\"synIdentifier\">:autolink</span> =&#62; <span class=\"synConstant\">true</span>, <span class=\"synIdentifier\">:space_after_headers</span> =&#62; <span class=\"synConstant\">true</span>)
<span class=\"synIdentifier\">STDOUT</span>.write <span class=\"synIdentifier\">HEADER</span><span class=\"synIdentifier\">STDOUT</span>.write munge(markdown.render(<span class=\"synIdentifier\">ARGF</span>.readlines.join <span class=\"synSpecial\">''</span>))
<span class=\"synIdentifier\">STDOUT</span>.write <span class=\"synSpecial\">&#34;</span><span class=\"synConstant\">&#60;/body&#62;&#60;/html&#62;</span><span class=\"synSpecial\">\\n&#34;</span></pre><p>h2 タグに <code>class=\"chapter\"</code> みたいなクラスが振ってあるのは calibre 向けに html を作る場合に html のタグで適当なメタデータを指定しておくと本のタイトルや目次を自動で出力してくれるそれを利用するため。</p><h4> calibre で epub に変換</h4><p><a href=\"http://calibre-ebook.com/\">calibre</a> は ebook management ツールだそうです。変換機能だけでなく、作成したファイルの管理 や Kindle デバイスへの転送なんかもやってくれる。</p><p>が、GUI でちまちまちファイルを入力してやるのは面倒。calibre についてくる ebook-convert という CUI 向けのコマンドがあるのでこれを使って  rake でビルドします。ついでなので mobi ファイルも作っちゃう。</p><pre class=\"syntax-highlight\"><span class=\"synComment\"># Rakefile</span>
task <span class=\"synIdentifier\">:default</span> =&#62; <span class=\"synSpecial\">&#34;</span><span class=\"synConstant\">book</span><span class=\"synSpecial\">&#34;</span>

task book: [<span class=\"synIdentifier\">:mobi</span>, <span class=\"synIdentifier\">:epub</span>]

file html: <span class=\"synIdentifier\">Dir</span>.glob(<span class=\"synSpecial\">'</span><span class=\"synConstant\">ja/*.md</span><span class=\"synSpecial\">'</span>) <span class=\"synStatement\">do</span> |<span class=\"synIdentifier\">task</span>|
  sh <span class=\"synSpecial\">&#34;</span><span class=\"synConstant\">bin/export_html.rb </span><span class=\"synSpecial\">#{task.prerequisites.join(' ')}</span><span class=\"synConstant\"> &#62; chef-solo-book.html</span><span class=\"synSpecial\">&#34;</span><span class=\"synStatement\">end</span>

task mobi: <span class=\"synSpecial\">%w[</span><span class=\"synConstant\">html</span><span class=\"synSpecial\">]</span><span class=\"synStatement\">do</span>
  sh <span class=\"synSpecial\">&#34;</span><span class=\"synConstant\">ebook-convert chef-solo-book.html chef-solo-book.mobi</span><span class=\"synSpecial\">&#34;</span><span class=\"synStatement\">end</span>

task epub: <span class=\"synSpecial\">%w[</span><span class=\"synConstant\">html</span><span class=\"synSpecial\">]</span><span class=\"synStatement\">do</span>
  sh <span class=\"synSpecial\">&#34;</span><span class=\"synConstant\">ebook-convert chef-solo-book.html chef-solo-book.epub --no-default-epub-cover</span><span class=\"synSpecial\">&#34;</span><span class=\"synStatement\">end</span>

task <span class=\"synIdentifier\">:clean</span><span class=\"synStatement\">do</span>
  sh <span class=\"synSpecial\">&#34;</span><span class=\"synConstant\">rm -f chef-solo-book.html *.epub *.mobi</span><span class=\"synSpecial\">&#34;</span><span class=\"synStatement\">end</span></pre><p>できあがったファイルは calibre の GUI なり Dropbox なりなんなりで Kindle や iPad なんかに転送すれば普通に電子書籍として読めるのでそれで実際の見た目や改ページが正しく行われてるかなんかを確認していきます。</p><h4> Sigil で HTML 目次を作る</h4><p>ここまでで epub は完成なのですが、Kindle for iPhone や Kindle for iPad は calibre が作った目次をなぜか無視してしまう。iOS 向けには html で目次を作るといいとのことだったので、<a href=\"https://code.google.com/p/sigil/\">Sigil</a> という epub エディタを使って目次を生成してやる。これはメニューから選ぶだけ。</p><p>本当はここも自動化したいけどいまのところ、そこまではやれていない。</p><p>あとはできあがった epub ファイルを KDP にアップロードすれば OK。ちなみに KDP にアップロードすると確認用の mobi ファイルを生成してくれるので最後の最後の確認はそれを使ってやるといいです。</p><h4> KDP バッドノウハウ</h4><p>そのほか細かいのがいろいろとあったので思いついたことを列挙しておきます。</p><ul><li> KDP で出版するとどうやら KDP 独自のスタイルが当たるようで、インデントや行間なんかの幅が変わったりする。結構読みやすい。ebook-convert で直接生成したままのではちょっと行間詰まりすぎ、みたいな印象を抱くと思うけど KDP で mobi を作ると良い感じになる前提でいればよい</li><li> Kindle Paperwhite で動作確認していると、更新したファイルのせいで端末内での記憶位置そのほかがぶっこわれるときがある。そういうときは一端端末から書籍を削除する</li><li> 生成した epub が valid かどうかは <a href=\"https://code.google.com/p/epubcheck/\" target=\"_blank\">https://code.google.com/p/epubcheck/</a> この辺を使うと良いと思う。書いてて思ったけどビルドフローに組み込んでしまえばいいかも</li><li> Podcast 内でも触れたけど、ファイルの更新を頻繁にやる前提でいる場合、KDP はそういうものではないので注意。ファイルの更新は自動ではユーザーに通知されないし、自動で更新されたりもしない。</li><li> またファイルをアップロードして実際にそれが反映されるまでに時間がかかる。その間、iOS版は Amazon.co.jp からの転送が不可になる

<ul><li> ファイルを更新しなくても KDP に入力した description の typo を直したという程度でも同様。Publish するたびに数時間 iOS 版が実質買えなくなる </li></ul></li><li> 技術書という性格もあって実際に出してみると PDF にしたいとか他の形式で読みたいという声が結構多かった。DRM フリーにしておけばその辺の再利用はユーザーに任せることができるので良いと思う。もちろん選択は著作権者の自由ではありますけど。DRM フリーかどうかは KDP のアップロード画面で選べる</li><li> epub の中にちゃんと思った通りにファイルが含まれているかどうか、なんてのは Sigil でも確認できるし Emacs (自分のは 24) の dired で epub を開くと中身をファイラで確認できた</li><li> Unicode 未定義な文字とかを使うと KDP で iOS 版が生成されないという事故があったりするらしい。実際のところ、ビルドがエラーになっているのか先に述べたファイル更新中で iOS 版がダウンロードできないだけなのか・・・といった事情は確認の術がない。余計なことで悩まないように、特殊な文字は必要がないなら使わないようにするのが懸命</li><li> 表紙は指定しないと KDP が自動で生成してくれるとあったけど、自分の場合書名が長かったのか何なのか、ずっと表紙がない状態だった。「画像はありません」のまま総合2位でランキングに居座るという胸熱な結果となりました。結局 @nagayama に作ってもらいました。</li><li> 表紙があると、「人気」とか「新着」というアイコンが書影に添付されて Amazon.co.jp の検索結果に出るようになって目も引くので、売り上げ的にもあったほうがいいと思います</li></ul><p>以上、KDP How To でした。Chef 本へのレビューもお待ちしてます!</p><p><div style=\"margin-bottom:0px;\" class=\"amazlet-box\"><div style=\"float:left;margin:0px 12px 1px 0px;\" class=\"amazlet-image\"><a target=\"_blank\" href=\"http://www.amazon.co.jp/exec/obidos/ASIN/B00BSPH158/naoyadyndnsor-22/ref=nosim/\" name=\"amazletlink\"><img alt=\"入門Chef Solo - Infrastructure as Code\" src=\"http://ecx.images-amazon.com/images/I/31u6VLGX2kL._SL160_.jpg\" style=\"border: none;\"></a></div><div style=\"line-height:120%; margin-bottom: 10px\" class=\"amazlet-info\"><div style=\"margin-bottom:10px;line-height:120%\" class=\"amazlet-name\"><a target=\"_blank\" href=\"http://www.amazon.co.jp/exec/obidos/ASIN/B00BSPH158/naoyadyndnsor-22/ref=nosim/\" name=\"amazletlink\">入門Chef Solo - Infrastructure as Code</a><div style=\"font-size:80%;margin-top:5px;line-height:120%\" class=\"amazlet-powered-date\">posted with <a target=\"_blank\" href=\"http://www.amazlet.com/\" title=\"amazlet\">amazlet</a> at 13.03.21</div></div><div class=\"amazlet-detail\">伊藤直也 (2013-03-11)<br>売り上げランキング: 36<br></div><div style=\"float: left;\" class=\"amazlet-sub-info\"><div style=\"margin-top: 5px\" class=\"amazlet-link\"><a target=\"_blank\" href=\"http://www.amazon.co.jp/exec/obidos/ASIN/B00BSPH158/naoyadyndnsor-22/ref=nosim/\" name=\"amazletlink\">Amazon.co.jpで詳細を見る</a></div></div></div><div style=\"clear: left\" class=\"amazlet-footer\"></div></div></p></div>
") (dc:creator nil "naoya") (dc:date nil "2013-03-21T13:00:08+09:00"))) ("Google Reader終了にまつわるRSSに関しての取材" "岡田有花さんに取材いただいたものがさきほど記事になりました。RSSやRSSリーダーは「終わる」のかについて。Google Reader の終了発表にまつわる話ここ最近ホットなトピックですね。 この3月、RSSに関連する大きなサービスが相次いで終わりを迎えた。3月5日にTwitterのRSS" "http://d.hatena.ne.jp/naoya/20130318/1363578062" (20806 36046) new 4 nil nil ((title nil " Google Reader終了にまつわるRSSに関しての取材") (link nil "http://d.hatena.ne.jp/naoya/20130318/1363578062") (description nil " 岡田有花さんに取材いただいたものがさきほど記事になりました。RSSやRSSリーダーは「終わる」のかについて。Google Reader の終了発表にまつわる話ここ最近ホットなトピックですね。 この3月、RSSに関連する大きなサービスが相次いで終わりを迎えた。3月5日にTwitterのRSS") (content:encoded nil "
<div class=\"section\"><p>岡田有花さんに取材いただいたものがさきほど記事になりました。RSSやRSSリーダーは「終わる」のかについて。Google Reader の終了発表にまつわる話ここ最近ホットなトピックですね。</p><blockquote title=\"「Google Readerが終わっても、RSSは終わらない」――伊藤直也さんに聞く (1/2) - ITmedia ニュース\" cite=\"http://www.itmedia.co.jp/news/articles/1303/18/news057.html\"><p>この3月、RSSに関連する大きなサービスが相次いで終わりを迎えた。3月5日にTwitterのRSSフィードが終了。3月14日にはGoogleが、RSSリーダー「Google Reader」を終了すると発表した。</p><p>　これらの動きを受けてネットでは、RSSについての議論が盛んになっている。「RSSは時代遅れ」「RSSリーダーは終わる」といった論調もある。</p><p>　だが、ニフティのブログサービス「ココログ」や、はてなのソーシャルブックマーク「はてなブックマーク」など、RSSに関連するサービスを多く手がけてきたフリーエンジニアの伊藤直也さんは、「RSSも、RSSリーダーも終わらない」と話す。</p><cite><a href=\"http://www.itmedia.co.jp/news/articles/1303/18/news057.html\" target=\"_blank\">「Google Readerが終わっても、RSSは終わらない」――伊藤直也さんに聞く (1/2) - ITmedia ニュース</a></cite></blockquote><p>もともと Google Reader 終了のニュースを見て Twitter でぶつぶつ言ってたら、岡田さんからこの件に関するまとめた記事を書きたいので取材させて欲しいという依頼があって・・・という経緯でした。ちまたをみてるとこれでRSSやRSSリーダーは終わりだ！というようなやや扇動的な記事もちらほらみかけてもやもやしていたので、ちょうどいいタイミングで取材をいただける感じになりました。実際のところどう思ってるの、というのは記事本体を見てください。</p><p>とりあえず岡田さんが、RSSとRSSリーダーの区別がついてないところから話が始まり一通り説明しました。ユースケースとしての「RSSリーダー」と、仕様 (フォーマット) としての「RSS」というののいずれの文脈でこの話をするのかで中身がまったく異なってくるということ、で、世間一般では前者のユースケースが減ってきてるから後者も終わりみたいな紐づけをされることもあるようだけど、そうではないということ。その前者も、よりよい代替となる手段がほかに出てこない限りはゼロにはならないということ・・・などなどの話をしました。</p><p>RSS はウェブ上において空気のように使われるべきだし、話題になった2000年代前半のブログの頃から結構時間が経って、望まれたとおり空気のように使われるようになったのでこうしてユースケースと仕様の両者がごっちゃになって議論されることは、それほど予想外のことではないのですけどね。それ単体ではほとんどビジネスにはならなかったので、オワコンだと言いたいきもちもよくわかります。けど、なんでもそうやって因果関係をみつけて時代の必然みたいな形で語ろうとすると間違っちゃうかな、とはちょっと思いました。</p><p>個人的には <a href=\"http://maclalala2.wordpress.com/2013/03/14/google-reader-%E3%81%AE%E7%B5%82%E4%BA%86%E3%81%AF%E3%81%99%E3%81%B0%E3%82%89%E3%81%97%E3%81%84%E3%83%8B%E3%83%A5%E3%83%BC%E3%82%B9%E3%81%A0%EF%BC%9Amarco-arment/\" target=\"_blank\">Google Reader の終了はすばらしいニュースだ：Marco Arment | maclalala2</a> が言っているように、これを機に既存のRSSリーダーの分野を見直したような新しいプロダクトやサービスとかがでてきて、そういう古いユースケースを置き換えていくみたいなのが進んでいくと楽しい、未来感あるねえと思っています。</p><p>で、全然関係ないけど以下を引用しておこう。吉本隆明の『ひとり 15歳の寺子屋』という本から。夏目漱石が大学だったかな、を留年して一年くらいぶらぶらしてた時期があったというところからよくそういう自由闊達な時間があったから漱石はあんな作品を生み出せたんだ・・・みたいに分析したがる向きが多いけどそうじゃねえよって老黄忠が言う場面ですな。</p><blockquote><p>だからといって、「そのハメをはずした一年があったからこそ、漱石は人の気持ちがわかる立派な小説家になりました」みたいなお決まりなことは、僕にはとうていいえません。</p><p>「こうしたから、こうなった」なんて、何かを学んだ気になってると人生まちがっちゃう。そんなふうに原因と結果が安易に結びつくことは、現実にはまずないんだって思ってた方がいい。むしろ「一年くらい、ハメはずしたからって、人生そんなに変わりゃしねえよ」っていった方がいいくらいです。</p></blockquote></div>
") (dc:creator nil "naoya") (dc:date nil "2013-03-18T12:41:02+09:00"))) ("Vagrant 1.1 で EC2 を vagrant up" "Vagrant 1.1 がリリースされました。 Vagrant は仮想サーバーのフロントエンドのツール、詳しくは Vagrant - naoyaのはてなダイアリー あたりを。 で、この 1.1 が 1.0 → 1.1 という割に結構大きなアップデートで新しく VM に VirtualBox 以外のものが選択できるようになっ" "http://d.hatena.ne.jp/naoya/20130315/1363340698" (20802 60826) new 5 nil nil ((title nil " Vagrant 1.1 で EC2 を vagrant up") (link nil "http://d.hatena.ne.jp/naoya/20130315/1363340698") (description nil " Vagrant 1.1 がリリースされました。 Vagrant は仮想サーバーのフロントエンドのツール、詳しくは Vagrant - naoyaのはてなダイアリー あたりを。 で、この 1.1 が 1.0 → 1.1 という割に結構大きなアップデートで新しく VM に VirtualBox 以外のものが選択できるようになっ") (content:encoded nil "
<div class=\"section\"><p><a href=\"http://www.hashicorp.com/blog/vagrant-1-1-and-vmware.html\">Vagrant 1.1 がリリースされました。</a> Vagrant は仮想サーバーのフロントエンドのツール、詳しくは <a href=\"http://d.hatena.ne.jp/naoya/20130205/1360062070\" target=\"_blank\"> Vagrant - naoyaのはてなダイアリー</a> あたりを。</p><p>で、この 1.1 が 1.0 → 1.1 という割に結構大きなアップデートで新しく VM に VirtualBox 以外のものが選択できるようになった。すなわち「VirtualBox のフロントエンド = Vagrant」から「各種仮想マシンのフロントエンド = Vagrant」という風にアップデートされた。</p><blockquote title=\"Vagrant 1.1リリース、VMware Fusion, EC2, Rackspace が新たに対応 | Act as Professional - hiroki.jp\" cite=\"http://hiroki.jp/2013/03/15/6844/\"><p>今回の 1.1 からVMを操作するproviderがプラグイン構造となり、VirtualBoxだけならず、公式で操作できる対象が増えました。</p><ul><li> VirtualBox</li><li> VMware Fusion</li><li> Amazon EC2 + VPC</li><li> Rackspace Cloud</li></ul><p>VMware Fusion以外はオープンソースで公開されています。</p><cite><a href=\"http://hiroki.jp/2013/03/15/6844/\" target=\"_blank\">Vagrant 1.1リリース、VMware Fusion, EC2, Rackspace が新たに対応 | Act as Professional - hiroki.jp</a></cite></blockquote><p>みんな「おっ」と反応するだろう点、その仮想マシンというのがローカルのみならず Amazon EC2 や Rackspace に対応してるじゃあーりませんか。<code>vagrant up</code> で EC2 インスタンスが立ちちあがるんですよ、胸熱!</p><p>これに伴いドキュメントも v.1.1 向けにアップデートされたようです。</p><ul><li><a href=\"http://docs.vagrantup.com/v2\" target=\"_blank\">http://docs.vagrantup.com/v2</a></li></ul><p>v2 というタグがついているように、バージョンは v1.1 でも内部的には 2 という扱いみたい。</p><h4> Version 1.1 での注意点</h4><p>早速やってみますがその前に2点ほど</p><ul><li> Vagrant の配布が rubygems ではなくなり<a href=\"http://downloads.vagrantup.com/\">パッケージ形式</a>になった。<code>gem install vagrant</code> はもう古いから v1.1 使う場合は削除してパッケージ版を入れろ、とのことです

<ul><li> rubygems から gem install しても v1.0 系しか入らない</li><li> どうもパスの関係か何かで、例えば github + Bundler なかで入れた場合は動作が保証できないと警告が出る</li></ul></li><li> Vagrantfile の書き方が少し変わった。具体的には <code>Vagrant.configure(\"2\")</code> とバージョン番号を指定する。以前のように <code>Vagrant::Config.run</code> した場合は v1.0 系の後方互換モードになる

<ul><li> 詳しくは <a href=\"http://docs.vagrantup.com/v2/vagrantfile/version.html\" target=\"_blank\">http://docs.vagrantup.com/v2/vagrantfile/version.html</a> このへん</li></ul></li></ul><p>あたりに注意。</p><p>個人的にはあんまりシステムワイドなパスに入れたくないんだけど、まあしょうがない。というわけで</p><pre>
$ /usr/sbin/vagrant -v
Vagrant version 1.1.0
</pre><p>バージョン 1.1 でございます。</p><h4> Vagrant で EC2 インスタンスを立ち上げる</h4><p>ま、ほぼ <a href=\"https://github.com/mitchellh/vagrant-aws\">README.md</a> に書いてるとおりなんですけどね。結構はまったりもしたので、紹介しておこう。</p><p>まずは AWS Provider を入れる。プラグインです (もしかしたらこの作業必要ないのかもしれない)</p><pre>
$ vagrant plugin install vagrant-aws
$ vagrant plugin list
vagrant-aws (0.1.0)
</pre><p>EC2 を Provider に使う場合は OS のイメージはいらないけど、Box が何もないとだめなのでダミーのそれを box add しろ、ということだそうです。</p><pre>
$ vagrant box add dummy https://github.com/mitchellh/vagrant-aws/raw/master/dummy.box           
$ vagrant box list
Berkshelf-CentOS-6.3-x86_64-minimal (virtualbox)
base                                (virtualbox)
dummy                               (aws)
</pre><p>続けて  Vagrantfile を調整していきましょう。</p><pre>
$ vagrant init
</pre><p>で作成して</p><pre class=\"syntax-highlight\"><span class=\"synIdentifier\">Vagrant</span>.configure(<span class=\"synSpecial\">&#34;</span><span class=\"synConstant\">2</span><span class=\"synSpecial\">&#34;</span>) <span class=\"synStatement\">do</span> |<span class=\"synIdentifier\">config</span>|
  config.vm.box = <span class=\"synSpecial\">&#34;</span><span class=\"synConstant\">dummy</span><span class=\"synSpecial\">&#34;</span>

  config.vm.provider <span class=\"synIdentifier\">:aws</span><span class=\"synStatement\">do</span> |<span class=\"synIdentifier\">aws</span>|
    aws.access_key_id     = <span class=\"synIdentifier\">ENV</span>[<span class=\"synSpecial\">'</span><span class=\"synConstant\">AWS_ACCESS_KEY_ID</span><span class=\"synSpecial\">'</span>]
    aws.secret_access_key = <span class=\"synIdentifier\">ENV</span>[<span class=\"synSpecial\">'</span><span class=\"synConstant\">AWS_SECRET_ACCESS_KEY</span><span class=\"synSpecial\">'</span>]
    aws.keypair_name = <span class=\"synSpecial\">&#34;</span><span class=\"synConstant\">naoya's keys</span><span class=\"synSpecial\">&#34;</span>
    aws.ssh_username = <span class=\"synSpecial\">&#34;</span><span class=\"synConstant\">ec2-user</span><span class=\"synSpecial\">&#34;</span>
    aws.ssh_private_key_path = <span class=\"synSpecial\">&#34;</span><span class=\"synConstant\">~/.ssh/aws-naoyaskeys.pem</span><span class=\"synSpecial\">&#34;</span>
    aws.instance_type = <span class=\"synSpecial\">&#34;</span><span class=\"synConstant\">t1.micro</span><span class=\"synSpecial\">&#34;</span>
    aws.region = <span class=\"synSpecial\">&#34;</span><span class=\"synConstant\">ap-northeast-1</span><span class=\"synSpecial\">&#34;</span>
    aws.ami = <span class=\"synSpecial\">&#34;</span><span class=\"synConstant\">ami-a3af2ba2</span><span class=\"synSpecial\">&#34;</span>
    aws.security_groups = [ <span class=\"synSpecial\">'</span><span class=\"synConstant\">webserver</span><span class=\"synSpecial\">'</span> ]
  <span class=\"synStatement\">end</span><span class=\"synStatement\">end</span></pre><p>と書く。</p><p>自分は AWS の API キーはシェルの環境変数に入れてるのでそこから取ってます。</p><ul><li><code>ssh_username</code> などもちゃんと指定しないと良い感じに ssh はしてくれない</li><li><code>instance_type</code> を指定しないとおもむろに m1.small が起ち上がったりして課金的につらい</li><li><code>security_groups</code> を指定しないと対象が default になり、EC2 の default は ssh port が空いてないので嵌る</li></ul><p>などなどあるので、ちょっと面倒ですが各種項目は丁寧にちゃんと設定しましょう。なお、<code>config.vm.network</code> あたりは今のところサポートしていないそうですが、VPC のアドレスを設定できる項目があるので問題ないでしょう。</p><p>これにて準備完了。vagrant up にございます。<code>--provider=aws</code> で Provider を選択するとよろしい。</p><pre>
$ vagrant up --provider=aws
Bringing machine &#39;default&#39; up with &#39;aws&#39; provider...
&#91;default] Warning! The AWS provider doesn&#39;t support any of the Vagrant
high-level network configurations (`config.vm.network`). They
will be silently ignored.
&#91;default] Launching an instance with the following settings...
&#91;default]  -- Type: t1.micro
&#91;default]  -- AMI: ami-a3af2ba2
&#91;default]  -- Region: ap-northeast-1
&#91;default]  -- Keypair: naoya&#39;s keys
&#91;default]  -- Security Groups: &#91;&#34;webserver&#34;]
&#91;default] Waiting for instance to become &#34;ready&#34;...
&#91;default] Waiting for SSH to become available...
&#91;default] Machine is booted and ready for use!
&#91;default] Rsyncing folder: /Users/naoya/vagrant/ec2berks/ =&#62; /vagrant
</pre><p>インスタンスがこれで起ち上がる。</p><pre>
$ vagrant ssh
vagrant ssh
Last login: Fri Mar 15 08:52:46 2013 from …

       __|  __|_  )
       _|  (     /   Amazon Linux AMI
      ___|&#92;___|___|

https://aws.amazon.com/amazon-linux-ami/2012.09-release-notes/
There are 11 security update(s) out of 20 total update(s) available
</pre><p>きたわー。public DNS を覚えなくても ssh できるのが地味に嬉しい。</p><pre>
$ vagrant destroy
</pre><p>これでインスタンスが Terminate されます。vagrant halt だとおそらくサスペンドではないかと思います。</p><h4> Chef でプロビジョニング</h4><p>EC2 インスタンスを Vagrant で立ち上げられる、というだけだとまあそこまで旨みは感じられないのですが例えば複数 VM をまとめて作成する マルチVM 機能を使ったり Chef や Puppet などのプロビジョニングツールと連携して <code>vagrant up</code> 時にプロビジョニングも走らせてしまう・・・という Vagrant の付加機能を使っていくと、EC2 を Vagrant で管理する意味が出てくる。</p><p>Chef Solo でプロビジョニング、やってみましょう。</p><pre class=\"syntax-highlight\"><span class=\"synIdentifier\">Vagrant</span>.configure(<span class=\"synSpecial\">&#34;</span><span class=\"synConstant\">2</span><span class=\"synSpecial\">&#34;</span>) <span class=\"synStatement\">do</span> |<span class=\"synIdentifier\">config</span>|
  config.vm.box = <span class=\"synSpecial\">&#34;</span><span class=\"synConstant\">dummy</span><span class=\"synSpecial\">&#34;</span>
  config.ssh.username = <span class=\"synSpecial\">&#34;</span><span class=\"synConstant\">ec2-user</span><span class=\"synSpecial\">&#34;</span><span class=\"synComment\"># これないとこける</span>

  config.vm.provider <span class=\"synIdentifier\">:aws</span><span class=\"synStatement\">do</span> |<span class=\"synIdentifier\">aws</span>|
    <span class=\"synComment\"># さっきと同じ</span><span class=\"synStatement\">end</span><span class=\"synComment\"># プロビジョニングの設定</span>
  config.vm.provision <span class=\"synIdentifier\">:chef_solo</span><span class=\"synStatement\">do</span> |<span class=\"synIdentifier\">chef</span>|
    chef.add_recipe <span class=\"synSpecial\">&#34;</span><span class=\"synConstant\">sandbox</span><span class=\"synSpecial\">&#34;</span><span class=\"synStatement\">end</span><span class=\"synStatement\">end</span></pre><p>という具合。Chef Solo を使う場合例によって rsync + ssh でレシピ転送と chef-solo 実行を行うようですが、その際に <code>config.ssh.username</code> を指定しとかないと vagrant ユーザーで操作しようとして落ちます。えらくはまって vagrant のソース読むはめに・・・。</p><p>あとはいつもどおりプロビジョニングの設定をしてやる。上記の chef オブジェクトはほぼ、Chef Solo の JSON ファイルに記述する Node Object 相当です。</p><p>クックブックの配置場所は Vagrantfile のあるパスの cookbooks ディレクトリが暗黙に期待されている。</p><pre>
$ tree
.
├── Vagrantfile
└── cookbooks
    └── sandbox
</pre><p>ので Vagrantfile のある場所で</p><pre>
$ knife cookbook create sandbox -o cookbooks
</pre><p>で作成する。</p><p>ここでは試しに Template を使って Ohai からEC2関連の値を取得したファイルを書き出してみよう。</p><pre class=\"syntax-highlight\"><span class=\"synComment\"># recipes/default.rb</span>
template <span class=\"synSpecial\">&#34;</span><span class=\"synConstant\">/tmp/vagrant_test.txt</span><span class=\"synSpecial\">&#34;</span><span class=\"synStatement\">do</span>
  mode <span class=\"synConstant\">0644</span><span class=\"synStatement\">end</span></pre><pre>
# templates/default/vagrant_test_txt.erb
&#60;%= node&#91;:ec2]&#91;:ami_id] %&#62;
&#60;%= node&#91;:ec2]&#91;:instance_type] %&#62;
&#60;%= node&#91;:ec2]&#91;:placement_availability_zone] %&#62;
</pre><p>すでに <code>vagrant up</code> 済みなのときプロビジョニングだけ適用するには <code>vagrant provision</code> です。</p><pre>
$ vagrant provision
&#91;default] Rsyncing folder: /Users/naoya/vagrant/ec2berks/ =&#62; /vagrant
&#91;default] Rsyncing folder: /Users/naoya/vagrant/ec2berks/cookbooks/ =&#62; /tmp/vagrant-chef-1/chef-solo-1/cookbooks
&#91;default] Running provisioner: VagrantPlugins::Chef::Provisioner::ChefSolo...
Generating chef JSON and uploading...
Running chef-solo...
&#91;2013-03-15T08:52:35+00:00] INFO: &#42;&#42;&#42; Chef 10.18.2 &#42;&#42;&#42;
…
</pre><pre>
$ vagrant ssh
$ cat /tmp/vagrant_test.txt
ami-a3af2ba2
t1.micro
ap-northeast-1a
</pre><p>はい、上手に焼けました。</p><p>というわけで EC2 インスタンスを Vagrant で操作できるようになった。やってみると、例えば EC2 インスタンスを立ち上げるスクリプトを書いて knife-solo で Chef Solo を流しているみたいなものなのでそこまで「すげえ！」という話ではないのかもしれないけれど、Vagrantfile に「インスタンスの状態」を記述して管理できる点、プロビジョナーとセットにすれば統一された EC2 上の試験環境の配布が楽になる点など、常用してもいいかなというポイントはちらほらあるように思いました。</p><p>逆にマルチVMやプロビジョニング連携を使わないとなると、そんなに嬉しいかどうか。自分で EC2 インスタンス立ち上げスクリプトを書いたりしなくていい、というくらいですかね。今後 Vagrant Sahara などのプラグインとちゃんと連携していくかどうかとかも気になるところではあります。</p><p>以上、Vagrant 1.1 キャッチアップでした。え、Chef の使い方とか良く分からない? なるほどそれでは</p><p><div style=\"margin-bottom:0px;\" class=\"amazlet-box\"><div style=\"float:left;margin:0px 12px 1px 0px;\" class=\"amazlet-image\"><a target=\"_blank\" href=\"http://www.amazon.co.jp/exec/obidos/ASIN/B00BSPH158/naoyadyndnsor-22/ref=nosim/\" name=\"amazletlink\"><img alt=\"入門Chef Solo - Infrastructure as Code\" src=\"http://ecx.images-amazon.com/images/I/31u6VLGX2kL._SL160_.jpg\" style=\"border: none;\"></a></div><div style=\"line-height:120%; margin-bottom: 10px\" class=\"amazlet-info\"><div style=\"margin-bottom:10px;line-height:120%\" class=\"amazlet-name\"><a target=\"_blank\" href=\"http://www.amazon.co.jp/exec/obidos/ASIN/B00BSPH158/naoyadyndnsor-22/ref=nosim/\" name=\"amazletlink\">入門Chef Solo - Infrastructure as Code</a><div style=\"font-size:80%;margin-top:5px;line-height:120%\" class=\"amazlet-powered-date\">posted with <a target=\"_blank\" href=\"http://www.amazlet.com/\" title=\"amazlet\">amazlet</a> at 13.03.17</div></div><div class=\"amazlet-detail\">伊藤直也 (2013-03-11)<br>売り上げランキング: 14<br></div><div style=\"float: left;\" class=\"amazlet-sub-info\"><div style=\"margin-top: 5px\" class=\"amazlet-link\"><a target=\"_blank\" href=\"http://www.amazon.co.jp/exec/obidos/ASIN/B00BSPH158/naoyadyndnsor-22/ref=nosim/\" name=\"amazletlink\">Amazon.co.jpで詳細を見る</a></div></div></div><div style=\"clear: left\" class=\"amazlet-footer\"></div></div></p><p>をおすすめしておきますね。</p></div>
") (dc:creator nil "naoya") (dc:date nil "2013-03-15T18:44:58+09:00"))) ("Kindle向けに『入門Chef Solo - Infrastructure as Code』を出版しました" "Chef のスタンドアロン版である Chef Solo の技術書を Kindle 向け電子書籍として出版しました。 入門Chef Solo - Infrastructure as Codeposted with amazlet at 13.03.17伊藤直也 (2013-03-11)売り上げランキング: 14Amazon.co.jpで詳細を見る がんばりました。原稿＼(^o^" "http://d.hatena.ne.jp/naoya/20130313/1363129532" (20799 46268) new 6 nil nil ((title nil " Kindle向けに『入門Chef Solo - Infrastructure as Code』を出版しました") (link nil "http://d.hatena.ne.jp/naoya/20130313/1363129532") (description nil " Chef のスタンドアロン版である Chef Solo の技術書を Kindle 向け電子書籍として出版しました。 入門Chef Solo - Infrastructure as Codeposted with amazlet at 13.03.17伊藤直也 (2013-03-11)売り上げランキング: 14Amazon.co.jpで詳細を見る がんばりました。原稿＼(^o^") (content:encoded nil "
<div class=\"section\"><p><a href=\"http://www.opscode.com/chef/\">Chef</a> のスタンドアロン版である Chef Solo の技術書を Kindle 向け電子書籍として出版しました。</p><p><div style=\"margin-bottom:0px;\" class=\"amazlet-box\"><div style=\"float:left;margin:0px 12px 1px 0px;\" class=\"amazlet-image\"><a target=\"_blank\" href=\"http://www.amazon.co.jp/exec/obidos/ASIN/B00BSPH158/naoyadyndnsor-22/ref=nosim/\" name=\"amazletlink\"><img alt=\"入門Chef Solo - Infrastructure as Code\" src=\"http://ecx.images-amazon.com/images/I/31u6VLGX2kL._SL160_.jpg\" style=\"border: none;\"></a></div><div style=\"line-height:120%; margin-bottom: 10px\" class=\"amazlet-info\"><div style=\"margin-bottom:10px;line-height:120%\" class=\"amazlet-name\"><a target=\"_blank\" href=\"http://www.amazon.co.jp/exec/obidos/ASIN/B00BSPH158/naoyadyndnsor-22/ref=nosim/\" name=\"amazletlink\">入門Chef Solo - Infrastructure as Code</a><div style=\"font-size:80%;margin-top:5px;line-height:120%\" class=\"amazlet-powered-date\">posted with <a target=\"_blank\" href=\"http://www.amazlet.com/\" title=\"amazlet\">amazlet</a> at 13.03.17</div></div><div class=\"amazlet-detail\">伊藤直也 (2013-03-11)<br>売り上げランキング: 14<br></div><div style=\"float: left;\" class=\"amazlet-sub-info\"><div style=\"margin-top: 5px\" class=\"amazlet-link\"><a target=\"_blank\" href=\"http://www.amazon.co.jp/exec/obidos/ASIN/B00BSPH158/naoyadyndnsor-22/ref=nosim/\" name=\"amazletlink\">Amazon.co.jpで詳細を見る</a></div></div></div><div style=\"clear: left\" class=\"amazlet-footer\"></div></div></p><p>がんばりました。原稿＼(^o^)／オワタ</p><h4> Chef Solo 本</h4><p>Chef はサーバー/インフラの状態管理フレームワークです。より単純化して言うならサーバー構築の自動化ツール。コードは Ruby で書きます。ウェブアプリケーションをホストするサーバーの管理にもちろん利用できますし、チームメンバーの開発環境を同じ状態に揃える、あるいは個人の開発環境の整備を自動化する、といったことにも利用できます。</p><p>本書の内容のは、その Chef の入門書です。Chef のインストールに始まり、Chef Solo によるサーバー構成変更の仕方、自動化の方法といった基本的なことを中心に、一緒に使えると便利な仮想サーバーの Vagrant、Chef Solo 実行に便利な knife-solo、Bundler 風に Chef のライブラリ (クックブック) を管理する Berkshelf などの解説も交えています。</p><p>以下、本文から引用です。</p><blockquote><p>筆者がなんでこんな本を書こと思ったかという一つの理由でもありますが、Chef は比較的シンプルで分かりやすいツールのはずなのに学習コストが少々お高め、という印象があります。</p><p>その原因のひとつに、Cookbook、Resource、Attribute、Data Bags、Role、Environment、Provider、LWRP ・・・ など多数の Chef 独自の概念が存在することが挙げられます。公式のドキュメントはいずれの項目についてもしっかりと書かれているのですが、しっかりと書かれているが故に、とりあえず使ってみたいという程度の場合に、どれをどこまで覚える必要があるのかが把握しづらい。</p><p>(中略)</p><p>概念の多さから来る学習コストの上昇カーブを極力抑えて、「とりあえずレシピを書いて Chef で遊べる・管理できる」レベルに最小限の投資で到達できるようにする、というのが本書のねらいです。</p></blockquote><p>先日 Engine Yard さんで開催された <a href=\"http://d.hatena.ne.jp/naoya/20130223/13615830272\">Chef 勉強会に行ったとき</a>に周りの Chef ユーザーのひとたちと話してみたところ、Chef の実行の仕方で躓いている人が散見されたこと、また Chef に関するネット上の情報が(公式ドキュメント以外は) 断片的で偏りがあることなどを感じました。おそらく今年は AWS をはじめとするクラウド (IaaS) が、昨年の勢いを更に増して普及していく年だと思いますが、それに伴う形で Chef のようなフレームワークにもより注目が集まるのではないかと思います。そんなところからこのタイミングで、ある程度の Chef の情報をまとめておくと良いのではないかと思い、もともとKDPで本を書いてみたかったこともあって、電子書籍でそれを形にしてみました。</p><p><a target=\"_blank\" href=\"http://www.amazon.co.jp/exec/obidos/ASIN/B00BSPH158/\" name=\"amazletlink\">Amazon.co.jp から購入可能</a>、890円です。</p><p>Kindle Paperwhite などの各種 Kindle 専用端末はもちろん、iPhone や iPad あるいは Android の Kindle アプリにも対応しています。また、コンテンツは DRM フリーなので購入後に好みのフォーマットに変換して利用することが可能です。(追記: データを更新した影響で一時的に iOS 版への転送が不可能になっています。しばらく時間が経てば再開すると思うので今しばらくお待ち下さい。)</p><h5> Kindle Paperwhite</h5><p><a href=\"http://cdn.bloghackers.net/images/20130313_011212.png\" class=\"http-image\" target=\"_blank\"><img src=\"http://cdn.bloghackers.net/images/20130313_011212.png\" class=\"http-image\" alt=\"http://cdn.bloghackers.net/images/20130313_011212.png\" width=\"400\"></a></p><h5> Kindle for iPad</h5><p><a href=\"http://cdn.bloghackers.net/images/20130313_011115.png\" class=\"http-image\" target=\"_blank\"><img src=\"http://cdn.bloghackers.net/images/20130313_011115.png\" class=\"http-image\" alt=\"http://cdn.bloghackers.net/images/20130313_011115.png\" width=\"540\"></a></p><h5> Kindle for iPhone</h5><p><a href=\"http://cdn.bloghackers.net/images/20130313_011419.png\" class=\"http-image\" target=\"_blank\"><img src=\"http://cdn.bloghackers.net/images/20130313_011419.png\" class=\"http-image\" alt=\"http://cdn.bloghackers.net/images/20130313_011419.png\" width=\"300\"></a></p><h4> 目次</h4><ul><li> #0 はじめに</li><li> #1 Chef とは何かを知りたい ─ Chef Overview</li><li> #2 Chef Solo をインストールして試したい ─ Hello Chef!</li><li> #3 nginx を Chef Solo で立ち上げたい</li><li> #4 Chef Soloの試験環境を3分で用意する ─ Vagrant</li><li> #5 リモートから chef-solo を実行する ─ knife-solo</li><li> #6 レシピを作って実行する流れをおさらいしたい</li><li> #7 サードパーティの Chef クックブックを使いたい</li><li> #8 代表的なレシピのサンプルを見たい ─ td-agent のレシピを読む</li><li> #9 パッケージをインストールする ─ Package</li><li> #10 サービスを起動したい ─ Service と Notification</li><li> #11 テンプレートから設定ファイルを配置したい ─ Template</li><li> #12 ファイルやディレクトリを扱いたい ─ Cookbook File, Directory</li><li> #13 ユーザーを作成したい ─ User, Group</li><li> #14 git レポジトリからファイルを取ってくる ─ Git</li><li> #15 任意のシェルスクリプトを実行したい ─ Execute, Script</li><li> #16 その他の Resource</li><li> #17 レシピ落ち穂拾い ─ run_list, ファイル分け, include_recipe</li><li> #18 Resource を自分で定義したい ─ Definition</li><li> #19 Attribute と Data Bags</li><li> #20 ノードを役割ごとにグルーピングして管理したい ─ Role</li><li> #21 サードパーティのクックブックを Bundler 風に管理したい ─ Berkshelf</li><li> #22 Chef Server の様子を知りたい - 概要からセットアップまで</li><li> #23 どこまでを Chef でやるべきか</li><li> おわりに</li></ul><h4> 出版にあたって</h4><ul><li> 今回 KDP で出版するにあたっては @miyagawa さんに質問したところ、Markdown から epub/mobi への変換のやり方について丁寧にアドバイスしてくれました。</li><li>  @ugtkbtk は原稿をレビューを手伝ってくれました。</li><li>  td-agent のレシピを紹介するにあたってはその掲載を @kzk_mover さんに快諾いただきました。</li><li> 本文中の内容、誤植、誤りといった点は定期的に修正して最新版として随時更新していくつもりです。(実は早速先ほど typo の修正のアップロードを行いました・・・。まだ書影がないのは KDP 既定画像の生成に時間がかかっているからみたいです。)</li><li> 実際にどうやって作ったか、なんかはまた後日エントリしたいと思います。基本は Markdown で書いて github で管理、epub です。</li><li> 今後 Chef 系の勉強会やイベントなんかがあったら是非呼んでください! 本の宣伝しにいきます! </li></ul><p>えー、そんなわけで『<a target=\"_blank\" href=\"http://www.amazon.co.jp/exec/obidos/ASIN/B00BSPH158/\" name=\"amazletlink\">入門Chef Solo - Infrastructure as Code</a>』 ぜひともよろしくお願いします! </p><h4> 追記</h4><p>EPUBファイルを直接欲しい、PDF版が欲しいといったリクエストをいただいています。こちら現在 <a href=\"http://tatsu-zine.com/\">達人出版会</a> さんにお願いして調整中です。少々お待ち下さいませ。</p><h4> 追記#2</h4><p>達人出版会さんからも出ました! PDF/EPUB ファイルが直接欲しい方はこちらからご購入くださいませ。</p><ul><li><a href=\"http://tatsu-zine.com/books/chef-solo\" target=\"_blank\">http://tatsu-zine.com/books/chef-solo</a></li></ul></div>
") (dc:creator nil "naoya") (dc:date nil "2013-03-13T08:05:32+09:00"))))