;; -*- coding: utf-8 -*-
(("Twitter Engineering" "Go under the hood with Twitter's Engineering Team." nil (20813 24330 338347 240000) feed 0 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637") (updated nil "2013-02-28T12:14:18.458-08:00") (category ((term . "opensource ruby java i18n"))) (title ((type . "text")) "Twitter Engineering") (subtitle ((type . "html")) "Go under the hood with Twitter's Engineering Team. ") (link ((rel . "http://schemas.google.com/g/2005#feed") (type . "application/atom+xml") (href . "http://engineering.twitter.com/feeds/posts/default"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/"))) (link ((rel . "hub") (href . "http://pubsubhubbub.appspot.com/"))) (link ((rel . "next") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default?start-index=26&max-results=25"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (generator ((version . "7.00") (uri . "http://www.blogger.com")) "Blogger") (openSearch:totalResults nil "79") (openSearch:startIndex nil "1") (openSearch:itemsPerPage nil "25") (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-7017276850832968138") (published nil "2013-02-28T12:09:00.000-08:00") (updated nil "2013-02-28T12:14:18.467-08:00") (title ((type . "text")) "Drinking from the Streaming API") (content ((type . "html")) "Today we’re open-sourcing the <a href=\"https://github.com/twitter/hbc\">Hosebird Client</a> (hbc) under the <a href=\"https://github.com/twitter/hbc/blob/master/LICENSE\">ALv2 license</a> to provide a robust Java HTTP library for consuming Twitter's <a href=\"https://dev.twitter.com/docs/streaming-apis\">Streaming API</a>. The client is full featured: it offers support for GZip, OAuth and partitioning; automatic reconnections with appropriate backfill counts; access to raw bytes payload; proper retry schemes, and relevant statistics. Even better, it’s been battle-tested in production by our internal teams. We highly recommend you take advantage of the Hosebird Client if you plan on working with the Streaming API.<br />
<br />
<b>Using Hosebird<br />
</b><br />
The Hosebird Client is broken into two main modules: <b>hbc-core</b> and <b>hbc-twitter4j</b>. The hbc-core module uses a simple message queue that a consumer can poll for messages. The hbc-twitter4j module lets you use the superb <a href=\"http://twitter4j.org/\">Twitter4J</a> project and its data model on top of the message queue to provide a parsing layer.<br />
<br />
The first step to use Hosebird is to setup the client using the<span style=\"font-family: Courier New, Courier, monospace;\"> ClientBuilder</span> API:<br />
<br />
<b id=\"internal-source-marker_0.31906672520563006\" style=\"font-weight: normal;\"><span style=\"background-color: white; color: #999988; font-family: Consolas; font-size: 12px; font-style: italic; vertical-align: baseline; white-space: pre-wrap;\">// Create an appropriately sized blocking queue</span><br />
<span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\">BlockingQueue</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">&lt;</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\">String</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">&gt;</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\"> queue </span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">=</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">new</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\"> LinkedBlockingQueue</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">&lt;</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\">String</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">&gt;(</span><span style=\"background-color: white; color: #009999; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\">10000</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">);</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"></span><br />
<span style=\"background-color: white; color: #999988; font-family: Consolas; font-size: 12px; font-style: italic; vertical-align: baseline; white-space: pre-wrap;\">// Authenticate via OAuth</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"></span><br />
<span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">Authentication auth </span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">=</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">new</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> OAuth1</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">consumerKey</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">,</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> consumerSecret</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">,</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> token</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">,</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> secret</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">);</span><span style=\"font-family: Arial; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"></span><br />
<span style=\"background-color: white; color: #999988; font-family: Consolas; font-size: 12px; font-style: italic; vertical-align: baseline; white-space: pre-wrap;\">// Build a hosebird client</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"></span><br />
<span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">ClientBuilder builder </span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">=</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">new</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> ClientBuilder</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">()</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" /> &nbsp;&nbsp;&nbsp;</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">hosts</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\">Constants</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: white; color: teal; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\">STREAM_HOST</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">)</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" /> &nbsp;&nbsp;&nbsp;</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">authentication</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">auth</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">)</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" /> &nbsp;&nbsp;&nbsp;</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">endpoint</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(new</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">StatusesSampleEndpoint</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">()</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">)</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" /> &nbsp;&nbsp;&nbsp;</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">processor</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(new</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> StringDelimitedProcessor</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">queue</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">))</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" /> &nbsp;&nbsp;&nbsp;</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">eventMessageQueue</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">queue</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">);</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" />Client hosebirdClient </span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">=</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> builder</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">build</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">();</span></b><br />
<string><string> <br />
After we have created a <span style=\"font-family: Courier New, Courier, monospace;\">Client</span>, we can connect and process messages:<br />
<br />
<b id=\"internal-source-marker_0.31906672520563006\" style=\"font-weight: normal;\"><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">client</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">connect</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">();</span><br />
<span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">while</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(!</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">client</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">isDone</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">())</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">{</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" /> &nbsp;String message = queue</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">take</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">();</span><br />
<span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;System.out.println(message); // print the message</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">}</span></b><br />
<br />
<b>Hosebird Examples</b><br />
<br />
We recommend you learn from the <a href=\"https://github.com/twitter/hbc/tree/master/hbc-example\">examples</a> on GitHub or contribute your own.<br />
<br />
If you want a quick example, set these properties in <span style=\"font-family: Courier New, Courier, monospace;\">hbc-example/pom.xml:<br />
</span><b id=\"internal-source-marker_0.31906672520563006\" style=\"font-weight: normal;\"><span style=\"font-family: 'Courier New'; font-size: 15px; vertical-align: baseline; white-space: pre-wrap;\">&lt;consumer.key&gt;SECRET&lt;/consumer.key&gt;</span><br />
<span style=\"font-family: 'Courier New'; font-size: 15px; vertical-align: baseline; white-space: pre-wrap;\">&lt;consumer.secret&gt;SECRET&lt;/consumer.secret&gt;</span><br />
<span style=\"font-family: 'Courier New'; font-size: 15px; vertical-align: baseline; white-space: pre-wrap;\">&lt;access.token&gt;SECRET&lt;/access.token&gt;</span><br />
<span style=\"font-family: 'Courier New'; font-size: 15px; vertical-align: baseline; white-space: pre-wrap;\">&lt;acesss.token.secret&gt;SECRET&lt;/acesss.token.secret&gt;</span></b><br />
<br />
Then you can run this command on the command line:<br />
<span style=\"font-family: Courier New, Courier, monospace;\"> mvn exec:java -pl hbc-example</span> <br />
<br />
This will connect to the <a href=\"https://dev.twitter.com/docs/api/1/get/statuses/sample\">sample stream API</a> and print 1000 JSON items from the API.<br />
<br />
Acknowledgements<br />
The Hosebird Client was primarily authored by Steven Liu (<a href=\"https://twitter.com/steven\">@steven</a>) and Kevin Oliver (<a href=\"https://twitter.com/kevino\">@kevino</a>). We’d also like to thank the <a href=\"https://twitter.com/TwitterAPI\">@TwitterAPI</a> team for their thoughtful suggestions and help.<br />
<br />
On behalf of the Hosebird team, <br />
- Chris Aniszczyk, Manager of Open Source (<a href=\"https://twitter.com/cra\">@cra</a>)</string></string>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/7017276850832968138"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/7017276850832968138"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2013/02/drinking-from-streaming-api.html") (title . "Drinking from the Streaming API"))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif"))))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-228421351187252841") (published nil "2013-02-19T12:10:00.000-08:00") (updated nil "2013-02-19T16:46:04.042-08:00") (title ((type . "text")) "Twitter Typeahead.js: You Autocomplete Me") (content ((type . "html")) "Twitter <a href=\"http://twitter.github.com/typeahead.js\">typeahead.js</a> is a fast and battle-tested jQuery plugin for auto completion. Today we’re open sourcing the code on <a href=\"https://github.com/twitter/typeahead.js\">GitHub</a> under the <a href=\"https://github.com/twitter/typeahead.js/blob/master/LICENSE\">MIT license</a>. By sharing a piece of our infrastructure with the open source community, we hope to evolve typeahead.js further with community input.<br />
<br />
<a href=\"http://4.bp.blogspot.com/-vUN5jO5VvfY/USPaIZbU5yI/AAAAAAAAAeU/Tix7jRANNpI/s1600/typeahead+image.png\" imageanchor=\"1\"><img border=\"0\" src=\"http://4.bp.blogspot.com/-vUN5jO5VvfY/USPaIZbU5yI/AAAAAAAAAeU/Tix7jRANNpI/s320/typeahead+image.png\" /></a><br />
<br />
<br />
If your web application needs a fully-featured queryable search box, typeahead.js can help. Some of its capabilities and features include:<br />
<ul><li>Search data on the client, server, or both</li>
<li>Handle multiple inputs on a single page with shared data and caching</li>
<li>Suggest multiple types of data (e.g. searches and accounts) in a single input</li>
<li>Support for international languages, including right-to-left (RTL) and input method editors (IME)</li>
<li>Define custom matching and ranking functions</li>
<li>Grey text hints that help explain what hitting tab will do</li>
</ul><br />
It’s also optimized for large local datasets, so it's fast for high-latency networks.<br />
<br />
<b>Examples</b><br />
<br />
We recommend you take a look at our <a href=\"http://twitter.github.com/typeahead.js/examples/\">examples</a> page. There are three ways to get data:<br />
<br />
Using local, hard-coded data passed on page render:<br />
<br />
<span style=\"font-family: Courier New, Courier, monospace;\">$('#input').typeahead([</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">{</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">name: 'planets',</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">local: [ \"Mercury\", \"Venus\", \"Earth\", \"Mars\", \"Jupiter\", \"Saturn\", \"Uranus\", \"Neptune\" ]</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">}</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">]);</span><br />
<br />
Using a prefetch URL that will be hit to grab data on pageload and then stored in localStorage:<br />
<br />
<span style=\"font-family: Courier New, Courier, monospace;\">$('#input').typeahead([</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">{</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">name: 'countries',</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">prefetch: '/countries.json',</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">}</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">]);</span><br />
<br />
Or using a queryable API that returns results as-you-type (with the query being passed in the ?q= parameter):<br />
<br />
<span style=\"font-family: Courier New, Courier, monospace;\">$('#input').typeahead([</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">{</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">name: 'countries',</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">remote: '/countries.json',</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">}</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">]);</span><br />
<br />
You can also combine local or prefetch with a remote fallback for the performance of local data combined with the coverage of a remote query API (e.g. quickly search your friends but be able to find anyone on your site). There are lots of options for configuring everything from ranking, matching, rendering, templating engines, and more; check out the <a href=\"https://github.com/twitter/typeahead.js#readme\">README</a> for those details.<br />
<br />
If you want to use this with a project like <a href=\"http://twitter.github.com/bootstrap\">Bootstrap</a>, all you have to do is include the JavaScript file for typeahead.js after Bootstrap’s JavaScript file and use our configuration options.<br />
<br />
We initially built typeahead.js to support our needs; now we look forward to improvements and suggestions from the community. To learn more about how typeahead.js works, check out our detailed <a href=\"https://github.com/twitter/typeahead.js#readme\">documentation</a>. To stay in touch, follow <a href=\"https://twitter.com/typeahead\">@typeahead</a> and submit <a href=\"https://github.com/twitter/typeahead.js/issues\">issues</a> on GitHub. Also, if building web application frameworks like typeahead.js interests you, why not consider <a href=\"https://twitter.com/jobs/engineering\">joining the flock</a>?<br />
<br />
<b>Acknowledgements</b><br />
Typeahead.js was primarily authored by Tim Trueman (<a href=\"https://twitter.com/timtrueman\">@timtrueman</a>), Veljko Skarich (<a href=\"https://twitter.com/vskarich\">@vskarich</a>) and Jake Harding (<a href=\"https://twitter.com/jakeharding\">@jakeharding</a>).<br />
<br />
On behalf of the typeahead.js team,<br />
- Chris Aniszczyk, Manager of Open Source (<a href=\"https://twitter.com/cra\">@cra</a>) ") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/228421351187252841"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/228421351187252841"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2013/02/twitter-typeaheadjs-you-autocomplete-me.html") (title . "Twitter Typeahead.js: You Autocomplete Me"))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://4.bp.blogspot.com/-vUN5jO5VvfY/USPaIZbU5yI/AAAAAAAAAeU/Tix7jRANNpI/s72-c/typeahead+image.png") (height . "72") (width . "72")))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-6494524750527558541") (published nil "2013-02-06T11:30:00.000-08:00") (updated nil "2013-02-06T11:30:39.509-08:00") (title ((type . "text")) "New Twitter search results ") (content ((type . "html")) "We just <a href=\"http://blog.twitter.com/2013/02/search-and-discover-improvements-get.html\">shipped a new version of the Twitter app</a> with a brand new search experience that blends the most relevant content - Tweets, user accounts, images, news, related searches, and more - into a single stream of results. This is a major shift from how we have previously partitioned results by type (for instance, Tweet search vs. people search). We think this simplified experience makes it easier to find great content on Twitter using your mobile device. <br />
<br />
A typical search scores items of the same type and picks the top-scoring results. In a blended search experience, this is not straightforward. The scores of different content types are computed by different services, and thus not directly comparable for blending. Another challenge is to decide which type of content to mix, as not all content types are always desirable to display. This post discusses our approach to solving these challenges.<br />
<br />
<b>Ranking<br />
</b> <br />
When a user searches, different types of content are searched separately, returning a sequence of candidate results for each content type with a type-specific score for each. For certain content types that are displayed as a single group or gallery unit, such as users or images, we assign the maximum score of results as the representative score of this content type. The result sequences for some content types may be trimmed or discarded entirely at this point.<br />
<br />
Once results of different content types are prepared, each type-specific score is converted into a universally compatible score, called a “uniscore”. Uniscores of different modules are used as a means to blend content types as in a merge-sort, except for the penalization of content type transition. This is to avoid over-diversification of content types in the blended result.<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://3.bp.blogspot.com/-McCkggNJrU0/URKuInWEznI/AAAAAAAAAeE/pNNT8WnWwx8/s1600/Fig%2B1.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"203\" src=\"http://3.bp.blogspot.com/-McCkggNJrU0/URKuInWEznI/AAAAAAAAAeE/pNNT8WnWwx8/s400/Fig%2B1.png\" width=\"400\" /></a></div><span style=\"font-size: x-small;\"><i>Fig. 1: Search ranker chose News1 followed by Tweet1 so far and is presented with three candidatesTweet2, User Group, and News2 to pick the content after Tweet1. News2 has the highest uniscore but search ranker picks Tweet2, instead of News2 as we penalize change in type between consecutive content by decreasing the score of News2 from 0.65 to 0.55, for instance.<br />
</i> </span><br />
<br />
<b>Score unification<br />
</b> <br />
Individual content is assigned a type-specific score, which is called a “raw” score, by its corresponding service. To facilitate blending and ranking content of different types as described above, raw scores are converted into uniscores using type-specific log-linear score conversion functions – where the chance of a converted score to take its value in [0, 1] is at least 95%, as estimated from observed dataset.<br />
<br />
<b>Content selection and boosting<br />
</b> <br />
Certain types of content may not have many relevant items to show for a particular input query, in which case we may choose not to include this type of content in search results. In other cases, for instance if query volume or matched item counts have an unusual spike (what we call a “burst”), we show this type and may also boost it to appear at a higher place in the results. To facilitate this, we represent trends in searches or matching result counts as a single number that is proportional to the level of “burstiness”.<br />
<br />
For example, consider measuring “burstiness” for the number of images and news content matching the query “photos”. We first obtain three sequences of term frequencies, e.g. :<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://3.bp.blogspot.com/-8RGFpYCO0eU/URKtx5XfFBI/AAAAAAAAAd0/RnDQO0Ysc6g/s1600/Fig%2B2.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"223\" src=\"http://3.bp.blogspot.com/-8RGFpYCO0eU/URKtx5XfFBI/AAAAAAAAAd0/RnDQO0Ysc6g/s400/Fig%2B2.png\" width=\"400\" /></a></div><i><span style=\"font-size: x-small;\">Fig. 2 : Three sequences of number of Tweets over eight 15 minute buckets from bucket 1 (2 hours ago) to 8 (most recent).<br />
Tweet : counts of Tweets that match query “photos”.<br />
Image : counts of Tweets that match query “photos” and contain image links.<br />
News : counts of Tweets that match query “photos” and contain news links.<br />
Query “photos” is shown not only to match Tweets with image links more than those with news links but also is increasing over time.</span></i><br />
<br />
Our approach to compute the burstiness of image and news facets is an extension of original work by Jon Kleinberg on bursty structure detection, which is in essence matching current level of burst to one of a predefined set of bursty states, while minimizing too diverse a change in matched states for smooth estimation [1].<br />
<br />
In our extension, burstiness of mixable content types including images, users, news, and tweets are computed simultaneously to reflect relative difference in bursty levels between different types and used the distance of observed rate from each state’s bursty level as state cost. This is because accurately estimating probability of occurrence is infeasible for real-time estimation due to expensive computational cost and possible introduction of zero intervals between probability states due to numerical approximation. Optimal state sequences for images and news are estimated as shown in Fig 3.<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://1.bp.blogspot.com/-LaEnOU0Rkms/URKtqth29GI/AAAAAAAAAdo/wWnnvrvAaCA/s1600/Fig%2B3.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"193\" src=\"http://1.bp.blogspot.com/-LaEnOU0Rkms/URKtqth29GI/AAAAAAAAAdo/wWnnvrvAaCA/s400/Fig%2B3.png\" width=\"400\" /></a></div><i><span style=\"font-size: x-small;\">Fig. 3 : Normalized image and news counts are matched to one of n=5 states : 1 average, 2 above, and 2 below.  Matched states curves show a more stable quantization of original sequence which has the effect of removal of small noisy peaks.</span><br />
</i> <br />
<br />
Finally, burstiness of each content type is computed as an exponential moving average of state IDs in the optimal state sequence. As shown in Fig. 3, jointly optimizing the sum of state cost and transition cost yields a smooth quantization of original sequence, which automatically filters out small noisy peaks in original counts. Also, this maps both trending (bursty) and steadily high sequences to a high burstiness value.<br />
<br />
Burstiness computed this way is used to filter out content types with low or no bursts. It’s also used to boost the score of corresponding content types, as a feature for a multi-class classifier that predicts the most likely content type for a query, and in additional components of the ranking system.<br />
<br />
<b>References<br />
</b><br />
[1] J. Kleinberg, Bursty and Hierarchical Structure in Streams, Proc. 8th ACM SIGKDD Intl. Conf. on Knowledge Discovery and Data Mining, 2002. (<a href=\"http://www.cs.cornell.edu/home/kleinber/bhs.pdf\">PDF</a>)<br />
<br />
Posted by <a href=\"http://twitter.com/glassyocean\">Youngin Shin</a><br />
Search-Quality Team") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6494524750527558541"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6494524750527558541"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2013/02/new-twitter-search-results.html") (title . "New Twitter search results "))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://3.bp.blogspot.com/-McCkggNJrU0/URKuInWEznI/AAAAAAAAAeE/pNNT8WnWwx8/s72-c/Fig%2B1.png") (height . "72") (width . "72")))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-4185766333414693779") (published nil "2013-01-31T08:50:00.000-08:00") (updated nil "2013-01-31T08:50:18.943-08:00") (title ((type . "text")) "Introducing Flight: a web application framework") (content ((type . "html")) "Last year we rolled out a <a href=\"http://engineering.twitter.com/2012/05/improving-performance-on-twittercom.html\">major reimplementation</a> of the Twitter website. In addition to shifting the rendering of our page content to the server (which achieved significant performance gains), we re-envisioned the entire client-side infrastructure with a clean, robust and easy-to-learn framework which we call <a href=\"http://twitter.github.com/flight/\">Flight</a>. Today we're making Flight available to the open source community under the liberal <a href=\"https://github.com/twitter/flight/blob/master/LICENSE\">MIT license</a> as a framework for structuring web applications. <br />
<br />
Whether you use Flight as the JavaScript framework for your next web project, or just as source for new ideas, we look forward to learning from diverse perspectives via community feedback and contributions on <a href=\"https://github.com/twitter/flight\">GitHub</a>.<br />
<br />
<b><span style=\"font-size: large;\">Why Flight?<br />
</span></b><br />
Flight is distinct from existing frameworks in that it doesn't prescribe or provide any particular approach to rendering or providing data to a web application. It's agnostic on how requests are routed, which templating language you use, or even if you render your HTML on the client or the server. While some web frameworks encourage developers to arrange their code around a prescribed model layer, Flight is organized around the existing DOM model with functionality mapped directly to DOM nodes.<br />
<br />
Not only does this obviate the need for additional data structures that will inevitably influence the broader architecture, but by mapping our functionality directly onto the native web we get to take advantage of native features. For example, we get custom event propagation for free by piggybacking off DOM event bubbling, and our event handling infrastructure works equally well with both native and custom events.<br />
<br />
<b><span style=\"font-size: large;\">How does it work?<br />
</span></b><br />
Flight enforces strict separation of concerns. When you create a component you don't get a handle to it. Consequently, components cannot be referenced by other components and cannot become properties of the global object tree. This is by design. Components do not engage each other directly; instead, they broadcast their actions as events which are subscribed to by other components. <br />
<br />
<b>Why events?<br />
</b><br />
Events are open-ended. When a component triggers an event, it has no knowledge of how its request will be satisfied or by whom. This enforced decoupling of functionality allows the engineer to consider each component in isolation rather than having to reason about the growing complexity of the application as a whole.<br />
<br />
By making DOM node events proxies for component events, we let the web work for us:<br />
<br />
<ul><li>we get event propagation for free</li>
<li>a component can subscribe to a given event type at the document level or it can choose to listen only those events originating from within a specified DOM Node</li>
<li>subscribing components do not distinguish between custom events from other components (e.g. 'dataMailItemsServed') and native DOM node events (e.g. 'click'), and process both types of event in an identical fashion.</li>
</ul><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://3.bp.blogspot.com/-kOtb8efsqvs/UQqgWfqxXhI/AAAAAAAAAdI/2lNVUu3dIyU/s1600/ss1.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"292\" width=\"400\" src=\"http://3.bp.blogspot.com/-kOtb8efsqvs/UQqgWfqxXhI/AAAAAAAAAdI/2lNVUu3dIyU/s400/ss1.png\" /></a></div><br />
<b>Mobility and testing<br />
</b><br />
Each component is a module that, aside from a minimal set of standard dependencies (relevant Flight utilities and mixins), has no reference to the outside world. Thus a given component will respond to a given event in the same way, regardless of environment. This makes testing simple and reliable — events are essentially the only variable, and a production event is easy to replicate in testing. You can even debug a component by triggering events in the console.<br />
<br />
<b>Mixins<br />
</b><br />
A mixin defines a set of functionality that is useful to more than one object. Flight comes with built-in support for <a href=\"http://javascriptweblog.wordpress.com/2011/05/31/a-fresh-look-at-javascript-mixins/\">functional mixins</a>, including protection against unintentional overrides and duplicate mixins. While classical JavaScript patterns support only single inheritance, a component prototype (or other object) can have multiple mixins applied to it. Moreover, mixins requires a fraction of the boilerplate required to form traditional classical hierarchies out of constructor-prototypes hybrids, and don't suffer the leaky abstractions of the latter ('super', 'static', 'const' etc.)<br />
<br />
<b><span style=\"font-size: large;\">Documentation and demo<br />
</span></b><br />
Our GitHub page includes <a href=\"https://github.com/twitter/flight/blob/master/README.md\">full documentation</a> as well as a <a href=\"https://github.com/twitter/flight/tree/gh-pages/demo\">sample app</a> in the form of an <a href=\"http://twitter.github.com/flight/demo/\">email client</a>:<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-jG6yq1qafBc/UQqgcn9JrsI/AAAAAAAAAdU/IqsPjTLGg1Q/s1600/ss2.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"164\" width=\"400\" src=\"http://4.bp.blogspot.com/-jG6yq1qafBc/UQqgcn9JrsI/AAAAAAAAAdU/IqsPjTLGg1Q/s400/ss2.png\" /></a></div><br />
<b><span style=\"font-size: large;\">Future work<br />
</span></b><br />
Flight is an ongoing and evolving project. We’re planning to add a full testing framework and make available more of the utilities that we use for the Twitter website frontend. We also look forward to your contributions and comments. We know we haven’t thought of everything, and with your help we can continue to improve Flight for the benefit of everyone.  <br />
<br />
<b><span style=\"font-size: large;\">Acknowledgments<br />
</span></b><br />
Flight was a group effort. These folks have contributed to the project: Angus Croll (<a href=\"https://twitter.com/angustweets\">@angustweets</a>), Dan Webb (<a href=\"https://twitter.com/danwrong\">@danwrong</a>), Kenneth Kufluk (<a href=\"https://twitter.com/kpk\">@kpk</a>), along with other members the Twitter web team. A special thank you to <a href=\"https://github.com/twitter/flight#authors\">folks in the web community</a> who took the time to review the code.<br />
<br />
On behalf of the Web Core team,<br />
— Angus Croll, Engineer (<a href=\"https://twitter.com/angustweets\">@angustweets</a>)") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/4185766333414693779"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/4185766333414693779"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2013/01/introducing-flight-web-application.html") (title . "Introducing Flight: a web application framework"))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://3.bp.blogspot.com/-kOtb8efsqvs/UQqgWfqxXhI/AAAAAAAAAdI/2lNVUu3dIyU/s72-c/ss1.png") (height . "72") (width . "72")))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-1769042099084361630") (published nil "2013-01-28T15:28:00.000-08:00") (updated nil "2013-01-28T15:28:25.958-08:00") (title ((type . "text")) "Braindump") (content ((type . "html")) "<h2 style=\"background-color: white; color: black; display: inline; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<span style=\"font-size: small;\"><i><span style=\"font-family: &quot;Helvetica Neue&quot;,Arial,Helvetica,sans-serif;\"><span style=\"font-weight: normal;\">Cross-posted from <a href=\"http://blog.oskarsson.nu/post/40196324612/the-twitter-stack\">@skr's blog</a>.&nbsp; </span></span></i></span></h2>
<br />
<br />
<h2 style=\"background-color: white; color: black; display: inline; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<span style=\"font-family: &quot;Helvetica Neue&quot;,Arial,Helvetica,sans-serif;\">The Twitter stack</span></h2>
<br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
For various reasons, including performance and cost, Twitter has poured significant engineering effort into breaking down the site backend into smaller JVM based services. As a nice side effect we’ve been able to open source several of the libraries and other useful tools that came out of this effort.</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
While there is a fair amount of information about these projects available as docs or slides I found no simple, high level introduction to what we can unofficially call the Twitter stack. So here it is. It’s worth noting that all this information is about open source projects, that it is public already and that I am not writing this as part of my job at Twitter or on their behalf.</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Now, granted these were not all conceived at Twitter and plenty of other companies have similar solutions. However I think the software mentioned below is quite powerful and with most of it released as open source it is a fairly compelling platform to base new services off of.</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
I will describe the projects from a Scala perspective, but quite a few are useful in Java programs as well. See the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://twitter.github.com/scala_school/\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Twitter Scala</a><span class=\"Apple-converted-space\">&nbsp;</span>school for an intro to the language, although that is not required to understand this post.</div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Finagle</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
At the heart of a service lies the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/finagle\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Finagle</a><span class=\"Apple-converted-space\">&nbsp;</span>library. By abstracting away the fundamental underpinnings of an RPC system, Finagle greatly reduces the complexity that service developers have to deal with. It allows us to focus on writing application-specific business logic instead of dwelling on lower level details of distributed systems. Ultimately the website itself uses these services to perform operations or fetch data needed to render the HTML. At Twitter the internal services use the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://thrift.apache.org/\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Thrift</a><span class=\"Apple-converted-space\">&nbsp;</span>protocol, but Finagle supports other protocols too such as Protocol buffers and HTTP.<br />
<br />
<b style=\"font-style: normal; font-weight: 700;\">Setting up a service using Finagle</b><br />
A quick dive into how you would set up a Thrift service using Finagle.</div>
<ol style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; list-style: decimal; margin: 10px 0px 10px 30px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<li style=\"margin: 0px; padding: 0px;\">Write a Thrift file defining your API. It should contain the structs, exceptions and methods needed to describe the service functionality. See<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://thrift.apache.org/docs/idl/\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Thrift Interface Description Language (IDL) docs</a>, in particular the examples at the end for more info.</li>
<li style=\"margin: 0px; padding: 0px;\">Use the Thrift file as input for a code generator that spits out code in your language. For Scala and Finagle based projects I would recommend<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/scrooge\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Scrooge</a>.</li>
<li style=\"margin: 0px; padding: 0px;\">Implement the Scala trait generated from your Thrift IDL. This is where the actual functionality of your service goes.</li>
<li style=\"margin: 0px; padding: 0px;\">Provide the Finagle server builder an instance of the implementation above, a port to bind to and any other settings you might need and start it up.</li>
</ol>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<br />
That looks pretty similar to just using plain Thrift without Finagle. However, there are quite a few improvements such as excellent monitoring support, tracing and Finagle makes it easy to write your service in an asynchronous fashion. More about these features later.<br />
<br />
You can also use Finagle as a client. It takes care of all the boring stuff such as timeouts, retries and load balancing for you.</div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Ostrich</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
So let’s say we have a Finagle Thrift service running. It’s doing very important work. Obviously you want to make sure it keeps doing that work and that it performs well. This is where<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/ostrich\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Ostrich</a><span class=\"Apple-converted-space\">&nbsp;</span>comes in.<br />
<br />
<b style=\"font-style: normal; font-weight: 700;\">Metrics</b><br />
Ostrich makes it easy to expose various metrics from your service. Let’s say you want to count how many times a particular piece of code is run. In your service you’d write a line of code that looks something like this:<br />
<br />
<code style=\"font-family: Monaco, 'Andale Mono', 'Liberation Mono', 'Courier New', monotype; font-size: 11px; font-style: normal; font-variant: normal; font-weight: normal; line-height: normal;\">Stats.incr(“some_important_counter”)</code><br />
<br />
As simple as that. The counter named some_important_counter will be incremented by 1.<span class=\"Apple-converted-space\">&nbsp;</span><br />
<br />
In addition to just straight up counters you can get gauges that report on the value of a variable:<br />
<br />
<code style=\"font-family: Monaco, 'Andale Mono', 'Liberation Mono', 'Courier New', monotype; font-size: 11px; font-style: normal; font-variant: normal; font-weight: normal; line-height: normal;\">Stats.addGauge(\"current_temperature\") { myThermometer.temperature }</code><br />
<br />
or you can time a snippet of code to track the performance<br />
<br />
<code style=\"font-family: Monaco, 'Andale Mono', 'Liberation Mono', 'Courier New', monotype; font-size: 11px; font-style: normal; font-variant: normal; font-weight: normal; line-height: normal;\">Stats.time(\"translation\") {<br />
&nbsp;document.translate(\"de\", \"en\")<br />
}</code><br />
<br />
Those and other examples can be found in the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/ostrich\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Ostrich readme</a>.<br />
<br />
<b style=\"font-style: normal; font-weight: 700;\">Export metrics</b><br />
Ostrich runs a small http admin interface to expose these metrics and other functionality. To fetch them you would simply hit http://hostname:port/stats.json to get the current snapshot of the metrics as JSON. At Twitter the stats from each service will be ingested from Ostrich by our internal observability stack, providing us with fancy graphs, alerting and so on.<br />
<br />
To tie this back to our previous section: If you provide a Finagle client or server builder with an Ostrich backed StatsReceiver it’ll happily splurt out tons of metrics about how the service is performing, the latencies for the RPC calls and the number of calls to each method to name a few.<br />
<br />
Ostrich can also deal with configuring your service, shutting down all the components gracefully and more.</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<br />
<img height=\"415px;\" src=\"https://lh4.googleusercontent.com/erHY9IvhEPTsi8rcfTc_dN38Fooa-fyN-N_YHCW3XR0WDtd8K9aGsQwXyH4bRwXWniWcesbpi37uQ9RDtEh45EC2XzlsEAjN3p7twM7THqrM3pdTEoY\" style=\"border: 0px;\" width=\"595px;\" /><br />
This is an example of what a dashboard could look like with stats gathered from Ostrich by our observability stack. Screenshot from @raffi’s<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://www.slideshare.net/raffikrikorian/realtime-systems-at-twitter\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">presentation</a><span class=\"Apple-converted-space\">&nbsp;</span>deck.<br />
<br /></div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Zipkin</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Ostrich and Finagle combined gives us good service level metrics. However, one downside of a more service oriented architecture is that it’s hard to get a high level performance overview of a single request throughout the stack.<br />
Perhaps you are a developer tasked with improving performance of a particular external api endpoint. With Zipkin you can get a visual representation of where most of the time to fulfill the request was spent. Think Firebug or Chrome developer tools for the back end.<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/zipkin/\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Zipkin</a><span class=\"Apple-converted-space\">&nbsp;</span>is a implementation of a tracing system based off of the Google Dapper paper.<br />
<br />
<b style=\"font-style: normal; font-weight: 700;\">Finagle-Zipkin</b><br />
So how does it work? There’s a<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/finagle/tree/master/finagle-zipkin\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">finagle-zipkin</a><span class=\"Apple-converted-space\">&nbsp;</span>module that will hook into the transmission logic of Finagle and time each operation performed by the service. It also passes request identifiers down to any services it relies on, this is how we can tie all the tracing data together. The tracing data is logged to the Zipkin backend and finally we can display and visualize that data in the Zipkin UI.<br />
<br />
Let’s say we use Zipkin to inspect a request and we see that it spent most of it’s time waiting for a query to a MySQL database. We could then also see the actual SQL query sent and draw some conclusions from it. Other times perhaps a GC in a Scala service was a fault. Either way, the hope is that a glance at the trace view will reveal where the developer should spend effort improving performance.<br />
<br />
Enabling tracing for Finagle services is often as simple as adding</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<code style=\"font-family: Monaco, 'Andale Mono', 'Liberation Mono', 'Courier New', monotype; font-size: 11px; font-style: normal; font-variant: normal; font-weight: normal; line-height: normal;\">.tracerFactory(ZipkinTracer())</code></div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
to your ClientBuilder or ServerBuilder. Setting up the whole Zipkin stack is a bit more work though, check out the docs for further assistance.</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<br />
<img height=\"334px;\" src=\"https://lh4.googleusercontent.com/LtHgQzXNOwMGI-2O1mVV_c3gklOziYL99p6Nbg6A2RbnkC7c5OMkHipHcc3KZE2jPg30_VXAy3axWpyben4Nndo8DKCnwOnX2HQbsiBPP9mDmnNjRl8\" style=\"border: 0px;\" width=\"614px;\" /><br />
Trace view, taken from my Strange loop<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://www.slideshare.net/johanoskarsson/zipkin-strangeloop\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">talk</a><span class=\"Apple-converted-space\">&nbsp;</span>about Zipkin.</div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Mesos</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<a href=\"http://incubator.apache.org/mesos/\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Mesos</a><span class=\"Apple-converted-space\">&nbsp;</span>describes itself as “a cluster manager that provides efficient resource isolation and sharing across distributed applications, or frameworks”. I’ll try to go through this section without using buzzwords such as “private cloud”, although technically I just did.<br />
<br />
The core Mesos project is an open source Apache incubator project. On top of it you can run schedulers that deal with more specific technologies, for example Storm and Hadoop. The idea being that the same hardware can be used for multiple purposes, reducing wasted resources.<br />
<br />
In addition to using<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://storm-project.net/\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Storm</a><span class=\"Apple-converted-space\">&nbsp;</span>on top of Mesos we deploy some of our JVM-based services to internal Mesos clusters. With the proper configuration it takes care of concerns such as rack diversity, rescheduling if a machine goes down and so on.<span class=\"Apple-converted-space\">&nbsp;</span><br />
<br />
The constraints imposed by Mesos have the positive side effect of enforcing adherence to various good distributed systems practices. For example:</div>
<ul style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; list-style: disc; margin: 10px 0px 10px 30px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<li style=\"margin: 0px; padding: 0px;\">Service owners shouldn’t make any assumptions about jobs’ lifetimes, as the Mesos scheduler can move jobs to new hosts at any time.</li>
<li style=\"margin: 0px; padding: 0px;\">Jobs shouldn’t write to local disk, since persistence is not guaranteed.</li>
<li style=\"margin: 0px; padding: 0px;\">Deploy tooling and configs shouldn’t use static server lists, since Mesos implies deployment to a dynamic environment.</li>
</ul>
<br />
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Iago</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Before putting your new service into production you might want to check how it performs under load. That’s where<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/iago\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Iago</a><span class=\"Apple-converted-space\">&nbsp;</span>(formerly Parrot) comes in handy. It’s a load testing framework that is pretty easy to use.<br />
<br />
The process might look something like this:</div>
<ol style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; list-style: decimal; margin: 10px 0px 10px 30px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<li style=\"margin: 0px; padding: 0px;\">Collect relevant traffic logs that you want to use as the basis for your load test.</li>
<li style=\"margin: 0px; padding: 0px;\">Write a configuration file for the test. It contains the hostnames to send load to, the number of requests per second, the load pattern and so on.</li>
<li style=\"margin: 0px; padding: 0px;\">Write the actual load test. It receives a log line, you transform that into a request to a client.</li>
<li style=\"margin: 0px; padding: 0px;\">Run the load test. At Twitter this will start up a few tasks in a Mesos cluster, send the traffic and log metrics.</li>
</ol>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<br />
<b style=\"font-style: normal; font-weight: 700;\">Example</b><br />
A load test class could be as simple as this:<br />
<br />
<code style=\"font-family: Monaco, 'Andale Mono', 'Liberation Mono', 'Courier New', monotype; font-size: 11px; font-style: normal; font-variant: normal; font-weight: normal; line-height: normal;\">class LoadTest(parrotService: ParrotService[ParrotRequest, Array[Byte]]) extends <br />
&nbsp;ThriftRecordProcessor(parrotService) {<br />
<br />
&nbsp;val client = new YourService.FinagledClient(service, new TBinaryProtocol.Factory())<br />
<br />
&nbsp;def processLines(job: ParrotJob, lines: Seq[String]) {<br />
&nbsp;&nbsp;&nbsp;lines foreach {line =&gt;client.doSomething(line) }<br />
&nbsp;}<br />
}<span class=\"Apple-converted-space\">&nbsp;</span></code><br />
<br />
This class will feed each log line to your service’s doSomething method, according to the parameters defined in the configuration of parrotService.</div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
ZooKeeper</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
ZooKeeper is an Apache project that is handy for all kinds of distributed systems coordination.<span class=\"Apple-converted-space\">&nbsp;</span><br />
<br />
One use case for ZooKeeper within Twitter is service discovery. Finagle services register themselves in ZooKeeper using our ServerSet library, see<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/finagle/tree/master/finagle-serversets\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">finagle-serversets</a>. This allows clients to simply say they’d like to communicate with “the production cluster for service a in data centre b” and the ServerSet implementation will ensure an up-to-date host list is available. Whenever new capacity is added the client will automatically be aware and will start load balancing across all servers.<br />
<br /></div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Scalding</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
From the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/scalding\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Scalding</a><span class=\"Apple-converted-space\">&nbsp;</span>github page: “Scalding is a Scala library that makes it easy to write MapReduce jobs in Hadoop. Instead of forcing you to write raw map and reduce functions, Scalding allows you to write code that looks like natural Scala”.<br />
<br />
As it turns out services that receive a lot of traffic generate tons of log entries. These can provide useful insights into user behavior or perhaps you need to transform them to be suitable as Iago load test input.<br />
<br />
I have to admit I was a bit sceptical about Scalding at first. It seemed there were already plenty of ways to write Hadoop jobs. Pig, Hive, plain MapReduce, Cascading and so on. However, when the rest of your project is in Scala it is very handy to be able to write Hadoop jobs in the same language. The syntax is often very close to the one used by Scala’s collection library, so you feel right at home, the difference being that with Scalding you might process terabytes of data with the same lines of code.<br />
<br />
A simple word count example from their tutorial:</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
&nbsp;<span class=\"Apple-converted-space\">&nbsp;</span><code style=\"font-family: Monaco, 'Andale Mono', 'Liberation Mono', 'Courier New', monotype; font-size: 11px; font-style: normal; font-variant: normal; font-weight: normal; line-height: normal;\">TextLine(args(\"input\"))<br />
&nbsp;&nbsp;&nbsp;.read<br />
&nbsp;&nbsp;&nbsp;.flatMap('line -&gt; 'word){ line : String =&gt; line.split(\"\\\\s\")}<br />
&nbsp;&nbsp;&nbsp;.groupBy('word){group =&gt; group.size}<br />
&nbsp;&nbsp;&nbsp;.write(Tsv(args(\"output\")))</code></div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
jvmgcprof</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
One of the well known downsides of relying on the JVM for time sensitive requests is that garbage collection pauses could ruin your day. If you’re unlucky a GC pause might hit at the wrong time, causing some requests to perform poorly or even timeout. Worst case that might have knock on effects that leads to downtime.<br />
<br />
As a first line of defence against GC issues you should of course tweak your JVM startup parameters to suit the kind of work the service is undertaking. I’ve found these<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://www.slideshare.net/aszegedi/everything-i-ever-learned-about-jvm-performance-tuning-twitter\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">slides</a><span class=\"Apple-converted-space\">&nbsp;</span>from Twitter alumni Attila Szegedi extremely helpful.<br />
<br />
Of course, you could minimize GC issues by reducing the amount of garbage your service generates. Start your service with jvmgcprof and it’ll help you reach that goal. If you already use Ostrich to track metrics in your service you can tell jvmgcprof which metric represents the work completed. For example you might want to know how many kilobytes of garbage is generated per incoming Thrift request. The jvmgcprof output for that could look something like this.<br />
<br />
2797MB w=101223 (231MB/s 28kB/w)<br />
50.00% &nbsp;8 &nbsp;&nbsp;297<br />
90.00% &nbsp;14 &nbsp;542<br />
95.00% &nbsp;15 &nbsp;572<br />
99.00% &nbsp;61 &nbsp;2237<br />
99.90% &nbsp;2620 &nbsp;&nbsp;&nbsp;94821<br />
99.99% &nbsp;2652 &nbsp;&nbsp;&nbsp;95974<br />
<br />
On the first line you can see that the number requests or work were 101223 for the period monitored, with 231MB/s of garbage or 28kB per request. The garbage per request can easily be compared after changes has been made to see if they had a positive or negative impact on garbage generation. See the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/jvmgcprof\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">jvmgcprof readme</a><span class=\"Apple-converted-space\">&nbsp;</span>for more information.</div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Summary</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
It’s no surprise, but it turns out that having a common stack is very beneficial. Improvements and bug fixes made by one team will benefit others. There is of course another side to that coin, sometimes bugs are introduced that might just be triggered in your service. However, as an example, when developing Zipkin it was immensely helpful to be able to assume that everyone used Finagle. That way they would get tracing for free once we were done.<br />
<br />
I have left out some of the benefits of the Twitter stack and how we use Scala, such as the very convenient way Futures allow you to deal with results from asynchronous requests. I hope to write a more in depth post on how to set up a Twitter style service that would deal with the details omitted in this article. In the meantime you can check out the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://twitter.github.com/scala_school/\">Scala school</a><span class=\"Apple-converted-space\">&nbsp;</span>for more information.<br />
<br />
Thanks to everyone who worked on the projects mentioned in this article, too many to name but you know who you are.<br />
<br />
Posted by <a href=\"https://twitter.com/skr\">Johan Oskarsson</a></div>
") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/1769042099084361630"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/1769042099084361630"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2013/01/braindump.html") (title . "Braindump"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif"))))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-264900056363370138") (published nil "2013-01-08T12:30:00.001-08:00") (updated nil "2013-01-08T14:08:33.443-08:00") (title ((type . "text")) "Improving Twitter search with real-time human computation") (content ((type . "html")) "One of the magical things about Twitter is that it opens a window to the world in <i>real-time</i>. An event happens, and seconds later, people share it across the planet.<br />
<p>Consider, for example, what happened when Flight 1549 crashed in the Hudson River: <br />
<p><blockquote class=\"twitter-tweet\"><a href=\"http://twitpic.com/135xa\">http://twitpic.com/135xa</a> - There's a plane in the Hudson. I'm on the ferry going to pick up the people. Crazy.<br />
— Janis Krums (@jkrums) <a data-datetime=\"2009-01-15T20:36:04+00:00\" href=\"https://twitter.com/jkrums/status/1121915133\">January 15, 2009</a></blockquote><script async=\"async\" charset=\"utf-8\" src=\"//platform.twitter.com/widgets.js\"></script><br />
Or when Osama bin Laden was killed:<br />
<br />
<blockquote class=\"twitter-tweet\">Helicopter hovering above Abbottabad at 1AM (is a rare event).<br />
— Sohaib Athar (@ReallyVirtual) <a data-datetime=\"2011-05-01T19:58:24+00:00\" href=\"https://twitter.com/ReallyVirtual/status/64780730286358528\">May 1, 2011</a></blockquote><script async=\"async\" charset=\"utf-8\" src=\"//platform.twitter.com/widgets.js\"></script><br />
Or when Obama was re-elected:<br />
<br />
<blockquote class=\"twitter-tweet\">Four more years. <a href=\"http://t.co/bAJE6Vom\" title=\"http://twitter.com/BarackObama/status/266031293945503744/photo/1\">twitter.com/BarackObama/st…</a><br />
— Barack Obama (@BarackObama) <a data-datetime=\"2012-11-07T04:16:18+00:00\" href=\"https://twitter.com/BarackObama/status/266031293945503744\">November 7, 2012</a></blockquote><script async=\"async\" charset=\"utf-8\" src=\"//platform.twitter.com/widgets.js\"></script><br />
When each of these events happened, people <i>instantly</i> came to Twitter, and in particular searched on Twitter to discover what was happening.<br />
<p>From a search and advertising perspective, however, these sudden events pose several challenges:<br />
<ol><li>The queries people perform have probably never before been seen, so it's impossible to know without very specific context what they mean. How would you know that #bindersfullofwomen refers to politics, and not office accessories, or that people searching for \"horses and bayonets\" are interested in the Presidential debates?<br />
<br />
<li>Since these spikes in search queries are so <a href=\"http://arxiv.org/abs/1205.6855\">short-lived</a>, there’s only a small window of opportunity to learn what they mean.<br />
</ol>So an event happens, people instantly come to Twitter to search for the event, and we need to teach our systems what these queries mean as quickly as we can — because in just a few hours, the search spike will be gone. <p>How do we do this? We’ve built a real-time human computation engine to help us identify search queries as soon as they're trending, send these queries to real humans to be judged, and then incorporate the human annotations into our back-end models.  <p><b>Overview</b> <p>Before we delve into the details, here's an overview of how the system works.  <ol><li>First, we monitor for which search queries are currently popular.<br />
Behind the scenes: we run a <a href=\"http://engineering.twitter.com/2011/08/storm-is-coming-more-details-and-plans.html\">Storm</a> topology that tracks statistics on search queries.<br />
For example, the query [Big Bird] may suddenly see a spike in searches from the US.<br />
<br />
<li>As soon as we discover a new popular search query, we send it to our human evaluators, who are asked a variety of questions about the query.<br />
Behind the scenes: when the Storm topology detects that a query has reached sufficient popularity, it connects to a Thrift API that dispatches the query to Amazon's Mechanical Turk service, and then polls Mechanical Turk for a response.<br />
For example: as soon as we notice \"Big Bird\" spiking, we may ask judges on Mechanical Turk to categorize the query, or provide other information (e.g., whether there are likely to be interesting pictures of the query, or whether the query is about a person or an event) that helps us serve relevant Tweets and ads.<br />
<br />
<li>Finally, after a response from an evaluator is received, we push the information to our backend systems, so that the next time a user searches for a query, our machine learning models will make use of the additional information. For example, suppose our evaluators tell us that [Big Bird] is related to politics; the next time someone performs this search, we know to surface ads by @barackobama or @mittromney, not ads about Dora the Explorer.<br />
</ol><b>Monitoring for popular queries</b>  <p><a href=\"https://github.com/nathanmarz/storm\">Storm</a> is a distributed system for real-time computation. In contrast to <i>batch</i> systems like Hadoop, which often introduce delays of hours or more, Storm allows us to run online data processing algorithms to discover search spikes as soon as they happen.  In brief, running a job on Storm involves creating a Storm topology that describes the processing steps that must occur, and deploying this topology to a Storm cluster. A topology itself consists of three things: <ol><li><i>Tuple streams</i> of data. In our case, these may be tuples of (search query, timestamp).<br />
<br />
<li><i>Spouts</i> that produce these tuple streams. In our case, we attach spouts to our search logs, which get written to every time a search occurs.<br />
<br />
<li><i>Bolts</i> that process tuple streams. In our case, we use bolts for operations like updating total query counts, filtering out non-English queries, and checking whether an ad is currently being served up for the query.<br />
</ol>Here’s a step-by-step walkthrough of how our query topology works:  <ol><li>Whenever you perform a search on Twitter, the search request gets logged to a <a href=\"http://kafka.apache.org/\">Kafka queue</a>.<br />
<br />
<li>The Storm topology attaches a spout to this Kafka queue, and the spout emits a tuple containing the query and other metadata (e.g., the time the query was issued and its location) to a bolt for processing.<br />
<br />
<li>This bolt updates the count of the number of times we've seen this query, checks whether the query is \"currently popular\" (using various statistics like time-decayed counts, the geographic distribution of the query, and the last time this query was sent for annotations), and dispatches it to our human computation pipeline if so.<br />
</ol>One interesting feature of our popularity algorithm is that we often re-judge queries that have been annotated before, since the intent of a search can change. For example, people may normally search for [Clint Eastwood] because they're interested in his movies, but during the 2012 Republican National Convention users may have wanted to see Tweets related to his speech there.  <p><b>Human evaluation of popular search queries</b> <p>We use human computation for a variety of tasks. (See also <a href=\"http://engineering.twitter.com/2012/08/crowdsourced-data-analysis-with.html\">Clockwork Raven</a>, an open-source project we built that makes launching tasks easier.) For example, we often run experiments to measure ad relevance and search quality, we use it to gather data to train and evaluate our machine learning models. In this section we'll describe how we use it to boost our understanding of popular search queries. <p>Suppose that our Storm topology has detected that the query [Big Bird] is suddenly spiking. Since the query may remain popular for only a few hours, we send it off to live humans, who can help us quickly understand what it means; this dispatch is performed via a Thrift service that allows us to design our tasks in a <a href=\"http://engineering.twitter.com/2012/08/crowdsourced-data-analysis-with.html\">web frontend</a>, and later programmatically submit them to Mechanical Turk using any of the different languages we use across Twitter. <p>On Mechanical Turk, judges are asked several questions about the query that help us serve better ads. Without going into the exact questions, here are flavors of a few possibilities: <p>- What category does the query belong to? For example, [Stanford] may typically be an education-related query, but perhaps there's a football game between Stanford and Berkeley at the moment, in which case the current search intent would be sports. <p>- Does the query refer to a person? If so, who? And, what is their Twitter handle if they have one? For example, the query [Happy Birthday Harry] may be trending, but it's hard to know beforehand which of the numerous celebrities named Harry it's referring to. Is it <a href=\"https://twitter.com/onedirection\">One Direction</a>'s <a href=\"https://twitter.com/Harry_Styles\">Harry Styles</a>, in which case the searcher is likely to be interested in teen pop? Harry Potter, in which case the searcher is likely to be interested in fantasy novels? Or someone else entirely? <p><b>Turkers in the machine</b> <p>Since humans are core to this system, our workforce was designed to give us fast and reliable results. <p>For completing all our tasks, we use a small <i>custom</i> pool of Mechanical Turk judges to ensure high quality. Other typical possibilities in the crowdsourcing world are to use a static set of in-house judges, to use the standard worker filters that Amazon provides, or to go through an outside company like <a href=\"http://crowdflower.com/\">Crowdflower</a>. We've experimented with these other solutions, and while they have their own benefits, we found that a custom pool fit our needs best for a few reasons: <p>- A typical industry standard for human evaluation is to use in-house judges. They usually provide high-quality work as they become experts at the evaluation task domain. In-house judges are unfortunately hard to scale as they require standardized hiring processes to be in place. They also tend to be relatively more expensive, it can be harder to communicate with them, and their schedules can be difficult to work with. <p>- Using the standard sets of workers that Mechanical Turk or other crowdsourcing platforms provide makes it easy to scale the workforce, but we’ve found that their quality doesn’t always meet our needs. Two methods of ensuring high quality are to seed gold-standard examples for which you know the true response throughout your task, or to use statistical analysis to determine which workers are the good ones. But these can be time-consuming and expensive to create, and we often run tasks that can have free-response or require some background research, for which these solutions don't work. Another problem is that using these filters gives you a <i>fluid</i> and constantly changing set of workers — which makes them hard to train. <p>In contrast: <p>- Our custom pool of judges work virtually all day. For many of them, this is a full-time job, and they're geographically distributed, so our tasks complete quickly at all hours. We can easily ask for thousands of judgments before lunch, and have them finished by the time we need, which makes iterating on our experiments much easier. <p>- We have several forums, mailing lists, and even live chat rooms set up, all of which makes it easy for judges to ask us questions and to respond to feedback. Our judges will even give <i>us</i> suggestions on how to improve our tasks; for example, when we run categorization tasks, they'll often report helpful categories that we should add. <p>- Since we only launch tasks on demand, and Amazon provides a ready source of workers if we ever need more, our judges are never twiddling their thumbs waiting for tasks or completing busywork, and our jobs are rarely backlogged. <p>- Because our judges are culled from the best of Mechanical Turk, they're experts at the kinds of tasks we send, and can often provide higher quality at a faster rate than what even in-house judges provide. For example, they'll often use the forums and chatrooms to collaborate amongst themselves to give us the best judgments, and they're already familiar with the Firefox and  Chrome scripts that help them be the most efficient at their work. <p>All the benefits described above are especially valuable in this real-time search annotation case: <p>- Having highly trusted workers means we don't need to wait for multiple annotations on a single search query to confirm  validity, so we can send responses to our backend as soon as a single judge responds. This entire pipeline is design for <i>real-time</i>, after all, so the lower the latency on the human evaluation part, the better. <p>- The static nature of our custom pool means that the judges are already familiar with our questions, and don't need to be trained again. <p>- Because our workers aren't limited to a fixed schedule or location, they can work anywhere, anytime — which is a requirement for this system, since global event spikes on Twitter are not limited to a standard 40-hour work week. <p>- And with the multiple easy avenues of communication we have set up, it's easy for us to answer questions that might arise when we add new questions or modify existing ones. <p><b>Singing telegram summary</b> <p>As an example of the kind of top quality our workers provide, we crowdsourced a singing telegram to celebrate the project's launch. Here's what they came up with:  <iframe allowfullscreen=\"allowfullscreen\" frameborder=\"0\" height=\"315\" src=\"http://www.youtube.com/embed/EIK8iVnU5EU\" width=\"420\"></iframe> <p>This video was created entirely by our workers, from the crowdsourced lyrics, to the crowdsourced graphics, and even the piano playing and singing. Special thanks in particular to our amazing Turker, workasaurusrex, the musician and silky smooth crooner who brought the masterpiece together. <p>Many thanks to the Revenue and Storm teams, as well as our Turkers, for their help in launching this project. <p>Posted by <a href=\"https://twitter.com/echen\">Edwin Chen</a> and <a href=\"https://twitter.com/alpa\">Alpa Jain</a>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/264900056363370138"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/264900056363370138"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2013/01/improving-twitter-search-with-real-time.html") (title . "Improving Twitter search with real-time human computation"))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://img.youtube.com/vi/EIK8iVnU5EU/default.jpg") (height . "72") (width . "72")))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-6064921610291059483") (published nil "2012-12-21T14:11:00.000-08:00") (updated nil "2012-12-21T14:21:37.607-08:00") (title ((type . "text")) "Right-to-left support for Twitter Mobile") (content ((type . "html")) "Thanks to the efforts of our <a href=\"https://translate.twitter.com/welcome\">translation volunteers</a>, last week we were able to <a href=\"http://blog.twitter.com/2012/03/twitter-now-available-in-arabic-farsi.html\">launch</a> right-to-left language support for our mobile website in Arabic and Farsi. Two interesting challenges came up during development for this feature:<br />
<br />
1)  We needed to support a timeline that has both right-to-left (RTL) and left-to-right (LTR) tweets. We also needed to make sure that specific parts of each tweet, such as usernames and URLs, are always displayed as LTR.<br />
<br />
2) For our touch website, we wanted to flip our UI so that it was truly an RTL experience. But this meant we would need to change a lot of our CSS rules to have reversed values for properties like padding, margins, etc. — both time-consuming and unsustainable for future development. We needed a solution that would let us make changes without having to worry about adding in new CSS rules for RTL every time.<br />
<br />
In this post, I detail how we handled these two challenges and offer some general RTL tips and other findings we gleaned during development.<br />
<br />
<b>General RTL tips</b><br />
<br />
The basis for supporting RTL lies in the dir element attribute, which can be set to either ltr or rtl. This allows you to set an element’s content direction, so that any text/children nodes would render in the orientation specified. You can see the difference below:<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://3.bp.blogspot.com/-VeYcasPQ_Dw/UNTaXWC_OHI/AAAAAAAAAcU/G8HJyzd6s4I/s1600/RTL1.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"64\" src=\"http://3.bp.blogspot.com/-VeYcasPQ_Dw/UNTaXWC_OHI/AAAAAAAAAcU/G8HJyzd6s4I/s400/RTL1.png\" width=\"400\" /></a></div>
<br />
In the first row, the text in the LTR column is correct, but in the second it’s the text in the RTL column. <br />
<br />
Since this attribute can be used on any element, it can a) be used to change the <span style=\"font-family: inherit;\">direction</span> of inline elements, such as links (see “Handling bidirectional tweet content” below) and b) if added to the root html node then the browser will flip the order of all the elements on the page automatically (see “Creating a right-to-left UI” below).<br />
<br />
The other way to change content direction lies in the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">direction</span> and <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">unicode-bidi</span> CSS properties. Just like the dir attribute, the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">direction</span> property allows you to specify the direction within an element. However, there is one key difference: while <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">direction</span> will affect any block-level elements, for it to affect inline elements the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">unicode-bidi</span> property must be set to <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">embed</span> or <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">override</span>. Using the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">dir</span> attribute acts as if both those properties were applied, and is the preferred method as bidi should be considered a document change, not a styling one.<br />
<br />
For more on this, see the “W3C directionality specs” section below.<br />
<br />
<b>Handling bidirectional tweet content</b><br />
<br />
One of the things we had to think about was how to properly align each tweet depending on the dominant directionality of the content characters. For example, a tweet with mostly RTL characters should be right-aligned and read from right to left. To figure out which chars were RTL, we used this regex:<br />
<br />
<span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">/[\\u0600-\\u06FF]|[\\u0750-\\u077F]|[\\u0590-\\u05FF]|[\\uFE70-\\uFEFF]/m</span><br />
<br />
Then depending on how many chars matched, we could figure out the direction we’d want to apply to the tweet. <br />
<br />
However, this would also affect the different entities that are in a tweet’s content. Tweet entities are special parts included in the text that has their own context applied to them, such as usernames and hashtags. Usernames and URLs should always be displayed as LTR, while hashtags may be RTL or LTR depending on what the first character is. To solve this, while parsing out entities we also make sure that the correct direction was applied to the element the entities were contained in.<br />
<br />
If you are looking to add RTL support for your site and you have dynamic text with mixed directionality, besides using the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">dir</span> attribute or <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">direction</span> property, you could also look into the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">\\u200e</span> (<b id=\"internal-source-marker_0.7591470791958272\" style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; color: black; font-family: Times; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"><span style=\"background-color: transparent; color: black; font-family: 'Courier New'; font-size: 15px; font-style: normal; font-variant: normal; font-weight: normal; text-decoration: initial; vertical-align: baseline; white-space: pre-wrap;\">&amp;lrm;</span></b>‎) and the<span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\"> \\u200f</span> (‏<b id=\"internal-source-marker_0.7591470791958272\" style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; color: black; font-family: Times; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"><span style=\"background-color: transparent; color: black; font-family: 'Courier New'; font-size: 15px; font-style: normal; font-variant: normal; font-weight: normal; text-decoration: initial; vertical-align: baseline; white-space: pre-wrap;\">&amp;lrm;</span></b>) characters. These are invisible control markers that tell the browser how the following text should be displayed. But be careful; conflicts can arise if both the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">dir / direction</span> and character marker methods are used together. Or if you are using Ruby, Twitter has a great localization gem called <a href=\"https://github.com/twitter/twitter-cldr-rb\">TwitterCldr</a> which can take a string and insert these markers appropriately.<br />
<br />
<b>Creating a right-to-left UI </b><br />
<br />
For our mobile touch website, we would first detect what language the user’s browser is set in. When it’s one of our supported RTL languages, we add the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">dir</span> attribute to our page. The browser will then flip the layout of the site so that everything was rendered on the right-hand side first. <br />
<br />
This worked fairly well on basic alignment of the page; however, this did not change how all the elements are styled. Properties like padding, margin, text-align, and float will all have the same values, which means that the layout will look just plain wrong in areas where these are applied. This can be the most cumbersome part of adding RTL support to a website, as it usually means adding special rules to your stylesheets to handle this flipped layout. <br />
<br />
For our mobile touch website, we are using<a href=\"http://code.google.com/p/closure-stylesheets/\"> Google Closure</a> as our stylesheet compiler. This has an extremely convenient flag called <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">--output-orientation</span>, which will go through your stylesheets and adjust the rules according to the value (LTR or RTL) you pass in. By running the stylesheet compilation twice, once with this flag set to RTL, we get two stylesheets that are the mirror images of each other. This fixed nearly all styling issues that came from needing to flip CSS values. In the end, there were only two extra rules that we needed to add to the RTL stylesheet - those were put into<span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\"> rtl.css</span> which gets added on as the last input file for the RTL compilation, thusly overriding any previous rules that were generated.<br />
<br />
After that, it’s just a matter of including the right stylesheet for the user’s language and voila! a very nicely RTL’d site with minimal extra effort on the development side.<br />
<br />
One last thing that we needed to think about was element manipulation with JS. Since elements will now be pushed as far to the right as possible instead of to the far left, the origin point in which an element starts at may be very different than what you'd expect - possibly even out of the visible area in a container. <br />
<br />
For example, we had to change the way that the media strip in our photo gallery moved based on the page’s directionality. Besides coordinates changing, an LTR user would drag starting from the right, then ending to the left in order to see more photos. For an RTL user, the natural inclination would be to start at a left point and drag to the right. This is something that can’t be handled automatically as with our stylesheet compiler, so it comes down to good old-fashioned programming to figure out how we wanted elements to move.<br />
<br />
<b>Improving translations</b><br />
<br />
We would like to thank our amazing translations community for helping us get to this point. Without your efforts,we would not have been able to launch this feature onto mobile Twitter. And although we've made great strides in supporting RTL, we still have more work to do. <br />
<br />
We would love to have more translations for other languages that are not complete yet, such as our other two RTL languages Hebrew and Urdu. Visit <a href=\"http://translate.twitter.com/\">translate.twitter.com</a> to see how you can help us add more languages to Twitter.<br />
<br />
<b>Helpful Resources</b><br />
<br />
W3C directionality specs:<br />
<ul>
<li><a href=\"http://www.w3.org/TR/2004/WD-xhtml2-20040722/mod-bidi.html\">dir</a> </li>
<li><a href=\"http://www.w3.org/TR/CSS2/visuren.html#direction\">direction / unicode-bidi </a></li>
<li><a href=\"http://www.w3.org/International/questions/qa-bidi-css-markup\">dir versus direction</a></li>
</ul>
More resources:<br />
<ul>
<li><a href=\"https://developer.mozilla.org/en-US/docs/CSS/direction\">Mozilla</a></li>
<li><a href=\"https://github.com/twitter/twitter-cldr-rb\">TwitterCLDR Ruby Gem</a> </li>
<li><a href=\"http://code.google.com/p/closure-stylesheets/\">Google Closure Stylesheets</a></li>
<li><a href=\"http://xkcd.com/1137/\">XKCD’s example of another control character </a></li>
</ul>
<br />
Posted by Christine Tieu (@ctieu)<br />
Engineer, Mobile Web Team") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6064921610291059483"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6064921610291059483"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/12/right-to-left-support-for-twitter-mobile.html") (title . "Right-to-left support for Twitter Mobile"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://3.bp.blogspot.com/-VeYcasPQ_Dw/UNTaXWC_OHI/AAAAAAAAAcU/G8HJyzd6s4I/s72-c/RTL1.png") (height . "72") (width . "72")))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-445106285386942826") (published nil "2012-12-20T09:56:00.001-08:00") (updated nil "2012-12-20T09:56:45.081-08:00") (title ((type . "text")) "How our photo filters came into focus") (content ((type . "html")) "<p>The old adage “a picture is worth a thousand words” is very apt for Twitter:  a single photo can express what otherwise might require many Tweets. Photos help capture whatever we’re up to: kids’ birthday parties, having fun with our friends, the world we see when we travel.</p><p>Like so many of you, lots of us here at Twitter really love sharing filtered photos in our tweets. As we got into doing it more often, we began to wonder if we could make that experience better, easier and faster. After all, the now-familiar process for tweeting a filtered photo has required a few steps:</p>1. Take the photo (with an app)<br />
2. Filter the photo (probably another app)<br />
3. Finally, tweet it! <br />
<p>Constantly needing to switch apps takes time, and results in frustration and wasted photo opportunities. So we challenged ourselves to make the experience as fast and simple as possible. We wanted everyone to be able to easily tweet photos that are beautiful, timeless, and meaningful.</p><p>With last week’s photo filters release, we think we accomplished that on the latest versions of Twitter for Android and Twitter for iPhone. Now we'd like to tell you a little more about what went on behind the scenes in order to develop this new photo filtering experience.</p><p><b>It’s all about the filters</b></p><p>Our guiding principle: to create filters that amplify what you want to express, and to help that expression stand the test of time. We began with research, user stories, and sketches. We designed and tested multiple iterations of the photo-taking experience, and relied heavily on user research to make decisions about everything from filters nomenclature and iconography to the overall flow. We refined and distilled until we felt we had the experience right. </p><br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://2.bp.blogspot.com/-TdUzWMo2yzw/UNNJfRIT6KI/AAAAAAAAAbc/qlh-4jNypAg/s1600/blog_eng1.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"300\" width=\"400\" src=\"http://2.bp.blogspot.com/-TdUzWMo2yzw/UNNJfRIT6KI/AAAAAAAAAbc/qlh-4jNypAg/s400/blog_eng1.png\" /></a></div><br />
<p>We spent many hours poring over the design of the filters. Since every photo is different, we did our analyses across a wide range of photos including portraits, scenery, indoor, outdoor and low-light shots. We also calibrated details ranging from color shifts, saturation, and contrast, to the shape and blend of the vignettes before handing the specifications over to Aviary, a company specializing in photo editing. They applied their expertise to build the algorithms that matched our filter specs.</p><br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-X9SKAtHFsuo/UNNObx5nrRI/AAAAAAAAAbw/9t31YkNwQ4w/s1600/blog_eng2.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"300\" width=\"400\" src=\"http://4.bp.blogspot.com/-X9SKAtHFsuo/UNNObx5nrRI/AAAAAAAAAbw/9t31YkNwQ4w/s400/blog_eng2.png\" /></a></div><br />
<b>Make it fast!</b><br />
<p>Our new photo filtering system is a tight integration of Aviary's cross-platform GPU-accelerated photo filtering technology with our own user interface and visual specifications for filters. Implementing this new UI presented some unique engineering challenges. The main one was the need to create an experience that feels instant and seamless to use — while working within constraints of memory usage and processing speed available on the wide range of devices our apps support.</p><p>To make our new filtering experience work, our implementation keeps up to four full-screen photo contexts in memory at once: we keep three full-screen versions of the image for when you’re swiping through photos (the one you’re currently looking at plus the next to the right and the left), and the fourth contains nine small versions of the photo for the grid view. And every time you apply or remove a crop or magic enhance, we update the small images in the grid view to reflect those changes, so it’s always up to date.</p><p>Without those, you could experience a lag when scrolling between photos — but mobile phones just don't have a lot of memory. If we weren't careful about when and how we set up these chunks of memory, one result could be running out of memory and crashing the app. So we worked closely with Aviary's engineering team to achieve a balance that would work well for many use cases. </p><b>Test and test some more</b><br />
<p>As soon as engineering kicked off, we rolled out this new feature internally so that we could work out the kinks, sanding down the rough spots in the experience. At first, the team tested it, and then we opened it up to all employees to get lots of feedback. We also engaged people outside the company for user research. All of this was vital to get a good sense about which aspects of the UI would resonate, or wouldn’t.</p><p>After much testing and feedback, we designed an experience in which you can quickly and easily choose between different filtering options – displayed side by side, and in a grid. Auto-enhancement and cropping are both a single tap away in an easy-to-use interface.</p><br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://3.bp.blogspot.com/-h3ui89b-SAo/UNNPRNClFBI/AAAAAAAAAb8/ZRZegKIBLr8/s1600/blog_eng3.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"300\" width=\"400\" src=\"http://3.bp.blogspot.com/-h3ui89b-SAo/UNNPRNClFBI/AAAAAAAAAb8/ZRZegKIBLr8/s400/blog_eng3.png\" /></a></div><br />
<p>Finally, a collaborative team of engineers, designers and product managers were able to ship a set of filters wrapped in a seamless UI that anyone with our Android or iPhone app can enjoy. And over time, we want our filters to evolve so that sharing and connecting become even more delightful. It feels great to be able to share it with all of you at last.</p><br />
Posted by @ryfar<br />
Tweet Composer Team<br />
<br />
<br />
<br />
") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/445106285386942826"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/445106285386942826"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/12/how-our-photo-filters-came-into-focus.html") (title . "How our photo filters came into focus"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://2.bp.blogspot.com/-TdUzWMo2yzw/UNNJfRIT6KI/AAAAAAAAAbc/qlh-4jNypAg/s72-c/blog_eng1.png") (height . "72") (width . "72")))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-3382965804299186883") (published nil "2012-12-13T09:25:00.000-08:00") (updated nil "2012-12-13T09:25:15.933-08:00") (title ((type . "text")) "Class project: “Analyzing Big Data with Twitter” ") (content ((type . "html")) "Twitter partnered with UC Berkeley this past semester to teach <a href=\"http://blogs.ischool.berkeley.edu/i290-abdt-s12/\">Analyzing Big Data with Twitter</a>, a class with <a href=\"http://people.ischool.berkeley.edu/~hearst/\">Prof. Marti Hearst</a>. In the first half of the semester, Twitter engineers went to UC Berkeley to talk about the <a href=\"http://engineering.twitter.com/\">technology behind Twitter</a>: from the basics of <a href=\"http://engineering.twitter.com/2012/06/building-and-profiling-high-performance.html\">scaling</a> up a <a href=\"http://engineering.twitter.com/2012/06/distributed-systems-tracing-with-zipkin.html\">service</a> to the algorithms behind <a href=\"http://engineering.twitter.com/2012/03/generating-recommendations-with.html\">user recommendations</a> and <a href=\"http://engineering.twitter.com/2011/05/engineering-behind-twitters-new-search.html\">search</a>. These talks are available online, on the course <a href=\"http://blogs.ischool.berkeley.edu/i290-abdt-s12/\">website</a>. <br />
<br />
In the second half of the course, students applied their knowledge and creativity to build data-driven applications on top of Twitter. They came up with a range of products that included tracking bands or football teams, monitoring Tweets to find calls for help, and identifying communities on Twitter. Each project was mentored by one of our engineers.<br />
<br />
Last week, 40 of the students came to Twitter HQ to demo their final projects in front of a group of our engineers, designers and engineering leadership team.<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://2.bp.blogspot.com/-HnOe0xampRc/UMoOdW2gAuI/AAAAAAAAAbI/Hl2WnAEbc_A/s1600/IMG_8847.jpg\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"267\" width=\"400\" src=\"http://2.bp.blogspot.com/-HnOe0xampRc/UMoOdW2gAuI/AAAAAAAAAbI/Hl2WnAEbc_A/s400/IMG_8847.jpg\" /></a></div><br />
The students' enthusiasm and creativity inspired and impressed all of us who were involved. The entire experience was really fun, and we hope to work with Berkeley more in the future.<br />
<br />
Many thanks to the volunteer Twitter engineers, to Prof. Hearst, and of course to our fantastic students!<br />
<br />
<blockquote class=\"twitter-tweet\"><p>Cannot believe that I'll be visiting the Twitter HQ tomorrow for our project presentations. Yay! Yes, had to tweet about it. <a href=\"https://twitter.com/search/%23ilovetwitter\">#ilovetwitter</a></p>&mdash; Priya Iyer (@myy_precious) <a href=\"https://twitter.com/myy_precious/status/276513438702923779\" data-datetime=\"2012-12-06T02:28:35+00:00\">December 6, 2012</a></blockquote><script src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><br />
<blockquote class=\"twitter-tweet\" data-in-reply-to=\"276887760420339712\"><p>@<a href=\"https://twitter.com/gilad\">gilad</a> @<a href=\"https://twitter.com/ucbtweeter\">ucbtweeter</a> Truly one of my dreams coming true! Thanks to everyone from Twitter and @<a href=\"https://twitter.com/martihearst\">martihearst</a> for making this happen.</p>&mdash; Seema Hari (@SeemaHari) <a href=\"https://twitter.com/SeemaHari/status/276990164843237376\" data-datetime=\"2012-12-07T10:02:56+00:00\">December 7, 2012</a></blockquote><script src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><br />
<br />
Posted by Gilad Mishne - <a href=\"http://twitter.com/gilad\">@gilad</a><br />
Engineering Manager, Search") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3382965804299186883"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3382965804299186883"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/12/class-project-analyzing-big-data-with.html") (title . "Class project: “Analyzing Big Data with Twitter” "))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://2.bp.blogspot.com/-HnOe0xampRc/UMoOdW2gAuI/AAAAAAAAAbI/Hl2WnAEbc_A/s72-c/IMG_8847.jpg") (height . "72") (width . "72")))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-169729317243469697") (published nil "2012-12-11T12:52:00.000-08:00") (updated nil "2012-12-11T13:00:18.316-08:00") (title ((type . "text")) "Blobstore: Twitter’s in-house photo storage system ") (content ((type . "html")) "Millions of people turn to Twitter to share and discover photos. To make it possible to upload a photo and attach it to your Tweet directly from Twitter, we partnered with Photobucket in 2011. As soon as photos became a more native part of the Twitter experience, more and more people began using this feature to share photos. <br />
<br />
In order to introduce new features and functionality, such as <a href=\"http://blog.twitter.com/2012/12/twitter-photos-put-filter-on-it.html\">filters</a>, and continue to improve the photos experience, Twitter’s Core Storage team began building an in-house photo storage system. In September, we began to use this new system, called Blobstore.<br />
<br />
<b><span style=\"font-size: large;\">What is Blobstore?</span></b><br />
<br />
Blobstore is Twitter’s low-cost and scalable storage system built to store photos and other binary large objects, also known as blobs. When we set out to build Blobstore, we had three design goals in mind:<br />
<br />
<ul>
<li><b>Low Cost:</b> Reduce the amount of money and time Twitter spent on storing Tweets with photos.</li>
<li><b>High Performance:</b> Serve images in the low tens of milliseconds, while maintaining a throughput of hundreds of thousands of requests per second.</li>
<li><b>Easy to Operate:</b> Be able to scale operational overhead with Twitter’s continuously growing infrastructure.</li>
</ul>
<br />
<b><span style=\"font-size: large;\">How does it work?</span></b><br />
<br />
When a user tweets a photo, we send the photo off to one of a set of Blobstore <b>front-end servers</b>. The front-end understands where a given photo needs to be written, and forwards it on to the servers responsible for actually storing the data. These storage servers, which we call <b>storage nodes</b>, write the photo to a disk and then inform a <b>Metadata store t</b>hat the image has been written and instruct it to record the information required to retrieve the photo. This<b> </b>Metadata store, which is a non-relational key-value store cluster with automatic multi-DC synchronization capabilities, spans across all of Twitter’s data centers providing a consistent view of the data that is in Blobstore.<br />
<br />
The brain of Blobstore, the <b>blob manager</b>, runs alongside the front-ends, storage nodes, and index cluster. The blob manager acts as a central coordinator for the management of the cluster. It is the source of all of the front-ends’ knowledge of where files should be stored, and it is responsible for updating this mapping and coordinating data movement when storage nodes are added, or when they are removed due to failures.<br />
<br />
Finally, we rely on <b>Kestrel</b>, Twitter’s existing asynchronous queue server, to handle tasks such as replicating images and ensuring data integrity across our data centers. <br />
<br />
We guarantee that when an image is successfully uploaded to Twitter, it is immediately retrievable from the data center that initially received the image. Within a short period of time, the image is replicated to all of our other data centers, and is retrievable from those as well. Because we rely on a multi-data-center Metadata store for the central index of files within Blobstore, we are aware in a very short amount of time whether an image has been written to its original data center; we can route requests there until the Kestrel queues are able to replicate the data.<br />
<br />
<b><span style=\"font-size: large;\">Blobstore Components</span></b><br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://2.bp.blogspot.com/-ck7Xv1OZygs/UMecZAbUr0I/AAAAAAAAAaY/5Dw0ntVVL4w/s1600/Blobstore%2BComponents.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"330\" src=\"http://2.bp.blogspot.com/-ck7Xv1OZygs/UMecZAbUr0I/AAAAAAAAAaY/5Dw0ntVVL4w/s400/Blobstore%2BComponents.png\" width=\"400\" /></a></div>
<br />
<b><span style=\"font-size: large;\">How is the data found?</span></b><br />
<br />
When an image is requested from Blobstore, we need to determine its location in order to access the data. There are a few approaches to solving this problem, each with its own pros and cons. One such approach is to map or hash each image individually to a given server by some method. This method has a fairly major downside in that it makes managing the movement of images much more complicated. For example, if we were to add or remove a server from Blobstore, we would need to recompute a new location for each individual image affected by the change. This adds operational complexity, as it would necessitate a rather large amount of bookkeeping to perform the data movement.<br />
<br />
We instead created a fixed-sized container for individual blobs of data, called a “<b>virtual bucket</b>”. We map images to these containers, and then we map the containers to the individual storage nodes. We keep  the total number of virtual buckets unchanged for the entire lifespan of our cluster. In order to determine which virtual bucket a given image is stored in, we perform a simple hash on the image’s unique ID. As long as the number of virtual buckets remains the same, this hashing will remain stable. The advantage of this stability is that we can reason about the movement of data at a much more coarsely grained level than the individual image.<br />
<br />
<b><span style=\"font-size: large;\">How do we place the data?</span></b><br />
<br />
When mapping virtual buckets to physical storage nodes, we keep some rules in mind to make sure that we don’t lose data when we lose servers or hard drives. For example, if we were to put all copies of a given image on a single rack of servers, losing that rack would mean that particular image would be unavailable.<br />
<br />
If we were to completely mirror the data on a given storage node on another storage node, it would be unlikely that we would ever have unavailable data, as the likelihood of losing both nodes at once is fairly low. However, whenever we were to lose a node, we would only have a single node to source from to re-replicate the data. We would have to recover slowly, so as to not impact the performance of the single remaining node.<br />
<br />
If we were to take the opposite approach and allow any server in the cluster to share a range of data on all servers, then we would avoid a bottleneck when recovering lost replicas, as we would essentially be able to read from the entire cluster in order to re-replicate data. However, we would also have a very high likelihood of data loss if we were to lose more than the replication factor of the cluster (two) per data center, as the chance that any two nodes would share some piece of data would be high. So, the optimal approach would be somewhere in the middle: for a given piece of data, there would be a limited number of machines that could share the range of data of its replica - more than one but less than the entire cluster.<br />
<br />
We took all of these things into account when we determined the mapping of data to our storage nodes. As a result, we built a library called “<b>libcrunch</b>” which understands the various data placement rules such as rack-awareness, understands how to replicate the data in way that minimizes risk of data loss while also maximizing the throughput of data recovery, and attempts to minimize the amount of data that needs to be moved upon any change in the cluster topology (such as when nodes are added or removed). It also gives us the power to fully map the network topology of our data center, so storage nodes have better data placement and we can take into account rack awareness and placement of replicas across PDU zones and routers.<br />
<br />
Keep an eye out for a blog post with more information on libcrunch.<br />
<br />
<b><span style=\"font-size: large;\">How is the data stored?</span></b><br />
<br />
Once we know where a given piece of data is located, we need to be able to efficiently store and retrieve it. Because of their relatively high storage density, we are using standard hard drives inside our storage nodes (3.5” 7200 RPM disks). Since this means that disk seeks are very expensive, we attempted to minimize the number of disk seeks per read and write.<br />
<br />
We pre-allocate ‘fat’ files on each storage node disk using fallocate(), of around 256MB each. We store each blob of data sequentially within a fat file, along with a small header. The offset and length of the data is then stored in the Metadata store, which uses SSDs internally, as the access pattern for index reads and writes is very well-suited for solid state media. Furthermore, splitting the index from the data saves us from needing to scale out memory on our storage nodes because we don’t need to keep any local indexes in RAM for fast lookups. The only time we end up hitting disk on a storage node is once we already have the fat file location and byte offset for a given piece of data. This means that we can generally guarantee a single disk seek for that read.<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://3.bp.blogspot.com/-c-gnLltkKUM/UMecoVXkGBI/AAAAAAAAAak/P9H75Wc8Cyg/s1600/How%2Bis%2Bthe%2Bdata%2Bstored.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"274\" src=\"http://3.bp.blogspot.com/-c-gnLltkKUM/UMecoVXkGBI/AAAAAAAAAak/P9H75Wc8Cyg/s400/How%2Bis%2Bthe%2Bdata%2Bstored.png\" width=\"400\" /></a></div>
<br />
<b><span style=\"font-size: large;\">Topology Management</span></b><br />
<br />
As the number of disks and nodes increases, the rate of failure increases. Capacity needs to be added, disks and nodes need to be replaced after failures, servers need to be moved. To make Blobstore operationally easy we put a lot of time and effort into libcrunch and the tooling associated with making cluster changes. <br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://4.bp.blogspot.com/-3hbpHmPwUOA/UMecvGKyH7I/AAAAAAAAAaw/irUWMopcGwk/s1600/blobStore_frontend.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"273\" src=\"http://4.bp.blogspot.com/-3hbpHmPwUOA/UMecvGKyH7I/AAAAAAAAAaw/irUWMopcGwk/s400/blobStore_frontend.png\" width=\"400\" /></a></div>
<br />
When a storage node fails, data that was hosted on that node needs to be copied from a surviving replica to restore the correct replication factor. The failed node is marked as unavailable in the cluster topology, and so libcrunch computes a change in the mapping from the virtual buckets to the storage nodes. From this mapping change, the storage nodes are instructed to copy and migrate virtual buckets to new locations.<br />
<br />
<b><span style=\"font-size: large;\">Zookeeper</span></b><br />
Topology and placement rules are stored internally in one of our Zookeeper clusters. The Blob Manager deals with this interaction and it uses this information stored in Zookeeper when an operator makes a change to the system. A topology change can consist of adjusting the replication factor, adding, failing, or removing nodes, as well as adjusting other input parameters for libcrunch. <br />
<br />
<b><span style=\"font-size: large;\">Replication across Data centers</span></b><br />
<br />
Kestrel is used for cross data center replication. Because kestrel is a durable queue, we use it to asynchronously replicate our image data across data centers. <br />
<br />
<span style=\"font-size: large;\"><b>Data center-aware Routing</b></span><br />
<br />
TFE (Twitter Frontend) is one of Twitter’s core components for routing. We wrote a custom plugin for TFE, that extends the default routing rules. Our Metadata store spans multiple data centers, and because the metadata stored per blob is small (a few bytes), we typically replicate this information much faster than the blob data. If a user tries to access a blob that has not been replicated to the nearest data center they are routed to, we look up this metadata information and proxy requests to the nearest data center that has the blob data stored. This gives us the property that if replication gets delayed, we can still route requests to the data center that stored the original blob, serving the user the image at the cost of a little higher latency until it’s replicated to the closer data center.<br />
<br />
<b><span style=\"font-size: large;\">Future work</span></b><br />
<br />
We have shipped the first version of blobstore internally. Although blobstore started with photos, we are adding other features and use cases that require blob storage to blobstore. And we are also continuously iterating on it to make it more robust, scalable, and easier to maintain.<br />
<br />
<b><span style=\"font-size: large;\">Acknowledgments</span></b><br />
<br />
Blobstore was a group effort. The following folks have contributed to the project: Meher Anand (<a href=\"https://twitter.com/meher_anand\">@meher_anand</a>), Ed Ceaser (<a href=\"https://twitter.com/asdf\">@asdf</a>), Harish Doddi (<a href=\"https://twitter.com/thinkingkiddo\">@thinkingkiddo</a>), Chris Goffinet (<a href=\"https://twitter.com/lenn0x\">@lenn0x</a>), Jack Gudenkauf (<a href=\"https://twitter.com/_jg\">@_jg</a>), and Sangjin Lee (<a href=\"https://twitter.com/sjlee\">@sjlee</a>). <br />
<br />
Posted by Armond Bigian <a href=\"https://twitter.com/armondbigian\">@armondbigian</a><br />
Engineering Director, Core Storage &amp; Database Engineering ") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/169729317243469697"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/169729317243469697"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/12/blobstore-twitters-in-house-photo.html") (title . "Blobstore: Twitter’s in-house photo storage system "))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://2.bp.blogspot.com/-ck7Xv1OZygs/UMecZAbUr0I/AAAAAAAAAaY/5Dw0ntVVL4w/s72-c/Blobstore%2BComponents.png") (height . "72") (width . "72")))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-3827306517110644259") (published nil "2012-12-07T10:15:00.000-08:00") (updated nil "2012-12-07T12:48:38.589-08:00") (title ((type . "text")) "Implementing pushState for twitter.com") (content ((type . "html")) "<p>As part of our <a href=\"http://engineering.twitter.com/2012/05/improving-performance-on-twittercom.html\">continuing effort to improve the performance of twitter.com</a>, we've recently implemented <a href=\"https://developer.mozilla.org/en-US/docs/DOM/Manipulating_the_browser_history#Adding_and_modifying_history_entries\">pushState</a>. With this change, users experience a perceivable decrease in latency when navigating between sections of twitter.com; in some cases near zero latency, as we're now caching responses on the client.</p><p>This post provides an overview of the pushState API, a summary of our implementation, and details some of the pitfalls and gotchas we experienced along the way.</p><h3>API Overview</h3><p>pushState is part of the <a href=\"https://developer.mozilla.org/en-US/docs/DOM/Manipulating_the_browser_history\">HTML 5 History API</a>&mdash; a set of tools for managing state on the client. The pushState() method enables mapping of a state object to a URL. The address bar is updated to match the specified URL without actually loading the page.</p><code>history.pushState([page data], [page title], [page URL])</code><br />
<p>While the pushState() method is used when navigating forward from A to B, the History API also provides a \"popstate\" event&mdash;used to mange back/forward button navigation. The event's \"state\" property maps to the data passed as the first argument to pushState().</p><p>If the user presses the back button to return to the initial point from which he/she first navigated via pushState, the \"state\" property of the \"popstate\" event will be undefined. To set the state for the initial, full-page load use the replaceState() method. It accepts the same arguments as the pushState() method.</p><code>history.replaceState([page data], [page title], [page URL])</code><br />
<p>The following diagram illustrates how usage of the History API comes together.</p><br />
<img src=\"http://4.bp.blogspot.com/-CHAZTpf_8hc/UMJV4axe9dI/AAAAAAAAAC8/S2rT5DIt-ok/s500/history-api-diagram-2.png\"  alt=\"Diagram illustrating use of the HTML 5 History API\" /><br />
<br />
<h3>Progressive Enhancement</h3><p>Our pushState implementation is a <a href=\"http://en.wikipedia.org/wiki/Progressive_enhancement\">progressive enhancement</a> on top of <a href=\"http://engineering.twitter.com/2012/05/improving-performance-on-twittercom.html\">our previous work</a>, and could be described as <a href=\"http://en.wikipedia.org/wiki/Hijax\">Hijax</a> + server-side rendering. By maintaining view logic on the server, we keep the client light, and maintain support for browsers that don't support pushState with the same URLs. This approach provides the additional benefit of enabling us to disable pushState at any time without jeopardizing any functionality.</p><h3>On the Server</h3><p>On the server, we configured each endpoint to return either full-page responses, or a JSON payload containing a partial, server-side rendered view, along with its corresponding JavaScript components. The decision of what response to send is determined by checking the Accept header and looking for \"application/json.\"</p><p>The same views are used to render both types of requests; to support pushState the views format the pieces used for the full-page responses into JSON.</p><p>Here are two example responses for the Interactions page to illustrate the point:</p><h4>pushState response</h4><pre><code>{
  // Server-rendered HTML for the view
  <b>page</b>: \"&#60;div&#62;&hellip;&#60;/div&#62;\",
  // Path to the JavaScript module for the associated view
  <b>module</b>: \"app/pages/connect/interactions\",
  // Initialization data for the current view
  <b>init_data</b>: {&hellip;},
  <b>title</b>: \"Twitter / Interactions\"
}
</code>
</pre><h4>Full page response</h4><pre><code>&#60;html&#62;
  &#60;head&#62;
    &#60;title&#62;<b>{{title}}</b>&#60;/title&#62;
  &#60;/head&#62;
  &#60;body&#62;
    &#60;div id=\"page-container\"><b>{{page}}</b>&#60;/div&#62;
  &#60;/body&#62;
&#60;/html&#62;
&#60;script&#62;
  using(<b>{{module}}</b>, function (pageModule) {
    pageModule<b>({{init_data}}</b>);
  });
&#60;/script&#62;
</code>
</pre><h3>Client Architecture</h3><p>Several aspects of our existing client architecture made it particularly easy to enhance twitter.com with pushState.</p><p>By contract, our components attach themselves to a single DOM node, listen to events via delegation, fire events on the DOM, and those events are broadcast to other components via DOM event bubbling. This allows our components to be even more loosely coupled&mdash;a component doesn't need a reference to another component in order to listen for its events.</p><p>Secondly, all of our components are defined using AMD, enabling the client to make decisions about what components to load.</p><p>With this client architecture we implemented pushState by adding two components: one responsible for managing the UI, the other data. Both are attached to the document, listen for events across the entire page, and broadcast events available to all components.</p><h4>UI Component</h4><ul><li>Manages the decision to pushState URLs by listening for document-wide clicks, and keyboard shortcuts</li>
<li>Broadcasts an event to initiate pushState navigation</li>
<li>Updates the UI in response to events from the data component</li>
</ul><h4>DATA Component</h4><ul><li>Only included if we're using pushState</li>
<li>Manages XHRs and caching of responses</li>
<li>Provides eventing around the HTML 5 history API to provide a single interface for UI components</li>
</ul><h4>Example pushState() Navigation LifeCycle</h4><ol><li>The user clicks on link with a specialized class (we choose \"js-nav\"), the click is caught by the UI component which prevents the default behavior and triggers a custom event to initiate pushState navigation.</li>
<li>The data component listens for that event and&hellip;<br />
<ol><li>Writes the current view to cache and, only before initial pushState navigation, calls replaceState() to set the state data for the view</li>
<li>Fetches the JSON payload for the requested URL (either via XHR or from cache)</li>
<li>Update the cache for the URL</li>
<li>Call pushState() to update the URL</li>
<li>Trigger an event indicating the UI should be updated</li>
</ol></li>
<li>The UI component resumes control by handling the event from the data component and&hellip;<br />
<ol><li>JavaScript components for the current view are torn down (event listeners detached, associated state is cleaned up)</li>
<li>The HTML for the current view is replaced with the new HTML</li>
<li>The script loader only fetches modules not already loaded</li>
<li>The JavaScript components for the current view are initialized</li>
<li>An event is triggered to alert all components that the view is rendered and initialized</li>
</ol></li>
</ol><h3>Pitfalls, Gotchas, etc.</h3><p>It'll come as no surprise to any experienced frontend engineers that the majority of the problems and annoyances with implementing pushState stem from either 1) inconsistencies in browser implementations of the HTML 5 History API, or 2) having to replicate behaviors or functionality you would otherwise get for free with full-page reloads.</p><h4>Don't believe the API, title updates are manual</h4><p>All browsers currently disregard the title attribute passed to the pushState() and replaceState() methods. Any updates to the page title need to be done manually.</p><h4>popstate Event Inconsistencies</h4><p>At the time of this writing, WebKit (and only WebKit) fires an extraneous popstate event after initial page load. This appears to be <a href=\"https://bugs.webkit.org/show_bug.cgi?id=93506\">a known bug in WebKit</a>, and is easy to work around by ignoring popstate events if the \"state\" property is undefined.</p><h4>State Object Size Limits</h4><p>Firefox imposes <a href=\"https://developer.mozilla.org/en-US/docs/DOM/Manipulating_the_browser_history#The_pushState().C2.A0method\">640KB character limit</a> on the serialized state object passed to pushState(), and will throw an exception if that limit is exceeded. We hit this limit in the early days of our implementation, and moved to storing state in memory. We limit the size of the serialized JSON we cache on the client per URL, and can adjust that number via a server-owned config.</p><p>It's worth noting that due to the aforementioned popstate bug in WebKit, we pass an empty object as the first argument to pushState() to distinguish WebKit's extraneous popstate events from those triggered in response to back/forward navigation.</p><h4>Thoughtful State Management Around Caching</h4><p>The bulk of the work implementing pushState went into designing a simple client framework that would facilitate caching and provide the right events to enable components to both prepare themselves to be cached, and restore themselves from cache. This was solved through a few simple design decisions:</p><ol><li>All events that trigger navigation (clicks on links, keyboard shortcuts, and back/forward button presses) are abstracted by the pushState UI component, routed through the same path in the data component, and subsequently fire the same events. This allows the UI to be both cached and handle updates in a uniform way.</li>
<li>The pushState UI component fires events around the rendering of updates: one before the DOM is updated, and another after the update is complete. The former enables UI components such as dialogs and menus to be collapsed in advance of the page being cached; the later enables UI components like timelines to update their timestamps when rendered from cache.</li>
<li>POST &#38; DELETE operations bust the client-side cache.</li>
</ol><h4>Re-implementing Browser Functionality</h4><p>As is often the case, changing the browser's default behavior in an effort to make the experience faster or simpler for the end-user typically requires more work on behalf of developers and designers. Here are some pieces of browser functionality that we had to re-implement:</p><ul><li>Managing the position of the scrollbar as the user navigates forward and backward.</li>
<li>Preserving context menu functionality when preventing a link's default click behavior.</li>
<li>Accounting for especially fast, indecisive user clicks by ensuring the response you're rendering is in sync with the last requested URL.</li>
<li>Canceling outbound XHRs when the user requests a new page to avoid unnecessary UI updates.</li>
<li>Implementing the <a href=\"http://preloaders.net/\">canonical AJAX spinner</a>, so the user knows the page is loading.</li>
</ul><h3>Final Thoughts</h3><p>Despite the usual browser inconsistencies and other gotchas, we're pretty happy with the HTML 5 History API. Our implementation has enabled us to deliver the fast initial page rendering times and robustness we associate with traditional, server-side rendered sites and the lightening quick in-app navigation and state changes associate with client-side rendered web applications.</p><h3>Helpful Resources</h3><ul><li>Mozilla's (<a href=\"https://twitter.com/mozilla\">@Mozilla</a>) <a href=\"https://developer.mozilla.org/en-US/docs/DOM/Manipulating_the_browser_history\">HTML 5 History API documentation</a></li>
<li>Chris Wanstrath's (<a href=\"https://twitter.com/defunkt\">@defunkt</a>) <a href=\"https://github.com/defunkt/jquery-pjax/\">pjax (pushState + ajax = pjax) plugin for jQuery project on GitHub</a></li>
<li>Benjamin Lupton's (<a href=\"https://twitter.com/balupton\">@balupton</a>) <a href=\"https://github.com/balupton/History.js/\">history.js project on GitHub</a></li>
<li>Modernizr's (<a href=\"https://twitter.com/Modernizr\">@Modernizr</a>) <a href=\"https://github.com/Modernizr/Modernizr\">pushState capability detection</a></li>
</ul><p>&mdash;Todd Kloots, Engineer, Web Core team (<a href=\"https://twitter.com/todd\">@todd</a>)</p>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3827306517110644259"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3827306517110644259"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/12/implementing-pushstate-for-twittercom_7.html") (title . "Implementing pushState for twitter.com"))) (author nil (name nil "Todd Kloots") (uri nil "https://plus.google.com/116070809214398998458") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://4.bp.blogspot.com/-CHAZTpf_8hc/UMJV4axe9dI/AAAAAAAAAC8/S2rT5DIt-ok/s72-c/history-api-diagram-2.png") (height . "72") (width . "72")))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-3288544544817065443") (published nil "2012-12-04T18:13:00.003-08:00") (updated nil "2012-12-04T18:24:21.742-08:00") (title ((type . "text")) "Twitter and SMS Spoofing") (content ((type . "html")) "Over the past two days, <a href=\"http://arstechnica.com/security/2012/12/tweeting-with-sms-can-open-door-to-hacks-on-your-twitter-account/\">a few articles</a> have been published about a potential problem concerning the ability to post false updates to another user's SMS-enabled Twitter account, and it has been misreported that US-based Twitter users are currently vulnerable to this type of attack.<br />
<br />
The general concern is that if a user has a Twitter account configured for <a href=\"https://support.twitter.com/articles/14014-twitter-via-sms-faq#\">SMS updates</a>, and an attacker knows that user's phone number, it could be possible for the attacker to send a fake SMS message to Twitter that looks like it's coming from that user's phone number, which would result in a fake post to that user's timeline.<br />
<br />
Most Twitter users interact over the SMS channel using a \"shortcode.\" In the US, for instance, <a href=\"https://support.twitter.com/articles/20170024\">this shortcode</a> is 40404. &nbsp;Because of the way that shortcodes work, it is not possible to send an SMS message with a fake source addressed to them, which eliminates the possibility of an SMS spoofing attack to those numbers. <br />
<br />
However, in some countries a Twitter shortcode is <a href=\"https://support.twitter.com/articles/14226#\">not yet available</a>, and in those cases Twitter users interact over the SMS channel using a \"longcode.\" A longcode is basically just a normal looking phone number. &nbsp;Given that it <i>is</i> possible to send an SMS message with a fake source address to these numbers, we have offered <a href=\"https://support.twitter.com/groups/34-apps-sms-and-mobile/topics/153-twitter-via-sms/articles/20169928-how-to-use-pins-with-sms#\">PIN protection</a> to users who sign up with a longcode since 2007. &nbsp;As of August of this year, we have additionally disallowed posting through longcodes for users that have an available shortcode.<br />
<br />
It has been misreported that US-based Twitter users are currently vulnerable to a spoofing attack because PIN protection is unavailable for them. &nbsp;By having a shortcode, PIN protection isn't necessary for US-based Twitter users, because they are not vulnerable to SMS spoofing. &nbsp;We only provide the option for PIN protection in cases where a user could have registered with a longcode that is susceptible to SMS spoofing.<br />
<br />
We work hard to protect our users from these kinds of threats and many others, and will continue to keep Twitter a site deserving of your trust.&nbsp; <br />
<br />
Posted by Moxie Marlinspike - <a href=\"https://twitter.com/moxie\">@moxie</a><br />
Engineering Manager, Product Security <br />
<br />") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3288544544817065443"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3288544544817065443"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/12/twitter-and-sms-spoofing.html") (title . "Twitter and SMS Spoofing"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif"))))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-649228845742278151") (published nil "2012-11-15T15:23:00.000-08:00") (updated nil "2012-11-15T15:23:16.299-08:00") (title ((type . "text")) "Discover with a new lens: Twitter cards") (content ((type . "html")) "<p>As you already know, there’s a myriad of things shared on Twitter every day, and not just 140 characters of text. There are links to breaking news stories, images from current events, and the latest activity from those you follow.</p><p>We want Discover to be the place where you find the best of that content relevant to you, even if you don’t necessarily know everyone involved. This is why we’ve introduced several improvements to Discover on twitter.com over the last few months. For example we redesigned it to show a <a href=\"http://blog.twitter.com/2012/09/more-tweets-to-discover.html\">continuous stream of Tweets</a> with photos and links to websites, in which you can also now see Tweets from activity, based on what your network favorites. We also added new signals to better blend together all the most relevant Tweets for you, and implemented <a href=\"https://twitter.com/twitter/status/266338665540755457\">polling</a> so you know whenever there are fresh Tweets to see.</p><blockquote class=\"twitter-tweet\"><p>Have you checked Discover lately? A new notification at the top of your stream shows when new Tweets are available. <a href=\"http://t.co/dL2NYafx\" title=\"http://twitter.com/twitter/status/266338665540755457/photo/1\">twitter.com/twitter/status…</a></p>&mdash; Twitter (@twitter) <a href=\"https://twitter.com/twitter/status/266338665540755457\" data-datetime=\"2012-11-08T00:37:41+00:00\">November 8, 2012</a></blockquote><script src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><br />
<p>Today we're introducing a new version of Discover for mobile that brings many of these features to your iPhone or Android phone. For this new release, we've completely re-done the backend and user interface to take advantage of <a href=\"https://dev.twitter.com/docs/cards\">Twitter cards</a>.</p><p>Using Twitter cards, you’ll now see Tweets in Discover with links to news and photos rather than the former story previews which were not interactive. And supporting Twitter cards on the backend means we can more directly improve the user experience in our native apps, too. You’ll see content from cards partners display as a previews in the stream, so that you’ll get headlines and publication names for story summaries and photo previews rather than shortened URLs. </p><p>All of this adds up to fewer taps, fewer screen views and more content for you to enjoy, faster. Of course, you can tap through to the details view for richer story summaries, bigger photos and the ability to reply, favorite or retweet Tweets.</p><p>We think this set of updates delivers the most engaging Discover experience yet, and we hope you enjoy the experience as much as we've enjoyed creating it.</p><p>Posted by Daniel Loreto - <a href=\"https://twitter.com/danielloreto\">@DanielLoreto</a><br />
Engineering Manager, Search and Relevance</p>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/649228845742278151"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/649228845742278151"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/11/discover-with-new-lens-twitter-cards.html") (title . "Discover with a new lens: Twitter cards"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif"))))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-3117912966130251114") (published nil "2012-11-12T13:32:00.000-08:00") (updated nil "2012-11-12T13:53:46.809-08:00") (title ((type . "text")) "Dimension Independent Similarity Computation (DISCO)") (content ((type . "html")) "MapReduce is a programming model for processing large data sets, typically used to do distributed computing on clusters of commodity computers. With large amount of processing power at hand, it’s very tempting to solve problems by brute force. However, we often combine clever sampling techniques with the power of MapReduce to extend its utility.<br />
<br />
Consider the problem of finding all pairs of similarities between D indicator (0/1 entries) vectors, each of dimension N. In particular we focus on cosine similarities between all pairs of D vectors in R^N. Further assume that each dimension is L-sparse, meaning each dimension has at most L non-zeros across all points. For example, typical values to compute similarities between all pairs of a subset of Twitter users can be:<br />
<br />
D = 10M<br />
N = 1B<br />
L = 1000<br />
<br />
Since the dimensions are sparse, it is natural to store the points dimension by dimension. To compute cosine similarities, we can easily feed each dimension t into MapReduce by using the following Mapper and Reducer combination<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://4.bp.blogspot.com/-_3IPLL6vJLg/UKFsYMRgbTI/AAAAAAAAAZQ/dqreJhdAjUo/s1600/image02.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"71\" src=\"http://4.bp.blogspot.com/-_3IPLL6vJLg/UKFsYMRgbTI/AAAAAAAAAZQ/dqreJhdAjUo/s640/image02.png\" width=\"512\" /></a></div>
<br />
Where #(w) counts the number of dimensions in which point w occurs, and #(w1, w2) counts the number of dimensions in which w1 and w2 co-occur, i.e., the dot product between w1 and w2. The steps above compute all dot products, which will then be scaled by the cosine normalization factor.<br />
<br />
There are two main complexity measures for MapReduce: “shuffle size”, and “reduce-key complexity”, defined shortly (Ashish Goel and Kamesh Munagala 2012). It can be easily shown that the above mappers will output on the order of O(NL^2) emissions, which for the example parameters we gave is infeasible. The number of emissions in the map phase is called the “shuffle size”, since that data needs to be shuffled around the network to reach the correct reducer.<br />
<br />
Furthermore, the maximum number of items reduced to a single key is at most #(w1, w2), which can be as large as N. Thus the “reduce-key complexity” for the above scheme is N.<br />
<br />
We can drastically reduce the shuffle size and reduce-key complexity by some clever sampling:<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://1.bp.blogspot.com/-34ZR2UwBq58/UKFsEADJLVI/AAAAAAAAAZE/2wSxCTdGU5A/s1600/image01.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"70\" src=\"http://1.bp.blogspot.com/-34ZR2UwBq58/UKFsEADJLVI/AAAAAAAAAZE/2wSxCTdGU5A/s640/image01.png\" width=\"512\" /></a></div>
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://1.bp.blogspot.com/-9E4sZjm3FF8/UKFqmjiPIPI/AAAAAAAAAYs/V6ejserefzs/s1600/image00.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" src=\"http://1.bp.blogspot.com/-9E4sZjm3FF8/UKFqmjiPIPI/AAAAAAAAAYs/V6ejserefzs/s1600/image00.png\" /></a></div>
<br />
Notation: p and ε are oversampling parameters.<br />
<br />
In this case, the output of the reducers are random variables whose expectations are the cosine similarities. Two proofs are needed to justify the effectiveness of this scheme. First, that the expectations are indeed correct and obtained with high probability, and second, that the shuffle size is greatly reduced. <br />
<br />
We prove both of these claims in (Reza Bosagh-Zadeh and Ashish Goel 2012). In particular, in addition to correctness, we prove that the shuffle size of the above scheme is only O(DL log(D)/ε), with no dependence on the “dimension” N, hence the name.<br />
<br />
This means as long as you have enough mappers to read your data, you can use the DISCO sampling scheme to make the shuffle size tractable. Furthermore, each reduce key gets at most O(log(D)/ε) values, thus making the reduce-key complexity tractable too. <br />
<br />
Within Twitter, we use the DISCO sampling scheme to compute similar users. We have also used the scheme to find highly similar pairs of words, by taking each dimension to be the indicator vector that signals in which Tweets the word appears. We further empirically verify the claims and observe large reductions in shuffle size, with details in the <a href=\"http://arxiv.org/abs/1206.2082\">paper</a>.<br />
<br />
Finally, this sampling scheme can be used to implement many other similarity measures. For Jaccard Similarity, we improve the implementation of the well-known MinHash (http://en.wikipedia.org/wiki/MinHash) scheme on Map-Reduce.<br />
<br />
Posted by <br />
Reza Zadeh (<a href=\"http://twitter.com/Reza_Zadeh\">@Reza_Zadeh</a>) and Ashish Goel (<a href=\"http://twitter.com/ashishgoel\">@ashishgoel</a>) - Personalization &amp; Recommendation Systems Group and Revenue Group<br />
<br />
<br />
<i>Bosagh-Zadeh, Reza and Goel, Ashish (2012), <a href=\"http://arxiv.org/abs/1206.2082\">Dimension Independent Similarity Computation, arXiv:1206.2082</a><br />
<br />
Goel, Ashish and Munagala, Kamesh (2012), <a href=\"http://www.stanford.edu/~ashishg/papers/mapreducecomplexity.pdf\">Complexity Measures for Map-Reduce, and Comparison to Parallel Computing</a>, http://www.stanford.edu/~ashishg/papers/mapreducecomplexity.pdf</i>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3117912966130251114"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3117912966130251114"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/11/dimension-independent-similarity.html") (title . "Dimension Independent Similarity Computation (DISCO)"))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://4.bp.blogspot.com/-_3IPLL6vJLg/UKFsYMRgbTI/AAAAAAAAAZQ/dqreJhdAjUo/s72-c/image02.png") (height . "72") (width . "72")))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-3939144769853576444") (published nil "2012-11-07T11:40:00.000-08:00") (updated nil "2012-11-07T11:40:54.499-08:00") (title ((type . "text")) "Bolstering our infrastructure") (content ((type . "html")) "Last night, the world tuned in to Twitter to share the election results as U.S. voters chose a president and settled many other campaigns. Throughout the day, people sent more than 31 million election-related Tweets (which contained certain key terms and relevant hashtags). And as results rolled in, we tracked the surge in election-related Tweets at 327,452 Tweets per minute (TPM). These numbers reflect the largest election-related Twitter conversation during our 6 years of existence, though they don’t capture the total volume of all Tweets yesterday.<br />
<br />
As an engineering team, we keep an eye on all of the activity across the platform –– in particular, on the number of Tweets per second (TPS). Last night, Twitter averaged about 9,965 TPS from 8:11pm to 9:11pm PT, with a one-second peak of 15,107 TPS at 8:20pm PT and a one-minute peak of 874,560 TPM. Seeing a sustained peak over the course of an entire event is a change from the way people have previously turned to Twitter during live events. <br />
<br />
In the past, we’ve generally experienced short-lived roars related to the clock striking midnight on <a href=\"http://blog.twitter.com/2011/01/celebrating-new-year-with-new-tweet.html\">New Year’s Eve</a> (6,939 Tweets per second, or TPS), the <a href=\"https://twitter.com/twitter/status/92754546824200193\">end of a soccer game</a> (7,196 TPS), or <a href=\"https://twitter.com/twitter/status/92754546824200193\">Beyonce’s pregnancy announcement</a> (8,868 TPS). Those spikes tended to last seconds, maybe minutes at most. Now, rather than brief spikes, we are seeing sustained peaks for hours. Last night is just another example of the traffic pattern we’ve experienced this year –– we also saw this during the <a href=\"http://blog.twitter.com/2012/06/courtside-tweets.html\">NBA Finals</a>, <a href=\"http://blog.twitter.com/2012/08/olympic-and-twitter-records.html\">Olympics Closing Ceremonies</a>, <a href=\"http://blog.twitter.com/2012/09/the-vmas-look-back-via-twitter.html\">VMAs</a>, and <a href=\"http://blog.twitter.com/2012/10/twitters-hip-hop-firmament-barsandstars.html\">Hip-Hop Awards</a>.<br />
<br />
Last night’s numbers demonstrate that as Twitter usage patterns change, Twitter the service can remain resilient. Over time, we have been working to build an infrastructure that can withstand an ever-increasing load. For example, we’ve been steadily <a href=\"http://engineering.twitter.com/2011/03/building-faster-ruby-garbage-collector.html\">optimizing the Ruby runtime</a>. And, as part of our ongoing migration away from Ruby, we’ve reconfigured the service so traffic from our mobile clients hits the Java Virtual Machine (JVM) stack, avoiding the Ruby stack altogether. <br />
<br />
Of course, we still have plenty more to do. We’ll continue to measure and evaluate event-based traffic spikes, including their size and duration. We’ll continue studying the best ways to accommodate expected and unexpected traffic surges and high volume conversation during planned real-time events such as elections and championship games, as well as unplanned events such as natural disasters.<br />
<br />
The bottom line: No matter when, where or how people use Twitter, we need to remain accessible 24/7, around the world. We’re hard at work delivering on that vision.<br />
<br />
- Mazen Rawashdeh, VP of Infrastructure Operations Engineering (<a href=\"http://twitter.com/mazenra\">@mazenra</a>)") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3939144769853576444"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3939144769853576444"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/11/bolstering-our-infrastructure.html") (title . "Bolstering our infrastructure"))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif"))))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-6800954039717501337") (published nil "2012-10-11T10:05:00.000-07:00") (updated nil "2012-10-11T10:07:44.399-07:00") (title ((type . "text")) "Open Sourcing Clutch.IO") (content ((type . "html")) "Clutch is an easy-to-integrate library for native iOS applications designed to help you develop faster, deploy instantly and run A/B tests. When Clutch co-founders Eric Florenzano (<a href=\"http://twitter.com/ericflo\">@ericflo</a>) and Eric Maguire (<a href=\"http://twitter.com/etmaguire\">@etmaguire</a>) recently joined the flock, they <a href=\"http://blog.clutch.io/post/29340796276/clutch-joins-the-flock\">promised</a> that everything you need to run Clutch on your own infrastructure would be available.<br />
<br />
<blockquote class=\"twitter-tweet\"><p>We are incredibly excited to announce that Twitter has acquired the IP of Clutch.io and we start work there today! <a href=\"http://t.co/chQ1iatB\" title=\"http://blog.clutch.io/post/29340796276/clutch-joins-the-flock\">blog.clutch.io/post/293407962…</a></p>&mdash; Clutch IO (<a href=\"http://twitter.com/clutchio\">@clutchio</a>) <a href=\"https://twitter.com/clutchio/status/235043048952840192\" data-datetime=\"2012-08-13T16:00:04+00:00\">August 13, 2012</a></blockquote><script src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><br />
<br />
Today, we’ve open-sourced the <a href=\"https://github.com/clutchio\">code</a> on GitHub under the Apache Public License 2.0, now with improved documentation to help get you started. As a reminder the hosted service will be active and supported until November 1. After that you can use the open-sourced code to run it on your own and modify it to your needs. Read more about how to <a href=\"https://github.com/clutchio/clutch\">set up your instance on GitHub</a> and ask any questions on the <a href=\"https://groups.google.com/forum/#!forum/clutchio\">mailing list</a> or on Twitter via <a href=\"http://twitter.com/clutchio\">@clutchio</a>.<br />
<br />
Releasing this code as an open source project is just the beginning. There are still plenty of areas for improvement from better documentation to an easier setup process. Now that the project is publicly available, we look forward to seeing a community blossom and grow the project into something greater.<br />
<br />
- Chris Aniszczyk, Manager of Open Source (<a href=\"http://twitter.com/cra\">@cra</a>)") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6800954039717501337"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6800954039717501337"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/10/open-sourcing-clutchio.html") (title . "Open Sourcing Clutch.IO"))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif"))))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-4925259586341921648") (published nil "2012-09-24T09:48:00.000-07:00") (updated nil "2012-09-24T09:48:22.177-07:00") (title ((type . "text")) "Scalding 0.8.0 and Algebird") (content ((type . "html")) "<p>Earlier this year we open sourced <a href=\"https://github.com/twitter/scalding\">Scalding</a>, a Scala API for <a href=\"http://www.cascading.org/\">Cascading</a> that makes it easy to write big data jobs in a syntax that’s simple and concise. We use Scalding heavily — for everything from custom ad targeting algorithms to PageRank on the Twitter graph. Since open sourcing Scalding, we’ve been improving our documentation by adding a <a href=\"https://github.com/twitter/scalding/wiki/Getting-Started\">Getting Started</a> guide and a <a href=\"https://github.com/twitter/scalding/wiki/Rosetta-Code\">Rosetta Code</a> page that contains several MapReduce tasks translated from other frameworks (e.g., Pig and Hadoop Streaming) into Scalding. </p><p>Today we are excited to tell you about the 0.8.0 release of Scalding.</p><h3>What's new</h3><p>There are a lot of <a href=\"https://github.com/twitter/scalding/blob/develop/CHANGES.md\">new features</a>, for example, Scalding now includes a <a href=\"https://github.com/twitter/scalding/wiki/Matrix-API-Reference\">type-safe Matrix API</a>. The Matrix API makes expressing matrix sums, products, and simple algorithms like cosine similarity trivial. The <a href=\"https://github.com/twitter/scalding/wiki/Type-safe-api-reference\">type-safe Pipe API</a> has some new functions and a few bug fixes.</p><p>In the familiar <a href=\"https://github.com/twitter/scalding/wiki/Fields-based-API-Reference\">Fields API</a>, we’ve added the ability to add type information to fields which allows scalding to pick up Ordering instances so that grouping on almost any scala collection becomes easy. There is now a function to estimate set size in groupBy: <a href=\"https://github.com/twitter/scalding/blob/develop/src/main/scala/com/twitter/scalding/ReduceOperations.scala#L62\">approxUniques</a> (a naive implementation requires two groupBys, but this function uses <a href=\"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.142.9475\">HyperLogLog</a>). Since many aggregations are simple transformations of existing Monoids (associative operations with a zero), we added mapPlusMap to simplify implementation of many reducing operations (<a href=\"https://github.com/twitter/scalding/blob/develop/src/main/scala/com/twitter/scalding/ReduceOperations.scala#L50\">count how many functions are implemented in terms of mapPlusMap</a>).</p><p>Cascading and scalding try to optimize your job to some degree, but in some cases for optimal performance, some hand-tuning is needed. This release adds three features to make that easier:<br />
<ul><li><a href=\"https://github.com/twitter/scalding/blob/develop/src/main/scala/com/twitter/scalding/RichPipe.scala#L253\">forceToDisk</a> forces a materialization and helps when you know the prior operation filters almost all data and should not be limited to just before a join or merge. </li>
<li>Map-side aggregation in Cascading is done in memory with a threshold on when to spill and poor tuning can result in performance issues or out of memory errors. To help alleviate these issues, we now expose a function in groupBy to specify the <a href=\"https://github.com/twitter/scalding/blob/develop/src/main/scala/com/twitter/scalding/GroupBuilder.scala#L91\">spillThreshold.</a></li>
<li>We make it easy for Scalding Jobs to control the Hadoop configuration by allowing <a href=\"https://github.com/twitter/scalding/blob/develop/src/main/scala/com/twitter/scalding/Job.scala#L98\">overriding</a> of the config.</li>
</ul></p><h3>Algebird</h3><p><a href=\"https://github.com/twitter/algebird\">Algebird</a> is our lightweight abstract algebra library for Scala and is targeted for building aggregation systems (such as <a href=\"https://github.com/nathanmarz/storm\">Storm</a>). It was originally developed as part of Scalding's Matrix API, but almost all of the common reduce operations we care about in Scalding turn out to be instances of Monoids. This common library gives Map-merge, Set-union, List-concatenation, primitive-type algebra, and some fancy Monoids such as HyperLogLog for set cardinality estimation. Algebird has no dependencies and should be easy to use from any scala project that is doing aggregation of data or data-structures.  For instance in the Algebird repo, type “sbt console” and then:</p><p><pre>scala> import com.twitter.algebird.Operators._
import com.twitter.algebird.Operators._</pre></p><p><pre>scala> Map(1 -> 3, 2 -> 5, 3 -> 7, 5 -> 1) + Map(1 -> 1, 2 -> 1)
res0: scala.collection.immutable.Map[Int,Int] = Map(1 -> 4, 2 -> 6, 3 -> 7, 5 -> 1)</pre></p><p><pre>scala> Set(1,2,3) + Set(3,4,5)
res1: scala.collection.immutable.Set[Int] = Set(5, 1, 2, 3, 4)</pre></p><p><pre>scala> List(1,2,3) + List(3,4,5)
res2: List[Int] = List(1, 2, 3, 3, 4, 5)</pre></p><p><pre>scala> Map(1 -> 3, 2 -> 4, 3 -> 1) * Map(2 -> 2)
res3: scala.collection.immutable.Map[Int,Int] = Map(2 -> 8)</pre></p><p><pre>scala> Map(1 -> Set(2,3), 2 -> Set(1)) + Map(2 -> Set(2,3))
res4: scala.collection.immutable.Map[Int,scala.collection.immutable.Set[Int]] = Map(1 -> Set(2, 3), 2 -> Set(1, 2, 3))</pre></p><h3>Future work</h3><p>We are thrilled to see industry recognition of Scalding; the project has received a <a href=\"http://www.infoworld.com/slideshow/65089/bossie-awards-2012-the-best-open-source-databases-202354#slide3\">Bossie Award</a> and there’s a community building around Scalding, with adopters like Etsy and eBay using it in production. In the near future, we are looking at adding optimized skew joins, refactoring the code base into smaller components and using Thrift and Protobuf lzo compressed data. On the whole, we look forward to improving documentation and nurturing a community around Scalding as we approach a 1.0 release.</p><p>If you’d like to help work on any features or have any bug fixes, we’re always looking for contributions. Just submit a pull request to say hello or reach out to us on the <a href=\"https://groups.google.com/forum/?fromgroups#!forum/cascading-user\">mailing list</a>. If you find something missing or broken, report it in the <a href=\"https://github.com/twitter/scalding/issues\">issue tracker</a>.</p><h3>Acknowledgements</h3><p>Scalding and Algebird are built by a community. We’d like to acknowledge the following folks who contributed to the project: Oscar Boykin (<a href=\"https://twitter.com/posco\">@posco</a>), Avi Bryant (<a href=\"https://twitter.com/avibryant\">@avibryant</a>), Edwin Chen (<a href=\"https://twitter.com/echen\">@echen</a>), Sam Ritchie (<a href=\"https://twitter.com/sritchie\">@sritchie</a>), Flavian Vasile (<a href=\"https://twitter.com/flavianv\">@flavianv</a>) and Argyris Zymnis (<a href=\"https://twitter.com/argyris\">@argyris</a>). </p><p>Follow <a href=\"https://twitter.com/scalding\">@scalding</a> on Twitter to stay in touch!</p><p>Posted by Chris Aniszczyk <a href=\"https://twitter.com/cra\">@cra</a><br />
Manager, Open Source</p><a href=\"\"></a>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/4925259586341921648"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/4925259586341921648"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/09/scalding-080-and-algebird.html") (title . "Scalding 0.8.0 and Algebird"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif"))))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-8363723829931580072") (published nil "2012-08-27T12:10:00.000-07:00") (updated nil "2012-08-27T12:10:02.534-07:00") (title ((type . "text")) "Joining the Linux Foundation") (content ((type . "html")) "<p>Today Twitter officially joins the Linux Foundation (<a href=\"https://twitter.com/linuxfoundation\">@linuxfoundation</a>), the nonprofit consortium dedicated to protecting and promoting the growth of the Linux operating system. <br />
</p><blockquote class=\"twitter-tweet\"><p>happy 21st birthday to <a href=\"https://twitter.com/search/?q=%23linux\"><s>#</s><b>linux</b></a>, we're proud to support the <a href=\"https://twitter.com/linuxfoundation\"><s>@</s><b>linuxfoundation</b></a> <a href=\"http://t.co/sJQxwdtF\" title=\"http://www.wired.com/thisdayintech/2009/08/0825-torvalds-starts-linux/\">wired.com/thisdayintech/…</a></p>&mdash; Twitter Open Source (@TwitterOSS) <a href=\"https://twitter.com/TwitterOSS/status/239413692314300417\" data-datetime=\"2012-08-25T17:27:26+00:00\">August 25, 2012</a></blockquote><script src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><br />
<p>We have tens of thousands machines running all types of services that run a tweaked version of Linux. One reason we support Linux is that open source development lets us control our destiny — we are able to innovate faster given the flexibility to customize based on our needs. We also love the large, stable and mature development community with whom we can collaborate to move the state of the kernel forward.  If you look at the latest <a href=\"http://go.linuxfoundation.org/who-writes-linux-2012\">Linux Development Report</a>, there are more than 7,800 developers from 800 different companies contributing to make Linux better for everyone.</p><p>We use a couple different kernel versions of Linux and tend to favor stability. As of today, we are mainly on the 2.6.39 kernel release. We tweak the kernel by adding some patches such as enhanced core dump functionality, <a href=\"http://unionfs.filesystems.org/\">UnionFS</a> support and the ability to allow <a href=\"https://developers.google.com/speed/articles/tcp_initcwnd_paper.pdf\">TCP congestion window</a> to be set on a socket basis.</p><p>We expect to further customize the kernel to optimize it for our production environment and contribute some of the work upstream. If you’re interested in hacking on kernel performance at the scale of Twitter and participating in the Linux community, we’d love to <a href=\"mailto:opensource@twitter.com\">hear from you</a> and speak with you at <a href=\"http://events.linuxfoundation.org/events/linuxcon\">LinuxCon</a> this week.</p><p>And of course, we wish Linux a <a href=\"https://groups.google.com/forum/?fromgroups=#!msg/comp.os.minix/dlNtH7RRrGA/SwRavCzVE7gJ\">happy 21st birthday</a>.</p><p>Posted by Chris Aniszczyk (<a href=\"https://twitter.com/cra\">@cra</a>), Manager of Open Source </p>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/8363723829931580072"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/8363723829931580072"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/08/joining-linux-foundation.html") (title . "Joining the Linux Foundation"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif"))))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-7784070147488545788") (published nil "2012-08-24T12:06:00.000-07:00") (updated nil "2012-08-24T12:06:57.283-07:00") (title ((type . "text")) "How we spent our Summer of Code") (content ((type . "html")) "<p>For the first time, <a href=\"http://engineering.twitter.com/2012/05/summer-of-code-at-twitter.html\">Twitter participated</a> in the <a href=\"http://code.google.com/soc/\">Google Summer of Code</a> (GSoC) and we want to share news on the resulting open source activities. Unlike many GSoC participating organizations that focus on a single ecosystem, we have a variety of projects spanning multiple programming languages and communities. </p><blockquote class=\"twitter-tweet\"><p>it's \"pencils down\" for <a href=\"https://twitter.com/gsoc\"><s>@</s><b>gsoc</b></a>, thank you so much to our mentors and student interns <a href=\"https://twitter.com/kl_7\"><s>@</s><b>kl_7</b></a> <a href=\"https://twitter.com/fbru02\"><s>@</s><b>fbru02</b></a> <a href=\"https://twitter.com/rubeydoo\"><s>@</s><b>rubeydoo</b></a> for hacking with us this summer</p>&mdash; Twitter Open Source (@TwitterOSS) <a href=\"https://twitter.com/TwitterOSS/status/238707212116185088\" data-datetime=\"2012-08-23T18:40:08+00:00\">August 23, 2012</a></blockquote><script src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><br />
<p>We accepted three students to work on a few projects:<br />
<ul><li>Kirill Lashuk (<a href=\"https://twitter.com/intent/user?screen_name=KL_7\">@KL_7</a>) mentored by Cameron Dutro (<a href=\"https://twitter.com/intent/user?screen_name=camertron\">@camertron</a>) added more internationalization and localization capabilities to Ruby via the <a href=\"https://github.com/twitter/twitter-cldr-rb\">TwitterCLDR</a> project. Among other things, he added the NFKD normalization algorithm, better access to Unicode code points and Unicode Collation Algorithm support, contributed over 6100 total lines of code, countless resource files and prepared the project for a new version of Ruby. His work should help anyone in the Ruby community needing robust internationalization support for their application.</li>
<li>Federico Brubacher (<a href=\"https://twitter.com/intent/user?screen_name=fbru02\">@fbru02</a>) mentored by Nathan Marz (<a href=\"https://twitter.com/intent/user?screen_name=nathanmarz\">@nathanmarz</a>) spent time kick starting and adding machine learning capabilities (<a href=\"https://github.com/nathanmarz/storm-contrib/tree/storm-ml/storm-ml\">see the code</a>) to <a href=\"http://storm-project.net/\">Twitter Storm</a>.</li>
<li>Ruben Oanta (<a href=\"https://twitter.com/intent/user?screen_name=rubeydoo\">@rubeydoo</a>) mentored by Marius Eriksen (<a href=\"https://twitter.com/intent/user?screen_name=marius\">@marius</a>) wrote a MySQL client (<a href=\"https://github.com/twitter/finagle/pull/98/files\">see the code</a>) for our RPC system, <a href=\"http://twitter.github.com/finagle/\">Twitter Finagle</a>. It supports both the binary and text protocols, allowing us to use both regular queries as well as prepared statements. His work provides a great foundation for our database clients to make better use of all of our shared infrastructure. We were also thrilled to collaborate with Tumblr’s Blake Matheny (<a href=\"https://twitter.com/intent/user?screen_name=bmatheny\">@bmatheny</a>) on mentoring this project.</li>
</ul></p><p>As part of GSoC, students and mentoring organizations receive a stipend. We are donating our portion of the stipend to <a href=\"http://www.girlswhocode.com/\">Girls Who Code</a>, an organization <a href=\"http://blog.twitter.com/2012/06/working-with-girls-who-code.html\">we support</a> that introduces high school girls to software development. </p><p>We really enjoyed the opportunity to take part in Google Summer of Code. Thank you to our three students, mentors and to Google for the program, we look forward to next year.</p><p>- Chris Aniszczyk (<a href=\"https://twitter.com/intent/user?screen_name=cra\">@cra</a>), Manager of Open Source</p>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/7784070147488545788"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/7784070147488545788"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/08/how-we-spent-our-summer-of-code.html") (title . "How we spent our Summer of Code"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif"))))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-3558478185343378834") (published nil "2012-08-16T09:59:00.000-07:00") (updated nil "2012-08-16T09:59:26.370-07:00") (title ((type . "text")) "Crowdsourced data analysis with Clockwork Raven") (content ((type . "html")) "<p>Today, we’re excited to open source <a href=\"http://twitter.github.com/clockworkraven/\">Clockwork Raven</a>, a web application that allows users to easily submit data to <a href=\"http://en.wikipedia.org/wiki/Amazon_Mechanical_Turk\">Mechanical Turk</a> for manual review and then analyze that data. Clockwork Raven steps in to do what algorithms cannot: it sends your data analysis tasks to real people and gets fast, cheap and accurate results. We use Clockwork Raven to gather tens of thousands of judgments from Mechanical Turk users every week.</p><h3>Motivation</h3><p>We’re huge fans of human evaluation at Twitter and how it can aid data analysis. In the past, we’ve used systems like Mechanical Turk and CrowdFlower, as well as an internal system where we train dedicated reviewers and have them come in to our offices. However, as we scale up our usage of human evaluation, we needed a better system. This is why we built Clockwork Raven and designed it with several important goals in mind:<br />
<ul><li><b>Requires little technical skill to use</b>: The current Mechanical Turk web interface requires knowledge of HTML to do anything beyond very basic tasks.<br />
</li>
<li><b>Uniquely suited for our needs</b>: Many of our evaluations require us to embed tweets and timelines in the task. We wanted to create reusable components that would allow us to  easily add these widgets to our tasks.</li>
<li><b>Scalable</b>: Manually training reviews doesn’t scale as well as a system that crowd sources the work through Mechanical Turk.</li>
<li><b>Reliable</b>: We wanted controls over who’s allowed to complete our evaluations, so we can ensure we’re getting top-notch results.</li>
<li><b>Low barrier of entry</b>: We wanted a tool that everyone in the company could use to launch evaluations.</li>
<li><b>Integrated analysis</b>: We wanted a tool that would analyze the data we gather, in addition to provide the option to export a JSON or CSV to import into tools like R or a simple spreadsheet.</li>
</ul></p><h3>Features</h3><p>In Clockwork Raven, you create an evaluation by submitting a table of data (CSV or JSON). Each row of this table corresponds to a task that a human will complete. We build a template for the tasks in the Template Builder, then submit them to Mechanical Turk and Clockwork Raven tracks how many responses we’ve gotten. Once all the tasks are complete, we can import the results into Clockwork Raven where they’re presented in a configurable bar chart and can be exported to a number of data formats.</p><p>Here’s the features we’ve built into Clockwork Raven to address the goals above:<br />
<ul><li>Clockwork Raven has a simple drag-and-drop builder not unlike the form builder in Google Docs. We can create headers and text sections, add multiple-choice and free-response questions, and insert data from a column in the uploaded data. <br /><br />
<img src=\"http://twitter.github.com/clockworkraven/img/thumbs/template-builder.png\" /></li>
<li>The template builder has pre-built components for common items we need to put in our evaluations, like users and Tweets. It’s easy to build new components, so you can design your own. In the template builder, we can pass parameters (like the identifier of the Tweet we’re embedding) into the component. Here’s how we insert a tweet:<br /><br />
<img src=\"http://twitter.github.com/clockworkraven/img/thumbs/components.png\" /></li>
<li>Clockwork Raven submits jobs to Mechanical Turk. We can get back thousands of judgements in an hour or less. And because Mechanical Turk workers come from all over the world, we get results whenever we want them.</li>
<li>Clockwork Raven allows you to manage a list of Trusted Workers. We’ve found that having a hand-picked list of workers is the best way to get great results. We can expand our pool by opening up our tasks beyond our hand-picked set and choosing workers who are doing a great job with our tasks.</li>
<li>Clockwork Raven authenticates against any LDAP directory (or you can manage user accounts manually). That means that you can give a particular LDAP group at your organization access to Clockwork Raven, and they can log in with their own username and password. No shared accounts, and full accountability for who’s spending what. You can also give “unprivileged” access to some users, allowing them to try Clockwork Raven out and submit evaluations to the Mechanical Turk sandbox (which is free), but not allowing them to submit tasks that cost money without getting approval.</li>
<li>Clockwork Raven has a built-in data analysis tool that lets you chart your results across multiple dimensions of data and view individual results:<br /><br />
<img src=\"http://twitter.github.com/clockworkraven/img/thumbs/results.png\" /></li>
</ul></p><h3>Future Work</h3><p>We’re actively developing Clockwork Raven and improving it over time. Our target for the next release is a comprehensive REST API that works with JSON (possibly Thrift as well). We’re hoping this will allow us to build Clockwork Raven into our workflows, as well as enable its use for real-time human evaluation. We’re also working on better ways of managing workers, by automatically managing the group of trusted workers through qualification tasks and automated analysis of untrusted users’ work.</p><p>If you’d like to help work on these features, or have any bug fixes, other features, or documentation improvements, we’re always looking for contributions. Just submit a pull request to say hello or reach out to us on the <a href=\"https://groups.google.com/forum/?fromgroups#!forum/twitter-clockworkraven\">mailing list</a>. If you find something missing or broken, report it in the <a href=\"https://github.com/twitter/clockworkraven/issues\">issue tracker</a>.</p><h3>Acknowledgements</h3><p>Clockwork Raven was primarily authored by Ben Weissmann (<a href=\"https://twitter.com/benweissmann\">@benweissmann</a>). In addition, we’d like to acknowledge the following folks who contributed to the project: Edwin Chen (<a href=\"https://twitter.com/echen\">@echen</a>) and Dave Buchfuhrer (<a href=\"https://twitter.com/daveFNbuck\">@daveFNbuck</a>).</p><p>Follow <a href=\"https://twitter.com/clockworkraven\">@clockworkraven</a> on Twitter to stay in touch!</p><p>- Chris Aniszczyk, Manager of Open Source (<a href=\"https://twitter.com/clockworkraven\">@cra</a>)</p>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3558478185343378834"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3558478185343378834"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/08/crowdsourced-data-analysis-with.html") (title . "Crowdsourced data analysis with Clockwork Raven"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif"))))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-1108671060552687033") (published nil "2012-08-07T11:06:00.000-07:00") (updated nil "2012-08-07T11:11:03.800-07:00") (title ((type . "text")) "Visualizing Hadoop with HDFS-DU") (content ((type . "html")) "<p>We are a heavy adopter of <a href=\"https://github.com/twitter/hdfs-du\">Apache Hadoop</a> with a large set of data that resides in its clusters, so it’s important for us to understand how these resources are utilized. At our July <a href=\"http://blog.twitter.com/2012/01/hack-week-twitter.html\">Hack Week</a>, we experimented with developing <a href=\"https://github.com/twitter/hdfs-du\">HDFS-DU</a> to provide us an interactive visualization of the underlying Hadoop Distributed File System (HDFS). The project aims to monitor different snapshots for the entire HDFS system in an interactive way, showing the size of the folders and the rate at which the size changes. It can also effectively identify efficient and inefficient file storage and highlight nodes in the file system where this is happening.</p><p>HDFS-DU provides the following in a web user interface:<br />
<ul><li>A TreeMap visualization where each node is a folder in HDFS. The area of each node can be relative to the size or number of descendents</li>
<li>A tree visualization showing the topology of the file system</li>
</ul></p><p>HDFS-DU is built using the following front-end technologies:<br />
<ul><li><a href=\"http://d3js.org/\">D3.js</a>: for tree visualization</li>
<li><a href=\"http://thejit.org/\">JavaScript InfoVis Toolkit</a>: for TreeMap visualization</li>
</ul></p><h3>Details</h3><p>Below is a screenshot of the HDFS-DU user interface (directory names scrubbed). The user interface is made up of two linked visualizations. The left visualization is a TreeMap and shows parent-child relationships through containment. The right visualization is a tree layout, which displays two levels of depth from the current selected node in the file system. The tree visualization displays extra information for each node on hover.</p><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://1.bp.blogspot.com/-4VPTuVaxVpk/UCFYwAIdpmI/AAAAAAAAAK8/72tbXz3Nd9I/s1600/1.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"352\" width=\"400\" src=\"http://1.bp.blogspot.com/-4VPTuVaxVpk/UCFYwAIdpmI/AAAAAAAAAK8/72tbXz3Nd9I/s400/1.png\" /></a></div><p>You can drill down on the TreeMap by clicking on a node, this would create the same effect as clicking on any tree node. There are two possible layouts for the TreeMap. The default one encodes file size in the area of each node. The second one encodes number of descendents in the area of each node. In the second view it's interesting to spot nodes where storage is inefficient.</p><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://2.bp.blogspot.com/-qSpx6IiGlpc/UCFY-h3c13I/AAAAAAAAALI/eVHAfwuSKA4/s1600/2.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"309\" width=\"400\" src=\"http://2.bp.blogspot.com/-qSpx6IiGlpc/UCFY-h3c13I/AAAAAAAAALI/eVHAfwuSKA4/s400/2.png\" /></a></div><br />
<h3>Future Work</h3><p>This project was created at our July Hack Week and we still consider it beta but useful software. In the future, we would love to improve the front-end client and create a new back-end for a different runtime environment. On the front end, the directory browser, currently on the right, is poorly suited to the task of showing the directory structure.  A view which looks more like a traditional filesystem browser would be more immediately recognizable and make better use of space (it is likely that a javascript file browser exists and could be used instead).  Also, the integration between the current file browser and the TreeMap needs improvement.</p><p>We initially envisioned the TreeMap as a <a href=\"http://en.wikipedia.org/wiki/Voronoi_diagram\">Voronoi TreeMap</a>, however our current implementation of that code ran too slowly to be practical.  We would love to get the Voronoi TreeMap code to work fast enough. We would also like to add the option to use different values to size and color the TreeMap areas.  For example, change in size, creation time, last access time, frequency of access.</p><h3>Acknowledgements</h3><p>HDFS-DU was primarily authored by Travis Crawford (<a href=\"https://twitter.com/tc/\">@tc</a>), Nicolas Garcia Belmonte (<a href=\"https://twitter.com/philogb\">@philogb</a>) and Robert Harris (<a href=\"https://twitter.com/trebor\">@trebor</a>). Given that this is a young project, we always appreciate bug fixes, features and documentation improvements. Feel free to fork the project and send us a pull request on GitHub to say hello. Finally, if you’re interested in visualization and distributed file systems like Hadoop, we’re always looking for engineers to <a href=\"https://twitter.com/jobs\">join the flock.</a></p><p>Follow <a href=\"https://twitter.com/hdfsdu\">@hdfsdu</a> on Twitter to stay in touch!</p><p>- Chris Aniszczyk, Manager of Open Source (<a href=\"https://twitter.com/cra\">@cra</a>)</p>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/1108671060552687033"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/1108671060552687033"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/08/visualizing-hadoop-with-hdfs-du.html") (title . "Visualizing Hadoop with HDFS-DU"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://1.bp.blogspot.com/-4VPTuVaxVpk/UCFYwAIdpmI/AAAAAAAAAK8/72tbXz3Nd9I/s72-c/1.png") (height . "72") (width . "72")))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-1884593817993851033") (published nil "2012-08-02T10:00:00.000-07:00") (updated nil "2012-08-02T10:07:54.477-07:00") (title ((type . "text")) "Trident: a high-level abstraction for realtime computation") (content ((type . "html")) "<p>Trident is a new high-level abstraction for doing realtime computing on top of <a href=\"http://storm-project.net/\">Twitter Storm</a>, available in <a href=\"http://storm-project.net/downloads.html\">Storm 0.8.0</a> (released today). It allows you to seamlessly mix high throughput (millions of messages per second), stateful stream processing with low latency distributed querying. If you're familiar with high level batch processing tools like <a href=\"http://pig.apache.org/\">Pig</a> or <a href=\"http://www.cascading.org/\">Cascading</a>, the concepts of Trident will be very familiar - Trident has joins, aggregations, grouping, functions, and filters. In addition to these, Trident adds primitives for doing stateful, incremental processing on top of any database or persistence store. Trident has consistent, exactly-once semantics, so it is easy to reason about Trident topologies.</p><p>We're really excited about Trident and believe it is a major step forward in Big Data processing. It builds upon Storm's foundation to make realtime computation as easy as batch computation.</p><h2>Example</h2><p>Let's look at an illustrative example of Trident. This example will do two things: </p><ol><li><p>Compute streaming word count from an input stream of sentences</p></li>
<li><p>Implement queries to get the sum of the counts for a list of words</p></li>
</ol><p>For the purposes of illustration, this example will read an infinite stream of sentences from the following source:</p><script src=\"https://gist.github.com/3234617.js?file=gistfile1.java\"></script><br />
<p>This spout cycles through that set of sentences over and over to produce the sentence stream. Here's the code to do the streaming word count part of the computation:</p><script src=\"https://gist.github.com/3234621.js?file=gistfile1.java\"></script><br />
<p>Let's go through the code line by line. First a TridentTopology object is created, which exposes the interface for constructing Trident computations. TridentTopology has a method called newStream that creates a new stream of data in the topology reading from an input source. In this case, the input source is just the FixedBatchSpout defined from before. Input sources can also be queue brokers like Kestrel or Kafka. Trident keeps track of a small amount of state for each input source (metadata about what it has consumed) in Zookeeper, and the \"spout1\" string here specifies the node in Zookeeper where Trident should keep that metadata.</p><p>Trident processes the stream as small batches of tuples. For example, the incoming stream of sentences might be divided into batches like so:</p><p><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-dvyMvMMVyQg/UBqwN1OQnoI/AAAAAAAAAKQ/uaYoI0UH9fU/s1600/batched-stream.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"240\" width=\"400\" src=\"http://4.bp.blogspot.com/-dvyMvMMVyQg/UBqwN1OQnoI/AAAAAAAAAKQ/uaYoI0UH9fU/s400/batched-stream.png\" /></a></div></p><p>Generally the size of those small batches will be on the order of thousands or millions of tuples, depending on your incoming throughput.</p><p>Trident provides a fully fledged batch processing API to process those small batches. The API is very similar to what you see in high level abstractions for Hadoop like Pig or Cascading: you can do group by's, joins, aggregations, run functions, run filters, and so on. Of course, processing each small batch in isolation isn't that interesting, so Trident provides functions for doing aggregations across batches and persistently storing those aggregations - whether in memory, in Memcached, in Cassandra, or some other store. Finally, Trident has first-class functions for querying sources of realtime state. That state could be updated by Trident (like in this example), or it could be an independent source of state.</p><p>Back to the example, the spout emits a stream containing one field called \"sentence\". The next line of the topology definition applies the Split function to each tuple in the stream, taking the \"sentence\" field and splitting it into words. Each sentence tuple creates potentially many word tuples - for instance, the sentence \"the cow jumped over the moon\" creates six \"word\" tuples. Here's the definition of Split:<br />
</p><script src=\"https://gist.github.com/3234623.js?file=gistfile1.java\"></script><br />
<p>As you can see, it's really simple. It simply grabs the sentence, splits it on whitespace, and emits a tuple for each word.</p><p>The rest of the topology computes word count and keeps the results persistently stored. First the stream is grouped by the \"word\" field. Then, each group is persistently aggregated using the Count aggregator. The persistentAggregate function knows how to store and update the results of the aggregation in a source of state. In this example, the word counts are kept in memory, but this can be trivially swapped to use Memcached, Cassandra, or any other persistent store. Swapping this topology to store counts in Memcached is as simple as replacing the persistentAggregate line with this (using <a href=\"https://github.com/nathanmarz/trident-memcached\">trident-memcached</a>), where the \"serverLocations\" variable is a list of host/ports for the Memcached cluster:</p><script src=\"https://gist.github.com/3234632.js?file=gistfile1.java\"></script><br />
<p>The values stored by persistentAggregate represents the aggregation of all batches ever emitted by the stream.</p><p>One of the cool things about Trident is that it has fully fault-tolerant, exactly-once processing semantics. This makes it easy to reason about your realtime processing. Trident persists state in a way so that if failures occur and retries are necessary, it won't perform multiple updates to the database for the same source data.</p><p>The persistentAggregate method transforms a Stream into a TridentState object. In this case the TridentState object represents all the word counts. We will use this TridentState object to implement the distributed query portion of the computation.</p><p>The next part of the topology implements a low latency distributed query on the word counts. The query takes as input a whitespace separated list of words and return the sum of the counts for those words. These queries are executed just like normal RPC calls, except they are parallelized in the background. Here's an example of how you might invoke one of these queries:</p><script src=\"https://gist.github.com/3234636.js?file=gistfile1.java\"></script><br />
<p>As you can see, it looks just like a regular remote procedure call (RPC), except it's executing in parallel across a Storm cluster. The latency for small queries like this are typically around 10ms. More intense DRPC queries can take longer of course, although the latency largely depends on how many resources you have allocated for the computation.</p><p>The implementation of the distributed query portion of the topology looks like this:<br />
</p><script src=\"https://gist.github.com/3234638.js?file=gistfile1.java\"></script><br />
<p>The same TridentTopology object is used to create the DRPC stream, and the function is named \"words\". The function name corresponds to the function name given in the first argument of execute when using a DRPCClient.</p><p>Each DRPC request is treated as its own little batch processing job that takes as input a single tuple representing the request. The tuple contains one field called \"args\" that contains the argument provided by the client. In this case, the argument is a whitespace separated list of words.</p><p>First, the Split function is used to split the arguments for the request into its constituent words. The stream is grouped by \"word\", and the stateQuery operator is used to query the TridentState object that the first part of the topology generated. stateQuery takes in a source of state - in this case, the word counts computed by the other portion of the topology - and a function for querying that state. In this case, the MapGet function is invoked, which gets the count for each word. Since the DRPC stream is grouped the exact same way as the TridentState was (by the \"word\" field), each word query is routed to the exact partition of the TridentState object that manages updates for that word.</p><p>Next, words that didn't have a count are filtered out via the FilterNull filter and the counts are summed using the Sum aggregator to get the result. Then, Trident automatically sends the result back to the waiting client.</p><p>Trident is intelligent about how it executes a topology to maximize performance. There's two interesting things happening automatically in this topology:</p><ol><li><p>Operations that read from or write to state (like persistentAggregate and stateQuery) automatically batch operations to that state. So if there's 20 updates that need to be made to the database for the current batch of processing, rather than do 20 read requests and 20 write requests to the database, Trident will automatically batch up the reads and writes, doing only 1 read request and 1 write request (and in many cases, you can use caching in your State implementation to eliminate the read request). So you get the best of both words of convenience - being able to express your computation in terms of what should be done with each tuple - and performance.</p></li>
<li><p>Trident aggregators are heavily optimized. Rather than transfer all tuples for a group to the same machine and then run the aggregator, Trident will do partial aggregations when possible before sending tuples over the network. For example, the Count aggregator computes the count on each partition, sends the partial count over the network, and then sums together all the partial counts to get the total count. This technique is similar to the use of combiners in MapReduce.</p></li>
</ol><p>Let's look at another example of Trident.</p><h2>Reach</h2><p>The next example is a pure DRPC topology that computes the reach of a URL on Twitter on demand. Reach is the number of unique people exposed to a URL on Twitter. To compute reach, you need to fetch all the people who ever tweeted a URL, fetch all the followers of all those people, unique that set of followers, and that count that uniqued set. Computing reach is too intense for a single machine - it can require thousands of database calls and tens of millions of tuples. With Storm and Trident, it's easy to parallelize the computation of each step across a cluster.</p><p>This topology will read from two sources of state. One database maps URLs to a list of people who tweeted that URL. The other database maps a person to a list of followers for that person. The topology definition looks like this:</p><script src=\"https://gist.github.com/3234642.js?file=gistfile1.java\"></script><br />
<p>The topology creates TridentState objects representing each external database using the newStaticState method. These can then be queried in the topology. Like all sources of state, queries to these databases will be automatically batched for maximum efficiency.</p><p>The topology definition is straightforward - it's just a simple batch processing job. First, the urlToTweeters database is queried to get the list of people who tweeted the URL for this request. That returns a list, so the ExpandList function is invoked to create a tuple for each tweeter.</p><p>Next, the followers for each tweeter must be fetched. It's important that this step be parallelized, so shuffle is invoked to evenly distribute the tweeters among all workers for the topology. Then, the followers database is queried to get the list of followers for each tweeter. You can see that this portion of the topology is given a large parallelism since this is the most intense portion of the computation.</p><p>Next, the set of followers is uniqued and counted. This is done in two steps. First a \"group by\" is done on the batch by \"follower\", running the \"One\" aggregator on each group. The \"One\" aggregator simply emits a single tuple containing the number one for each group. Then, the ones are summed together to get the unique count of the followers set. Here's the definition of the \"One\" aggregator:</p><script src=\"https://gist.github.com/3234645.js?file=gistfile1.java\"></script><br />
<p>This is a \"combiner aggregator\", which knows how to do partial aggregations before transferring tuples over the network to maximize efficiency. Sum is also defined as a combiner aggregator, so the global sum done at the end of the topology will be very efficient.</p><p>Let's now look at Trident in more detail.</p><h2>Fields and tuples</h2><p>The Trident data model is the TridentTuple which is a named list of values. During a topology, tuples are incrementally built up through a sequence of operations. Operations generally take in a set of input fields and emit a set of \"function fields\". The input fields are used to select a subset of the tuple as input to the operation, while the \"function fields\" name the fields emitted by the operation.<br />
</p><p>Consider this example. Suppose you have a stream called \"stream\" that contains the fields \"x\", \"y\", and \"z\". To run a filter MyFilter that takes in \"y\" as input, you would say:<br />
</p><script src=\"https://gist.github.com/3234647.js?file=gistfile1.java\"></script><br />
<p>Suppose the implementation of MyFilter is this:<br />
</p><script src=\"https://gist.github.com/3234650.js?file=gistfile1.java\"></script><br />
<p>This will keep all tuples whose \"y\" field is less than 10. The TridentTuple given as input to MyFilter will only contain the \"y\" field. Note that Trident is able to project a subset of a tuple extremely efficiently when selecting the input fields: the projection is essentially free.<br />
</p><p>Let's now look at how \"function fields\" work. Suppose you had this function:<br />
</p><script src=\"https://gist.github.com/3234652.js?file=gistfile1.java\"></script><br />
<p>This function takes two numbers as input and emits two new values: the addition of the numbers and the multiplication of the numbers. Suppose you had a stream with the fields \"x\", \"y\", and \"z\". You would use this function like this:<br />
</p><script src=\"https://gist.github.com/3234653.js?file=gistfile1.java\"></script><br />
<p>The output of functions is additive: the fields are added to the input tuple. So the output of this each call would contain tuples with the five fields \"x\", \"y\", \"z\", \"added\", and \"multiplied\". \"added\" corresponds to the first value emitted by AddAndMultiply, while \"multiplied\" corresponds to the second value.<br />
</p><p>With aggregators, on the other hand, the function fields replace the input tuples. So if you had a stream containing the fields \"val1\" and \"val2\", and you did this:<br />
</p><script src=\"https://gist.github.com/3234656.js?file=gistfile1.java\"></script><br />
<p>The output stream would only contain a single tuple with a single field called \"sum\", representing the sum of all \"val2\" fields in that batch.<br />
</p><p>With grouped streams, the output will contain the grouping fields followed by the fields emitted by the aggregator. For example:<br />
</p><script src=\"https://gist.github.com/3234661.js?file=gistfile1.java\"></script><br />
<p>In this example, the output will contain the fields \"val1\" and \"sum\".<br />
</p><h2>State</h2><p>A key problem to solve with realtime computation is how to manage state so that updates are idempotent in the face of failures and retries. It's impossible to eliminate failures, so when a node dies or something else goes wrong, batches need to be retried. The question is - how do you do state updates (whether external databases or state internal to the topology) so that it's like each message was processed only once?<br />
</p><p>This is a tricky problem, and can be illustrated with the following example. Suppose that you're doing a count aggregation of your stream and want to store the running count in a database. If you store only the count in the database and it's time to apply a state update for a batch, there's no way to know if you applied that state update before. The batch could have been attempted before, succeeded in updating the database, and then failed at a later step. Or the batch could have been attempted before and failed to update the database. You just don't know.<br />
</p><p>Trident solves this problem by doing two things:<br />
</p><ol><li><p>Each batch is given a unique id called the \"transaction id\". If a batch is retried it will have the exact same transaction id.</p></li>
<li><p>State updates are ordered among batches. That is, the state updates for batch 3 won't be applied until the state updates for batch 2 have succeeded.</p></li>
</ol><p>With these two primitives, you can achieve exactly-once semantics with your state updates. Rather than store just the count in the database, what you can do instead is store the transaction id with the count in the database as an atomic value. Then, when updating the count, you can just compare the transaction id in the database with the transaction id for the current batch. If they're the same, you skip the update - because of the strong ordering, you know for sure that the value in the database incorporates the current batch. If they're different, you increment the count.<br />
</p><p>Of course, you don't have to do this logic manually in your topologies. This logic is wrapped by the State abstraction and done automatically. Nor is your State object required to implement the transaction id trick: if you don't want to pay the cost of storing the transaction id in the database, you don't have to. In that case the State will have at-least-once-processing semantics in the case of failures (which may be fine for your application). You can read more about how to implement a State and the various fault-tolerance tradeoffs possible <a href=\"https://github.com/nathanmarz/storm/wiki/Trident-state\">in this doc</a>.<br />
</p><p>A State is allowed to use whatever strategy it wants to store state. So it could store state in an external database or it could keep the state in-memory but backed by HDFS (like how HBase works). State's are not required to hold onto state forever. For example, you could have an in-memory State implementation that only keeps the last X hours of data available and drops anything older. Take a look at the implementation of the <a href=\"https://github.com/nathanmarz/trident-memcached\">Memcached integration</a> for an example State implementation.<br />
</p><h2>Execution of Trident topologies</h2><p>Trident topologies compile down into as efficient of a Storm topology as possible. Tuples are only sent over the network when a repartitioning of the data is required, such as if you do a groupBy or a shuffle. So if you had this Trident topology:<br />
</p><p><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-LZD5mUEkC2s/UBqwZbpKT9I/AAAAAAAAAKc/-2eKlRrAt_Y/s1600/trident-to-storm1.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"260\" width=\"400\" src=\"http://4.bp.blogspot.com/-LZD5mUEkC2s/UBqwZbpKT9I/AAAAAAAAAKc/-2eKlRrAt_Y/s400/trident-to-storm1.png\" /></a></div></p><p>It would compile into Storm spouts/bolts like this:<br />
</p><p><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://1.bp.blogspot.com/-WpJ9YiaCn7c/UBqwpnK6cpI/AAAAAAAAAKo/2tV2bXfgzEE/s1600/trident-to-storm2.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"259\" width=\"400\" src=\"http://1.bp.blogspot.com/-WpJ9YiaCn7c/UBqwpnK6cpI/AAAAAAAAAKo/2tV2bXfgzEE/s400/trident-to-storm2.png\" /></a></div></p><p>As you can see, Trident colocates operations within the same bolt as much as possible.<br />
</p><h2>Conclusion</h2><p>Trident makes realtime computation elegant. You've seen how high throughput stream processing, state manipulation, and low-latency querying can be seamlessly intermixed via Trident's API. Trident lets you express your realtime computations in a natural way while still getting maximal performance. To get started with Trident, take a look at these <a href=\"https://github.com/nathanmarz/storm-starter/tree/master/src/jvm/storm/starter/trident\">sample Trident topologies</a> and the <a href=\"https://github.com/nathanmarz/storm/wiki/Documentation\">Trident documentation</a>.<br />
</p><p>- Nathan Marz, Software Engineer (<a href=\"https://twitter.com/nathanmarz\">@nathanmarz</a>)<br />
</p>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/1884593817993851033"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/1884593817993851033"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/08/trident-high-level-abstraction-for.html") (title . "Trident: a high-level abstraction for realtime computation"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://4.bp.blogspot.com/-dvyMvMMVyQg/UBqwN1OQnoI/AAAAAAAAAKQ/uaYoI0UH9fU/s72-c/batched-stream.png") (height . "72") (width . "72")))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-2058782037128621168") (published nil "2012-08-01T11:43:00.001-07:00") (updated nil "2012-08-02T10:34:47.870-07:00") (title ((type . "text")) "TwitterCLDR: Improving Internationalization Support in Ruby") (content ((type . "html")) "<p>We recently open sourced <a href =\"https://github.com/twitter/twitter-cldr-rb\">TwitterCLDR</a> under the Apache Public License 2.0. TwitterCLDR is an <a href=\"http://site.icu-project.org\">“ICU level”</a> internationalization library for Ruby that supports dates, times, numbers, currencies, world languages, sorting, text normalization, time spans, plurals, and unicode code point data. By sharing our code with the community we hope to collaborate together and improve internationalization support for websites all over the world. If your company is considering supporting multiple languages, then you can try TwitterCLDR to help your internationalization efforts.</p><h3>Motivation</h3><p>Here’s a test. Say this date out loud: <i>2/1/2012</i></p><p>If you said, “February first, 2012”, you’re probably an American. If you said, “January second, 2012”, you’re probably of European or possibly Asian descent. If you said, “January 12, 1902”, you’re probably a computer. The point is that as humans, we almost never think about formatting dates, plurals, lists, and the like. If you’re creating a platform available around the world, however, these kinds of minutiae make a big difference to users.</p><p>The <a href=\"http://www.unicode.org/consortium/consort.html\">Unicode Consortium</a> publishes and maintains a bunch of data regarding formatting dates, numbers, lists, and more, called the <a href=\"http://cldr.unicode.org\">Common Locale Data Repository (CLDR)</a>. IBM maintains International Components for Unicode (ICU), a library that uses the Unicode Consortium’s data to make it easier for programmers to use. However, this library is targeted at Java and C/C++ developers and not Ruby programmers, which is one of the programming languages used at Twitter. For example, Ruby and TwitterCLDR helps power our <a href=\"http://translate.twttr.com/welcome\">Translation Center</a>. TwitterCLDR provides a way to use the same CLDR data that Java uses, but in a Ruby environment. Hence, formatting dates, times, numbers, currencies and plurals should now be much easier for the typical Rubyist. Let’s go over some real world examples.</p><h2>Example Code</h2><p><b>Dates, Numbers, and Currencies</b></p><p>Let’s format a date in Spanish (es):<br />
<pre>$> DateTime.now.localize(:es).to_full_s
$> \"lunes, 12 de diciembre de 2011 21:44:57 UTC -0800\"</pre></p><p>Too long?  Make it shorter:<br />
<pre>$> DateTime.now.localize(:es).to_short_s
$> \"12/12/11 21:44\" </pre></p><p>Built in support for relative times lets you do this:<br />
<pre>$> (DateTime.now - 1).localize(:en).ago.to_s
$> \"1 day ago\"
$> (DateTime.now + 1).localize(:en).until.to_s
$> \"In 1 day\"</pre></p><p>Number formatting is easy:<br />
<pre>$> 1337.localize(:en).to_s
$> \"1,337\"
$> 1337.localize(:fr).to_s
$> \"1 337\"</pre></p><p>We’ve got you covered for currencies and decimals too:<br />
<pre>$> 1337.localize(:es).to_currency.to_s(:currency => \"EUR\")
$> \"1.337,00 €\"
$> 1337.localize(:es).to_decimal.to_s(:precision => 3)
$> \"1.337,000\"</pre></p><p>Currency data?  Absolutely:<br />
<pre>$> TwitterCldr::Shared::Currencies.for_country(\"Canada\")
$> { :currency => \"Dollar\", :symbol => \"$\", :code => \"CAD\" }</pre></p><p><b>Plurals</b></p><p>Get the plural rule for a number:<br />
<pre>$> TwitterCldr::Formatters::Plurals::Rules.rule_for(1, :ru)
$> :one
$> TwitterCldr::Formatters::Plurals::Rules.rule_for(3, :ru)
$> :few
$> TwitterCldr::Formatters::Plurals::Rules.rule_for(10, :ru)
$> :many</pre></p><p>Embed plurals right in your translatable phrases using JSON syntax:<br />
<pre>$> str = 'there %<{ \"horse_count\": { \"one\": \"is one horse\", \"other\": \"are %{horse_count} horses\" } }> in the barn'
$> str.localize % { :horse_count => 3 }
$> \"there are 3 horses in the barn\"</pre></p><p><b>Unicode Data</b></p><p>Get attributes for any Unicode code point:<br />
<pre>$> code_point = TwitterCldr::Shared::CodePoint.for_hex(\"1F3E9\")
$> code_point.name
$> \"LOVE HOTEL\"
$> code_point.category
$> \"So\"</pre></p><p>Normalize strings using Unicode’s standard algorithms (NFD, NFKD, NFC, or NFKC):<br />
<pre>$> \"español\".localize.code_points
$> [\"0065\", \"0073\", \"0070\", \"0061\", \"00F1\", \"006F\", \"006C\"]
$> \"español\".localize.normalize(:using => :NFKD).code_points
$> [\"0065\", \"0073\", \"0070\", \"0061\", \"006E\", \"0303\", \"006F\", \"006C\"]</pre></p><p><b>Sorting (Collation)</b></p><p>TwitterCLDR includes a pure Ruby, from-scratch implementation of the <a href=\"http://unicode.org/reports/tr10/\">Unicode Collation Algorithm</a> (with tailoring) that enables locale-aware sorting capabilities.</p><p>Alphabetize a list using regular Ruby sort:<br />
<pre>$> [\"Art\", \"Wasa\", \"Älg\", \"Ved\"].sort
$> [\"Art\", \"Ved\", \"Wasa\", \"Älg\"]</pre></p><p>Alphabetize a list using TwitterCLDR’s locale-aware sort:<br />
<pre>$> [\"Art\", \"Wasa\", \"Älg\", \"Ved\"].localize(:de).sort.to_a
$> [\"Älg\", \"Art\", \"Ved\", \"Wasa\"]</pre></p><p>NOTE: Most of these methods can be customized to your liking.</p><h3>JavaScript Support</h3><p>What good is all this internationalization support in Ruby if I can’t expect the same output on the client side too? To bridge the gap between the client and server sides, TwitterCLDR also contains a JavaScript implementation (known as twitter-cldr-js) whose compiled files are maintained in a <a href=\"https://github.com/twitter/twitter-cldr-js\">separate GitHub repo</a>.  At the moment, twitter-cldr-js supports dates, times, relative times, and plural rules.  We’re working on expanding its capabilities, so stay tuned.</p><h3>Future Work</h3><p>In the future, we hope to add even more internationalization capabilities to TwitterCLDR, including Rails integration, phone number and postal code validation, support for Unicode characters in Ruby 1.8 strings and regular expressions, and the ability to translate timezone names via the TZInfo gem and ActiveSupport. We would love to have the community use TwitterCLDR and help us improve the code to reach everyone in the world.</p><h3>Acknowledgements</h3><p>Twitter CLDR was primarily authored by Cameron Dutro (<a href=\"https://twitter.com/camertron\">@camertron</a>).  In addition, we’d like to acknowledge the following folks who contributed to the project either directly or indirectly: Kirill Lashuk (<a href=\"https://twitter.com/kl_7\">@kl_7</a>), Nico Sallembien (<a href=\"https://twitter.com/nsallembien\">@nsallembien</a>), Sumit Shah (<a href=\"https://twitter.com/omnidactyl\">@omnidactyl</a>), Katsuya Noguchi, Engineer (<a href=\"https://twitter.com/kn\">@kn</a>), Timothy Andrew (<a href=\"https://twitter.com/timothyandrew\">@timothyandrew</a>) and Kristian Freeman (<a href=\"https://twitter.com/imkmf\">@imkmf</a>).</p><br />
- Chris Aniszczyk, Manager of Open Source (<a href=\"https://twitter.com/cra\">@cra</a>)<br />") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/2058782037128621168"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/2058782037128621168"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/08/twittercldr-improving.html") (title . "TwitterCLDR: Improving Internationalization Support in Ruby"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif"))))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-6094938499221070180") (published nil "2012-07-10T13:15:00.000-07:00") (updated nil "2012-07-11T09:48:44.970-07:00") (title ((type . "text")) "Caching with Twemcache") (content ((type . "html")) "<b><i>Update - July 11, 2012, 9:45am<br />
</i></b><br />
<i>We want to correct an error regarding the slab calcification problem we mentioned in the original post. This problem only applied to our v1.4.4 fork of Memcached; this correction is reflected below. The recent Memcached version has addressed some of these problems. </i><br />
<br />
We built <a href=\"http://github.com/twitter/twemcache\">Twemcache</a> because we needed a more robust and manageable version of Memcached, suitable for our large-scale production environment. Today, we are open-sourcing Twemcache under the New BSD license. As one of the largest adopters of <a href=\"http://memcached.org/\">Memcached</a>, a popular open source caching system, we have used Memcached over the years to help us scale our ever-growing traffic. Today, we have hundreds of dedicated cache servers keeping over 20TB of data from over 30 services in-memory, including crucial data such as user information and Tweets. Collectively these servers handle almost 2 trillion queries on any given day (that’s more than 23 million queries per second). As we continued to grow, we needed a more robust and manageable version of Memcached suitable for our large scale production environment. <br />
<br />
We have been running Twemcache in production for more than a year and a half. Twemcache is based on a fork of Memcached v1.4.4 that is <b>heavily modified</b> to improve maintainability and help us monitor our cache servers better. We improved performance, removed code that we didn’t find necessary, refactored large source files and added observability related features. The following sections will provide more details on why we did this and what those new features are.<br />
<br />
<b><span style=\"font-size: large;\">Motivation</span></b><br />
<br />
Almost all of our cache use cases fall into two categories:<br />
<br />
<ul><li>as an <b>optimization for disk</b> where cache is used as the in-memory serving layer to shed load from databases.</li>
<li>as an <b>optimization for cpu</b> where cache is used as a buffer to store items that are expensive to recompute.</li>
</ul><br />
An example of these two optimizations is “caching of Tweets”. All Tweets are persisted to disk when they are created, but most Tweets requested by users need to be served out of memory for performance reasons. We use Twemcache to store recent and frequently accessed Tweets, as an optimization for disk. When a Tweet shows up in a particular client, it takes a particular presentation - rendered Tweet - which has other metadata like number of retweets, favorites etc. We also use Twemcache to store the recently rendered Tweets, as an optimization for cpu. <br />
<br />
To effectively address the use cases mentioned above, it's extremely important that caches are <b>always available</b> and have <b>predictable performance</b> with respect to item hit rate even when operating at full capacity. Caches should also be able to <b>adapt to changing item sizes on-the-fly</b> as application data size grows or shrinks over time. Finally, it is critical to have <b>observability into caches</b> to monitor the health and effectiveness of our cache clusters. It turns out that all these problems are interrelated because adapting to changing item sizes usually requires a cache reconfiguration — which impacts availability and predictability. Twemcache tries to address these needs with the help of the following features:<br />
<br />
<b>Random Eviction<br />
</b><br />
The v1.4.4 implementation of Memcached, which Twemcache is based on, suffers from a problem we call <i>slab calcification</i>. In Memcached, a slab can only store items of a given maximum size and once a slab has been allocated to a slab class, it cannot be reassigned to another slab class. In other words, slabs once allocated are locked to their respective slab classes. This is the crux of the slab calcification problem. When items grow or shrink in size, new slabs must be to allocated to store them. Over time, when caches reach full memory capacity, to store newer items we must rely on evicting existing items in the same slab class. If the newer items are of a size with no slabs allocated, write requests may fail completely. Meanwhile, slabs allocated to a different slab class may sit idle. Slab calcification leads to loss of capacity and efficiency. <br />
<br />
To solve this problem without resorting to periodically restarting the server instances, we introduced a new eviction strategy called <i>random eviction</i>. In this strategy, when a new item needs to be inserted and it cannot be accommodated by the space occupied by an expired item or the available free memory, we’ll simply pick a random slab from the list of all allocated slabs, evict all items within that slab, and reallocate it to the slab class that fits the new item. <br />
<br />
It turns out that this feature is quite powerful for two reasons:<br />
<br />
<ul><li>Cache servers can now gracefully move on-the-fly from one slab size to another for a given application. This enables our cache servers to adapt to changing item sizes and have a predictable long term hit rate by caching an application’s active working set of items.</li>
<li>Application developers don’t have to worry about reconfiguring their cache server when they add or delete fields from their cache item structures or if their item size grows over time.</li>
</ul><br />
By providing a stable hit rate, random eviction prevents performance degradation due to data pattern change and system instability associated with restarts. The <a href=\"http://www.youtube.com/watch?v=EtROv2or8SE&amp;feature=youtu.be&amp;hd=1\">video</a> below illustrates how over time Twemcache is able to adapt to a shifting size pattern and still remain effective.<br />
<br />
<iframe width=\"560\" height=\"315\" src=\"http://www.youtube.com/embed/EtROv2or8SE\" frameborder=\"0\" allowfullscreen></iframe><br />
<br />
<b>Lock-less Stats Collection</b><br />
<br />
Cache observability enables us to monitor the health of our cache clusters and ensure that applications are using them effectively. To address this need, we redesigned the Memcached stats module. Similar to the findings in Facebook’s <a href=\"https://www.facebook.com/note.php?note_id=39391378919\">attempt to scale Memcached</a>, we found that the global statistics lock was a main contention point.  <br />
<br />
This motivated us to use an updater-aggregator model of thread synchronization, in which worker threads always update thread-local metrics, and a background aggregator thread asynchronously collects metrics from all threads periodically holding only one thread-local lock at a time. Once aggregated, stats polling comes for free. Removing a global lock reduces the time Twemcache spends in a unresponsive state. There is a slight trade-off between how up-to-date stats are and how much burden stats collection puts on the system. However, the difference in total mutex wait time between aggregating once and 100 times per second is under 20%, and the impact on performance is totally predictable and thread-local. On top of making stats collection scalable, we also systematically reviewed the metrics, and came up with a more comprehensive list of metrics: Memcached provides 48 global metrics, 18 slab metrics and 10 item stats; Twemcache, on the other hand, provides 74 global metrics and 39 slab metrics. We merged item metrics into slab metrics to further simplify stats collection.<br />
<br />
<b>Asynchronous Command Logger<br />
</b><br />
When using Memcached, one of the hardest problems we faced was the hit-rate and memory-footprint trade-off - the sweet spot for achieving the desired performance gain with reasonable resources, as it is typically not possible to keep the entire data set in memory. To pinpoint the minimum memory requirement for a given hit rate, we needed a way to systematically analyze an application's data access pattern. To address this need, we implemented a new feature called command logger in Twemcache. When turned on, each worker thread will record a time stamped command header as well as return status, as shown below:<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-DiHbJIMfYik/T_yEi1a6wEI/AAAAAAAAAWs/fDWInSdbjLo/s1600/klogger_samples.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"56\" width=\"400\" src=\"http://4.bp.blogspot.com/-DiHbJIMfYik/T_yEi1a6wEI/AAAAAAAAAWs/fDWInSdbjLo/s400/klogger_samples.png\" /></a></div><br />
Each line of the command log gives precise information on the client, the time when a request was received, the command header including the command, key, flags and data length, a return code, and reply message length. In fact, the only thing missing is the item value itself, which turns out to be unimportant for our analysis.<br />
<br />
The command logger supports lockless read/write into ring buffers. Each worker thread logs into a thread-local buffer as they process incoming queries, and a background thread asynchronously dumps buffer contents to either a file or a socket. Thus the overhead on worker threads is minimal and so would not affect the service availability. The logger has been tested to log at about 100k requests-per-second. To control the speed of log generation, the command logger also supports sampling. Once we know what keys are accessed, the way they are accessed, and their return status, we can perform offline data analysis to estimate optimal working set size, item heat map, etc.<br />
<br />
<b><span style=\"font-size: large;\">Future work</span></b><br />
<br />
Twemcache is the result of our effort to turn Memcached into a reliable building block in Twitter’s data infrastructure. We kept the simplicity of the Memcached protocol intact, but made the service more dependable and more informative with Twemcache, without sacrificing performance. While we initially focused on the challenging goal of making Memcached work extremely well within the Twitter infrastructure, we look forward to sharing our code and ideas with the Memcached community in the long term. <br />
<br />
In the near future, we plan to evolve Twemcache in the open, address the hashtable lock contention issue that would further improve scalability, support more eviction strategies, support bootstrapping the cache from disk and provide a complete set of real-time data analysis tools. To view the source code and share feedback, please visit the <a href=\"https://github.com/twitter/twemcache\">Twemcache GitHub page</a>. You can also follow Twemcache's Twitter account (@<a href=\"https://twitter.com/twemcache\">Twemcache</a>) for updates. We would love to hear any ideas you have in improving Twemcache via pull requests or issues. Or better yet, why not consider joining the flock (@<a href=\"https://twitter.com/jointheflock\">jointheflock</a>) if you want to help build a world class caching system? <br />
<br />
<b><span style=\"font-size: large;\">Other work: Twemproxy</span></b><br />
<br />
Twemcache is one of the building blocks that comprise the caching system at Twitter. Another fundamental building block in our caching system is <a href=\"https://github.com/twitter/twemproxy\">Twemproxy</a>, a proxy for memcached protocol that we recently open sourced. Twemproxy minimizes the connections to our backend caching servers and enables us to scale horizontally. Furthermore, we are also actively developing the client side of our caching system on top of the Twitter <a href=\"https://github.com/twitter/finagle\">Finagle</a> stack.<br />
<br />
<b><span style=\"font-size: large;\">Acknowledgements</span></b><br />
<br />
Twemcache was primarily engineered by Manju Rajashekhar (@<a href=\"http://twitter.com/manju\">manju</a>) and Yao Yue (@<a href=\"http://twitter.com/thinkingfish\">thinkingfish</a>).  In addition, we’d like to acknowledge the following folks who contributed to the project either directly or indirectly and its deployment and maintenance in our datacenters: Anirudh Srinivas  (@<a href=\"http://twitter.com/asrin\">asrin</a>), David Lam (@<a href=\"http://twitter.com/kkdlam\">kkdlam</a>), Krishna Gade (@<a href=\"http://twitter.com/krishnagade\">krishnagade</a>), Joshua Coats (@<a href=\"http://twitter.com/shu\">shu</a>), Owen Vallis (@<a href=\"http://twitter.com/o_e_bert\">o_e_bert</a>), Rob Benson (@<a href=\"http://twitter.com/rgbenson\">rgbenson</a>), Brandon Mitchell (@<a href=\"http://twitter.com/bitbckt\">bitbckt</a>) and Xin Xiang (@<a href=\"http://twitter.com/xiangxin72\">xiangxin72</a>).<br />
<br />
- Chris Aniszczyk, Manager of Open Source (@<a href=\"http://twitter.com/cra\">cra</a>)") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6094938499221070180"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6094938499221070180"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/07/caching-with-twemcache.html") (title . "Caching with Twemcache"))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://img.youtube.com/vi/EtROv2or8SE/default.jpg") (height . "72") (width . "72")))) (entry nil (id nil "tag:blogger.com,1999:blog-5340805191653517637.post-6638353306900912486") (published nil "2012-06-25T11:17:00.000-07:00") (updated nil "2012-06-25T11:34:14.376-07:00") (title ((type . "text")) "Building and profiling high performance systems with Iago") (content ((type . "html")) "<a href=\"http://twitter.github.com/iago\">Iago</a> is a load generator that we created to help us test services before they encounter production traffic. While there are many load generators available in the open source and commercial software worlds, Iago provides us with capabilities that are uniquely suited for Twitter’s environment and the precise degree to which we need to test our services. <br />
<br />
There are three main properties that make Iago a good fit for Twitter:<br />
<br />
<ul><li><b>High performance:</b> In order to reach the highest levels of performance, your load generator must be equally performant. It must generate traffic in a very precise and predictable way to minimize variance between test runs and allow comparisons to be made between development iterations. Additionally, testing systems to failure is an important part of capacity planning, and it requires you to generate load significantly in excess of expected production traffic.</li>
<li><b>Multi-protocol:</b> Modelling a system as complex as Twitter can be difficult, but it’s made easier by decomposing it into component services. Once decomposed, each piece can be tested in isolation; this requires your load generator to speak each service’s protocol. Twitter has in excess of 100 such services, and Iago can and has tested most of them due to its built-in support for the protocols we use, including HTTP, Thrift and several others.</li>
<li><b>Extensible:</b> Iago is designed first and foremost for engineers. It assumes that the person building the system will also be interested in validating its performance and will know best how to do so. As such, it’s designed from the ground up to be extensible – making it easy to generate new traffic types, over new protocols and with individualized traffic sources. It is also provides sensible defaults for common use cases, while allowing for extensive configuration without writing code if that’s your preference.</li>
</ul><br />
<br />
Iago is the load generator we always wished we had. Now that we’ve built it, we want to share it with others who might need it to solve similar problems. Iago is now open sourced at <a href=\"https://github.com/twitter/iago\">GitHub</a> under the Apache Public License 2.0 and we are happy to accept any feedback (or pull requests) the open source community might have.<br />
<br />
<b>How does Iago work?</b><br />
<br />
Iago’s <a href=\"https://github.com/twitter/iago\">documentation</a> goes into more detail, but it is written in Scala and is designed to be extended by anyone writing code for the JVM platform. Non-blocking requests are generated at a specified rate, using an underlying, configurable statistical distribution (the default is to model a <a href=\"http://en.wikipedia.org/wiki/Poisson_Process\">Poisson Process</a>). The request rate can be varied as appropriate – for instance to warm up caches before handling full production load. In general the focus is on the arrival rate aspect of <a href=\"http://en.wikipedia.org/wiki/Little%27s_Law\">Little’s Law</a>, instead of concurrent users, which is allowed to float as appropriate given service latency. This greatly enhances the ability to compare multiple test runs and protects against service regressions inducing load generator slow down.<br />
<br />
In short, Iago strives to model a system where requests arrive independently of your service’s ability to handle them. This is as opposed to load generators which model closed systems where users will patiently handle whatever latency you give them. This distinction allows us to closely mimic failure modes that we would encounter in production.<br />
<br />
Part of achieving high performance is the ability to scale horizontally. Unsurprisingly, Iago is no different from the systems we test with it. A single instance of Iago is composed of cooperating processes that can generate ~10K RPS provided a number of requirements are met including factors such as size of payload, the response time of the system under test, the number of ephemeral sockets available, and the rate you can actually generate messages your protocol requires. Despite this complexity, with horizontal scaling Iago is used to routinely test systems at Twitter with well over 200K RPS. We do this internally using our <a href=\"http://incubator.apache.org/mesos/\">Apache Mesos grid</a> computing infrastructure, but Iago can adapt to any system that supports creating multiple JVM processes that can discover each other using <a href=\"http://zookeeper.apache.org/\">Apache Zookeeper</a>.<br />
<br />
<b>Iago at Twitter<br />
</b><br />
Iago has been used at Twitter throughout our stack, from our core database interfaces, storage sub-systems and domain logic, up to the systems accepting front end web requests. We routinely evaluate new hardware with it, have extended it to support correctness testing at scale and use it to test highly specific endpoints such as the new <a href=\"http://blog.twitter.com/2012/06/tailored-trends-bring-you-closer.html\">tailored trends</a>, personalized search, and Discovery releases. We’ve used it to model anticipated load for large events as well as the overall growth of our system over time. It’s also good for providing background traffic while other tests are running, simply to provide the correct mix of usage that we will encounter in production.<br />
<br />
<b>Acknowledgements &amp; Future Work<br />
</b><br />
Iago was primarily authored by James Waldrop (<a href=\"https://twitter.com/hivetheory\">@hivetheory</a>), but as with any such engineering effort a large number of people have contributed. A special thanks go out to the Finagle team, Marius Eriksen (<a href=\"https://twitter.com/marius\">@marius</a>), Arya Asemanfar (<a href=\"https://twitter.com/a_a\">@a_a</a>), Evan Meagher (<a href=\"https://twitter.com/evanm\">@evanm</a>), Trisha Quan (<a href=\"https://twitter.com/trisha\">@trisha</a>) and Stephan Zuercher (<a href=\"https://twitter.com/zuercher\">@zuercher</a>) for being tireless consumers as well as contributors to the project. Furthermore, we’d like to thank Raffi Krikorian (<a href=\"https://twitter.com/raffi\">@raffi</a>) and Dave Loftesness (<a href=\"https://twitter.com/dloft\">@dloft</a>) for originally envisioning and spearheading the effort to create Iago.<br />
<br />
To view the Iago source code and participate in the creation and development of our roadmap, please visit <a href=\"https://github.com/twitter/iago\">Iago</a> on GitHub. If you have any further questions, we suggest joining the <a href=\"https://groups.google.com/forum/?fromgroups#!forum/iago-users\">mailing list</a> and following <a href=\"https://twitter.com/iagoloadgen\">@iagoloadgen</a>. If you’re at the Velocity Conference this week in San Francisco, please swing by our <a href=\"http://velocityconf.com/velocity2012/public/schedule/detail/26222\">office hours</a> to learn more about Iago. <br />
<br />
- Chris Aniszczyk, Manager of Open Source (<a href=\"https://twitter.com/cra\">@cra</a>)") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6638353306900912486"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6638353306900912486"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/06/building-and-profiling-high-performance.html") (title . "Building and profiling high performance systems with Iago"))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif"))))))) ("Drinking from the Streaming API" "Today we’re open-sourcing the <a href=\"https://github.com/twitter/hbc\">Hosebird Client</a> (hbc) under the <a href=\"https://github.com/twitter/hbc/blob/master/LICENSE\">ALv2 license</a> to provide a robust Java HTTP library for consuming Twitter's <a href=\"https://dev.twitter.com/docs/streaming-apis\">Streaming API</a>. The client is full featured: it offers support for GZip, OAuth and partitioning; automatic reconnections with appropriate backfill counts; access to raw bytes payload; proper retry schemes, and relevant statistics. Even better, it’s been battle-tested in production by our internal teams. We highly recommend you take advantage of the Hosebird Client if you plan on working with the Streaming API.<br />
<br />
<b>Using Hosebird<br />
</b><br />
The Hosebird Client is broken into two main modules: <b>hbc-core</b> and <b>hbc-twitter4j</b>. The hbc-core module uses a simple message queue that a consumer can poll for messages. The hbc-twitter4j module lets you use the superb <a href=\"http://twitter4j.org/\">Twitter4J</a> project and its data model on top of the message queue to provide a parsing layer.<br />
<br />
The first step to use Hosebird is to setup the client using the<span style=\"font-family: Courier New, Courier, monospace;\"> ClientBuilder</span> API:<br />
<br />
<b id=\"internal-source-marker_0.31906672520563006\" style=\"font-weight: normal;\"><span style=\"background-color: white; color: #999988; font-family: Consolas; font-size: 12px; font-style: italic; vertical-align: baseline; white-space: pre-wrap;\">// Create an appropriately sized blocking queue</span><br />
<span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\">BlockingQueue</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">&lt;</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\">String</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">&gt;</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\"> queue </span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">=</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">new</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\"> LinkedBlockingQueue</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">&lt;</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\">String</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">&gt;(</span><span style=\"background-color: white; color: #009999; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\">10000</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">);</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"></span><br />
<span style=\"background-color: white; color: #999988; font-family: Consolas; font-size: 12px; font-style: italic; vertical-align: baseline; white-space: pre-wrap;\">// Authenticate via OAuth</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"></span><br />
<span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">Authentication auth </span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">=</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">new</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> OAuth1</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">consumerKey</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">,</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> consumerSecret</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">,</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> token</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">,</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> secret</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">);</span><span style=\"font-family: Arial; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"></span><br />
<span style=\"background-color: white; color: #999988; font-family: Consolas; font-size: 12px; font-style: italic; vertical-align: baseline; white-space: pre-wrap;\">// Build a hosebird client</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"></span><br />
<span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">ClientBuilder builder </span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">=</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">new</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> ClientBuilder</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">()</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" /> &nbsp;&nbsp;&nbsp;</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">hosts</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\">Constants</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: white; color: teal; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\">STREAM_HOST</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">)</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" /> &nbsp;&nbsp;&nbsp;</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">authentication</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">auth</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">)</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" /> &nbsp;&nbsp;&nbsp;</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">endpoint</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(new</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">StatusesSampleEndpoint</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">()</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">)</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" /> &nbsp;&nbsp;&nbsp;</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">processor</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(new</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> StringDelimitedProcessor</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">queue</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">))</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" /> &nbsp;&nbsp;&nbsp;</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">eventMessageQueue</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">queue</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">);</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" />Client hosebirdClient </span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">=</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> builder</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">build</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">();</span></b><br />
<string><string> <br />
After we have created a <span style=\"font-family: Courier New, Courier, monospace;\">Client</span>, we can connect and process messages:<br />
<br />
<b id=\"internal-source-marker_0.31906672520563006\" style=\"font-weight: normal;\"><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">client</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">connect</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">();</span><br />
<span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">while</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(!</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">client</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">isDone</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">())</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">{</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" /> &nbsp;String message = queue</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">take</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">();</span><br />
<span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;System.out.println(message); // print the message</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">}</span></b><br />
<br />
<b>Hosebird Examples</b><br />
<br />
We recommend you learn from the <a href=\"https://github.com/twitter/hbc/tree/master/hbc-example\">examples</a> on GitHub or contribute your own.<br />
<br />
If you want a quick example, set these properties in <span style=\"font-family: Courier New, Courier, monospace;\">hbc-example/pom.xml:<br />
</span><b id=\"internal-source-marker_0.31906672520563006\" style=\"font-weight: normal;\"><span style=\"font-family: 'Courier New'; font-size: 15px; vertical-align: baseline; white-space: pre-wrap;\">&lt;consumer.key&gt;SECRET&lt;/consumer.key&gt;</span><br />
<span style=\"font-family: 'Courier New'; font-size: 15px; vertical-align: baseline; white-space: pre-wrap;\">&lt;consumer.secret&gt;SECRET&lt;/consumer.secret&gt;</span><br />
<span style=\"font-family: 'Courier New'; font-size: 15px; vertical-align: baseline; white-space: pre-wrap;\">&lt;access.token&gt;SECRET&lt;/access.token&gt;</span><br />
<span style=\"font-family: 'Courier New'; font-size: 15px; vertical-align: baseline; white-space: pre-wrap;\">&lt;acesss.token.secret&gt;SECRET&lt;/acesss.token.secret&gt;</span></b><br />
<br />
Then you can run this command on the command line:<br />
<span style=\"font-family: Courier New, Courier, monospace;\"> mvn exec:java -pl hbc-example</span> <br />
<br />
This will connect to the <a href=\"https://dev.twitter.com/docs/api/1/get/statuses/sample\">sample stream API</a> and print 1000 JSON items from the API.<br />
<br />
Acknowledgements<br />
The Hosebird Client was primarily authored by Steven Liu (<a href=\"https://twitter.com/steven\">@steven</a>) and Kevin Oliver (<a href=\"https://twitter.com/kevino\">@kevino</a>). We’d also like to thank the <a href=\"https://twitter.com/TwitterAPI\">@TwitterAPI</a> team for their thoughtful suggestions and help.<br />
<br />
On behalf of the Hosebird team, <br />
- Chris Aniszczyk, Manager of Open Source (<a href=\"https://twitter.com/cra\">@cra</a>)</string></string>" "http://www.blogger.com/feeds/5340805191653517637/posts/default/7017276850832968138" (20783 47770) old 1 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-7017276850832968138") (published nil "2013-02-28T12:09:00.000-08:00") (updated nil "2013-02-28T12:14:18.467-08:00") (title ((type . "text")) "Drinking from the Streaming API") (content ((type . "html")) "Today we’re open-sourcing the <a href=\"https://github.com/twitter/hbc\">Hosebird Client</a> (hbc) under the <a href=\"https://github.com/twitter/hbc/blob/master/LICENSE\">ALv2 license</a> to provide a robust Java HTTP library for consuming Twitter's <a href=\"https://dev.twitter.com/docs/streaming-apis\">Streaming API</a>. The client is full featured: it offers support for GZip, OAuth and partitioning; automatic reconnections with appropriate backfill counts; access to raw bytes payload; proper retry schemes, and relevant statistics. Even better, it’s been battle-tested in production by our internal teams. We highly recommend you take advantage of the Hosebird Client if you plan on working with the Streaming API.<br />
<br />
<b>Using Hosebird<br />
</b><br />
The Hosebird Client is broken into two main modules: <b>hbc-core</b> and <b>hbc-twitter4j</b>. The hbc-core module uses a simple message queue that a consumer can poll for messages. The hbc-twitter4j module lets you use the superb <a href=\"http://twitter4j.org/\">Twitter4J</a> project and its data model on top of the message queue to provide a parsing layer.<br />
<br />
The first step to use Hosebird is to setup the client using the<span style=\"font-family: Courier New, Courier, monospace;\"> ClientBuilder</span> API:<br />
<br />
<b id=\"internal-source-marker_0.31906672520563006\" style=\"font-weight: normal;\"><span style=\"background-color: white; color: #999988; font-family: Consolas; font-size: 12px; font-style: italic; vertical-align: baseline; white-space: pre-wrap;\">// Create an appropriately sized blocking queue</span><br />
<span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\">BlockingQueue</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">&lt;</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\">String</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">&gt;</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\"> queue </span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">=</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">new</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\"> LinkedBlockingQueue</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">&lt;</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\">String</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">&gt;(</span><span style=\"background-color: white; color: #009999; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\">10000</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">);</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"></span><br />
<span style=\"background-color: white; color: #999988; font-family: Consolas; font-size: 12px; font-style: italic; vertical-align: baseline; white-space: pre-wrap;\">// Authenticate via OAuth</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"></span><br />
<span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">Authentication auth </span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">=</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">new</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> OAuth1</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">consumerKey</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">,</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> consumerSecret</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">,</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> token</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">,</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> secret</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">);</span><span style=\"font-family: Arial; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"></span><br />
<span style=\"background-color: white; color: #999988; font-family: Consolas; font-size: 12px; font-style: italic; vertical-align: baseline; white-space: pre-wrap;\">// Build a hosebird client</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"></span><br />
<span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">ClientBuilder builder </span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">=</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">new</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> ClientBuilder</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">()</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" /> &nbsp;&nbsp;&nbsp;</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">hosts</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\">Constants</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 12px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: white; color: teal; font-family: Consolas; font-size: 12px; vertical-align: baseline; white-space: pre-wrap;\">STREAM_HOST</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">)</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" /> &nbsp;&nbsp;&nbsp;</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">authentication</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">auth</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">)</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" /> &nbsp;&nbsp;&nbsp;</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">endpoint</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(new</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">StatusesSampleEndpoint</span><span style=\"background-color: white; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">()</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">)</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" /> &nbsp;&nbsp;&nbsp;</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">processor</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(new</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> StringDelimitedProcessor</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">queue</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">))</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" /> &nbsp;&nbsp;&nbsp;</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">eventMessageQueue</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">queue</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">);</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" />Client hosebirdClient </span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">=</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> builder</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">build</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">();</span></b><br />
<string><string> <br />
After we have created a <span style=\"font-family: Courier New, Courier, monospace;\">Client</span>, we can connect and process messages:<br />
<br />
<b id=\"internal-source-marker_0.31906672520563006\" style=\"font-weight: normal;\"><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">client</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">connect</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">();</span><br />
<span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">while</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">(!</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">client</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">isDone</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">())</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> </span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">{</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"><br class=\"kix-line-break\" /> &nbsp;String message = queue</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">.</span><span style=\"background-color: #f8f8f8; color: teal; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\">take</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">();</span><br />
<span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;System.out.println(message); // print the message</span><span style=\"background-color: #f8f8f8; color: #333333; font-family: Consolas; font-size: 13px; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">}</span></b><br />
<br />
<b>Hosebird Examples</b><br />
<br />
We recommend you learn from the <a href=\"https://github.com/twitter/hbc/tree/master/hbc-example\">examples</a> on GitHub or contribute your own.<br />
<br />
If you want a quick example, set these properties in <span style=\"font-family: Courier New, Courier, monospace;\">hbc-example/pom.xml:<br />
</span><b id=\"internal-source-marker_0.31906672520563006\" style=\"font-weight: normal;\"><span style=\"font-family: 'Courier New'; font-size: 15px; vertical-align: baseline; white-space: pre-wrap;\">&lt;consumer.key&gt;SECRET&lt;/consumer.key&gt;</span><br />
<span style=\"font-family: 'Courier New'; font-size: 15px; vertical-align: baseline; white-space: pre-wrap;\">&lt;consumer.secret&gt;SECRET&lt;/consumer.secret&gt;</span><br />
<span style=\"font-family: 'Courier New'; font-size: 15px; vertical-align: baseline; white-space: pre-wrap;\">&lt;access.token&gt;SECRET&lt;/access.token&gt;</span><br />
<span style=\"font-family: 'Courier New'; font-size: 15px; vertical-align: baseline; white-space: pre-wrap;\">&lt;acesss.token.secret&gt;SECRET&lt;/acesss.token.secret&gt;</span></b><br />
<br />
Then you can run this command on the command line:<br />
<span style=\"font-family: Courier New, Courier, monospace;\"> mvn exec:java -pl hbc-example</span> <br />
<br />
This will connect to the <a href=\"https://dev.twitter.com/docs/api/1/get/statuses/sample\">sample stream API</a> and print 1000 JSON items from the API.<br />
<br />
Acknowledgements<br />
The Hosebird Client was primarily authored by Steven Liu (<a href=\"https://twitter.com/steven\">@steven</a>) and Kevin Oliver (<a href=\"https://twitter.com/kevino\">@kevino</a>). We’d also like to thank the <a href=\"https://twitter.com/TwitterAPI\">@TwitterAPI</a> team for their thoughtful suggestions and help.<br />
<br />
On behalf of the Hosebird team, <br />
- Chris Aniszczyk, Manager of Open Source (<a href=\"https://twitter.com/cra\">@cra</a>)</string></string>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/7017276850832968138"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/7017276850832968138"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2013/02/drinking-from-streaming-api.html") (title . "Drinking from the Streaming API"))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))))) ("Twitter Typeahead.js: You Autocomplete Me" "Twitter <a href=\"http://twitter.github.com/typeahead.js\">typeahead.js</a> is a fast and battle-tested jQuery plugin for auto completion. Today we’re open sourcing the code on <a href=\"https://github.com/twitter/typeahead.js\">GitHub</a> under the <a href=\"https://github.com/twitter/typeahead.js/blob/master/LICENSE\">MIT license</a>. By sharing a piece of our infrastructure with the open source community, we hope to evolve typeahead.js further with community input.<br />
<br />
<a href=\"http://4.bp.blogspot.com/-vUN5jO5VvfY/USPaIZbU5yI/AAAAAAAAAeU/Tix7jRANNpI/s1600/typeahead+image.png\" imageanchor=\"1\"><img border=\"0\" src=\"http://4.bp.blogspot.com/-vUN5jO5VvfY/USPaIZbU5yI/AAAAAAAAAeU/Tix7jRANNpI/s320/typeahead+image.png\" /></a><br />
<br />
<br />
If your web application needs a fully-featured queryable search box, typeahead.js can help. Some of its capabilities and features include:<br />
<ul><li>Search data on the client, server, or both</li>
<li>Handle multiple inputs on a single page with shared data and caching</li>
<li>Suggest multiple types of data (e.g. searches and accounts) in a single input</li>
<li>Support for international languages, including right-to-left (RTL) and input method editors (IME)</li>
<li>Define custom matching and ranking functions</li>
<li>Grey text hints that help explain what hitting tab will do</li>
</ul><br />
It’s also optimized for large local datasets, so it's fast for high-latency networks.<br />
<br />
<b>Examples</b><br />
<br />
We recommend you take a look at our <a href=\"http://twitter.github.com/typeahead.js/examples/\">examples</a> page. There are three ways to get data:<br />
<br />
Using local, hard-coded data passed on page render:<br />
<br />
<span style=\"font-family: Courier New, Courier, monospace;\">$('#input').typeahead([</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">{</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">name: 'planets',</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">local: [ \"Mercury\", \"Venus\", \"Earth\", \"Mars\", \"Jupiter\", \"Saturn\", \"Uranus\", \"Neptune\" ]</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">}</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">]);</span><br />
<br />
Using a prefetch URL that will be hit to grab data on pageload and then stored in localStorage:<br />
<br />
<span style=\"font-family: Courier New, Courier, monospace;\">$('#input').typeahead([</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">{</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">name: 'countries',</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">prefetch: '/countries.json',</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">}</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">]);</span><br />
<br />
Or using a queryable API that returns results as-you-type (with the query being passed in the ?q= parameter):<br />
<br />
<span style=\"font-family: Courier New, Courier, monospace;\">$('#input').typeahead([</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">{</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">name: 'countries',</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">remote: '/countries.json',</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">}</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">]);</span><br />
<br />
You can also combine local or prefetch with a remote fallback for the performance of local data combined with the coverage of a remote query API (e.g. quickly search your friends but be able to find anyone on your site). There are lots of options for configuring everything from ranking, matching, rendering, templating engines, and more; check out the <a href=\"https://github.com/twitter/typeahead.js#readme\">README</a> for those details.<br />
<br />
If you want to use this with a project like <a href=\"http://twitter.github.com/bootstrap\">Bootstrap</a>, all you have to do is include the JavaScript file for typeahead.js after Bootstrap’s JavaScript file and use our configuration options.<br />
<br />
We initially built typeahead.js to support our needs; now we look forward to improvements and suggestions from the community. To learn more about how typeahead.js works, check out our detailed <a href=\"https://github.com/twitter/typeahead.js#readme\">documentation</a>. To stay in touch, follow <a href=\"https://twitter.com/typeahead\">@typeahead</a> and submit <a href=\"https://github.com/twitter/typeahead.js/issues\">issues</a> on GitHub. Also, if building web application frameworks like typeahead.js interests you, why not consider <a href=\"https://twitter.com/jobs/engineering\">joining the flock</a>?<br />
<br />
<b>Acknowledgements</b><br />
Typeahead.js was primarily authored by Tim Trueman (<a href=\"https://twitter.com/timtrueman\">@timtrueman</a>), Veljko Skarich (<a href=\"https://twitter.com/vskarich\">@vskarich</a>) and Jake Harding (<a href=\"https://twitter.com/jakeharding\">@jakeharding</a>).<br />
<br />
On behalf of the typeahead.js team,<br />
- Chris Aniszczyk, Manager of Open Source (<a href=\"https://twitter.com/cra\">@cra</a>)" "http://www.blogger.com/feeds/5340805191653517637/posts/default/228421351187252841" (20772 7372) old 2 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-228421351187252841") (published nil "2013-02-19T12:10:00.000-08:00") (updated nil "2013-02-19T16:46:04.042-08:00") (title ((type . "text")) "Twitter Typeahead.js: You Autocomplete Me") (content ((type . "html")) "Twitter <a href=\"http://twitter.github.com/typeahead.js\">typeahead.js</a> is a fast and battle-tested jQuery plugin for auto completion. Today we’re open sourcing the code on <a href=\"https://github.com/twitter/typeahead.js\">GitHub</a> under the <a href=\"https://github.com/twitter/typeahead.js/blob/master/LICENSE\">MIT license</a>. By sharing a piece of our infrastructure with the open source community, we hope to evolve typeahead.js further with community input.<br />
<br />
<a href=\"http://4.bp.blogspot.com/-vUN5jO5VvfY/USPaIZbU5yI/AAAAAAAAAeU/Tix7jRANNpI/s1600/typeahead+image.png\" imageanchor=\"1\"><img border=\"0\" src=\"http://4.bp.blogspot.com/-vUN5jO5VvfY/USPaIZbU5yI/AAAAAAAAAeU/Tix7jRANNpI/s320/typeahead+image.png\" /></a><br />
<br />
<br />
If your web application needs a fully-featured queryable search box, typeahead.js can help. Some of its capabilities and features include:<br />
<ul><li>Search data on the client, server, or both</li>
<li>Handle multiple inputs on a single page with shared data and caching</li>
<li>Suggest multiple types of data (e.g. searches and accounts) in a single input</li>
<li>Support for international languages, including right-to-left (RTL) and input method editors (IME)</li>
<li>Define custom matching and ranking functions</li>
<li>Grey text hints that help explain what hitting tab will do</li>
</ul><br />
It’s also optimized for large local datasets, so it's fast for high-latency networks.<br />
<br />
<b>Examples</b><br />
<br />
We recommend you take a look at our <a href=\"http://twitter.github.com/typeahead.js/examples/\">examples</a> page. There are three ways to get data:<br />
<br />
Using local, hard-coded data passed on page render:<br />
<br />
<span style=\"font-family: Courier New, Courier, monospace;\">$('#input').typeahead([</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">{</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">name: 'planets',</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">local: [ \"Mercury\", \"Venus\", \"Earth\", \"Mars\", \"Jupiter\", \"Saturn\", \"Uranus\", \"Neptune\" ]</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">}</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">]);</span><br />
<br />
Using a prefetch URL that will be hit to grab data on pageload and then stored in localStorage:<br />
<br />
<span style=\"font-family: Courier New, Courier, monospace;\">$('#input').typeahead([</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">{</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">name: 'countries',</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">prefetch: '/countries.json',</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">}</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">]);</span><br />
<br />
Or using a queryable API that returns results as-you-type (with the query being passed in the ?q= parameter):<br />
<br />
<span style=\"font-family: Courier New, Courier, monospace;\">$('#input').typeahead([</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">{</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">name: 'countries',</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">remote: '/countries.json',</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">}</span><br />
<span style=\"font-family: Courier New, Courier, monospace;\">]);</span><br />
<br />
You can also combine local or prefetch with a remote fallback for the performance of local data combined with the coverage of a remote query API (e.g. quickly search your friends but be able to find anyone on your site). There are lots of options for configuring everything from ranking, matching, rendering, templating engines, and more; check out the <a href=\"https://github.com/twitter/typeahead.js#readme\">README</a> for those details.<br />
<br />
If you want to use this with a project like <a href=\"http://twitter.github.com/bootstrap\">Bootstrap</a>, all you have to do is include the JavaScript file for typeahead.js after Bootstrap’s JavaScript file and use our configuration options.<br />
<br />
We initially built typeahead.js to support our needs; now we look forward to improvements and suggestions from the community. To learn more about how typeahead.js works, check out our detailed <a href=\"https://github.com/twitter/typeahead.js#readme\">documentation</a>. To stay in touch, follow <a href=\"https://twitter.com/typeahead\">@typeahead</a> and submit <a href=\"https://github.com/twitter/typeahead.js/issues\">issues</a> on GitHub. Also, if building web application frameworks like typeahead.js interests you, why not consider <a href=\"https://twitter.com/jobs/engineering\">joining the flock</a>?<br />
<br />
<b>Acknowledgements</b><br />
Typeahead.js was primarily authored by Tim Trueman (<a href=\"https://twitter.com/timtrueman\">@timtrueman</a>), Veljko Skarich (<a href=\"https://twitter.com/vskarich\">@vskarich</a>) and Jake Harding (<a href=\"https://twitter.com/jakeharding\">@jakeharding</a>).<br />
<br />
On behalf of the typeahead.js team,<br />
- Chris Aniszczyk, Manager of Open Source (<a href=\"https://twitter.com/cra\">@cra</a>) ") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/228421351187252841"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/228421351187252841"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2013/02/twitter-typeaheadjs-you-autocomplete-me.html") (title . "Twitter Typeahead.js: You Autocomplete Me"))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://4.bp.blogspot.com/-vUN5jO5VvfY/USPaIZbU5yI/AAAAAAAAAeU/Tix7jRANNpI/s72-c/typeahead+image.png") (height . "72") (width . "72"))))) ("New Twitter search results" "We just <a href=\"http://blog.twitter.com/2013/02/search-and-discover-improvements-get.html\">shipped a new version of the Twitter app</a> with a brand new search experience that blends the most relevant content - Tweets, user accounts, images, news, related searches, and more - into a single stream of results. This is a major shift from how we have previously partitioned results by type (for instance, Tweet search vs. people search). We think this simplified experience makes it easier to find great content on Twitter using your mobile device. <br />
<br />
A typical search scores items of the same type and picks the top-scoring results. In a blended search experience, this is not straightforward. The scores of different content types are computed by different services, and thus not directly comparable for blending. Another challenge is to decide which type of content to mix, as not all content types are always desirable to display. This post discusses our approach to solving these challenges.<br />
<br />
<b>Ranking<br />
</b> <br />
When a user searches, different types of content are searched separately, returning a sequence of candidate results for each content type with a type-specific score for each. For certain content types that are displayed as a single group or gallery unit, such as users or images, we assign the maximum score of results as the representative score of this content type. The result sequences for some content types may be trimmed or discarded entirely at this point.<br />
<br />
Once results of different content types are prepared, each type-specific score is converted into a universally compatible score, called a “uniscore”. Uniscores of different modules are used as a means to blend content types as in a merge-sort, except for the penalization of content type transition. This is to avoid over-diversification of content types in the blended result.<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://3.bp.blogspot.com/-McCkggNJrU0/URKuInWEznI/AAAAAAAAAeE/pNNT8WnWwx8/s1600/Fig%2B1.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"203\" src=\"http://3.bp.blogspot.com/-McCkggNJrU0/URKuInWEznI/AAAAAAAAAeE/pNNT8WnWwx8/s400/Fig%2B1.png\" width=\"400\" /></a></div><span style=\"font-size: x-small;\"><i>Fig. 1: Search ranker chose News1 followed by Tweet1 so far and is presented with three candidatesTweet2, User Group, and News2 to pick the content after Tweet1. News2 has the highest uniscore but search ranker picks Tweet2, instead of News2 as we penalize change in type between consecutive content by decreasing the score of News2 from 0.65 to 0.55, for instance.<br />
</i> </span><br />
<br />
<b>Score unification<br />
</b> <br />
Individual content is assigned a type-specific score, which is called a “raw” score, by its corresponding service. To facilitate blending and ranking content of different types as described above, raw scores are converted into uniscores using type-specific log-linear score conversion functions – where the chance of a converted score to take its value in [0, 1] is at least 95%, as estimated from observed dataset.<br />
<br />
<b>Content selection and boosting<br />
</b> <br />
Certain types of content may not have many relevant items to show for a particular input query, in which case we may choose not to include this type of content in search results. In other cases, for instance if query volume or matched item counts have an unusual spike (what we call a “burst”), we show this type and may also boost it to appear at a higher place in the results. To facilitate this, we represent trends in searches or matching result counts as a single number that is proportional to the level of “burstiness”.<br />
<br />
For example, consider measuring “burstiness” for the number of images and news content matching the query “photos”. We first obtain three sequences of term frequencies, e.g. :<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://3.bp.blogspot.com/-8RGFpYCO0eU/URKtx5XfFBI/AAAAAAAAAd0/RnDQO0Ysc6g/s1600/Fig%2B2.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"223\" src=\"http://3.bp.blogspot.com/-8RGFpYCO0eU/URKtx5XfFBI/AAAAAAAAAd0/RnDQO0Ysc6g/s400/Fig%2B2.png\" width=\"400\" /></a></div><i><span style=\"font-size: x-small;\">Fig. 2 : Three sequences of number of Tweets over eight 15 minute buckets from bucket 1 (2 hours ago) to 8 (most recent).<br />
Tweet : counts of Tweets that match query “photos”.<br />
Image : counts of Tweets that match query “photos” and contain image links.<br />
News : counts of Tweets that match query “photos” and contain news links.<br />
Query “photos” is shown not only to match Tweets with image links more than those with news links but also is increasing over time.</span></i><br />
<br />
Our approach to compute the burstiness of image and news facets is an extension of original work by Jon Kleinberg on bursty structure detection, which is in essence matching current level of burst to one of a predefined set of bursty states, while minimizing too diverse a change in matched states for smooth estimation [1].<br />
<br />
In our extension, burstiness of mixable content types including images, users, news, and tweets are computed simultaneously to reflect relative difference in bursty levels between different types and used the distance of observed rate from each state’s bursty level as state cost. This is because accurately estimating probability of occurrence is infeasible for real-time estimation due to expensive computational cost and possible introduction of zero intervals between probability states due to numerical approximation. Optimal state sequences for images and news are estimated as shown in Fig 3.<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://1.bp.blogspot.com/-LaEnOU0Rkms/URKtqth29GI/AAAAAAAAAdo/wWnnvrvAaCA/s1600/Fig%2B3.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"193\" src=\"http://1.bp.blogspot.com/-LaEnOU0Rkms/URKtqth29GI/AAAAAAAAAdo/wWnnvrvAaCA/s400/Fig%2B3.png\" width=\"400\" /></a></div><i><span style=\"font-size: x-small;\">Fig. 3 : Normalized image and news counts are matched to one of n=5 states : 1 average, 2 above, and 2 below.  Matched states curves show a more stable quantization of original sequence which has the effect of removal of small noisy peaks.</span><br />
</i> <br />
<br />
Finally, burstiness of each content type is computed as an exponential moving average of state IDs in the optimal state sequence. As shown in Fig. 3, jointly optimizing the sum of state cost and transition cost yields a smooth quantization of original sequence, which automatically filters out small noisy peaks in original counts. Also, this maps both trending (bursty) and steadily high sequences to a high burstiness value.<br />
<br />
Burstiness computed this way is used to filter out content types with low or no bursts. It’s also used to boost the score of corresponding content types, as a feature for a multi-class classifier that predicts the most likely content type for a query, and in additional components of the ranking system.<br />
<br />
<b>References<br />
</b><br />
[1] J. Kleinberg, Bursty and Hierarchical Structure in Streams, Proc. 8th ACM SIGKDD Intl. Conf. on Knowledge Discovery and Data Mining, 2002. (<a href=\"http://www.cs.cornell.edu/home/kleinber/bhs.pdf\">PDF</a>)<br />
<br />
Posted by <a href=\"http://twitter.com/glassyocean\">Youngin Shin</a><br />
Search-Quality Team" "http://www.blogger.com/feeds/5340805191653517637/posts/default/6494524750527558541" (20754 44895) old 3 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-6494524750527558541") (published nil "2013-02-06T11:30:00.000-08:00") (updated nil "2013-02-06T11:30:39.509-08:00") (title ((type . "text")) "New Twitter search results ") (content ((type . "html")) "We just <a href=\"http://blog.twitter.com/2013/02/search-and-discover-improvements-get.html\">shipped a new version of the Twitter app</a> with a brand new search experience that blends the most relevant content - Tweets, user accounts, images, news, related searches, and more - into a single stream of results. This is a major shift from how we have previously partitioned results by type (for instance, Tweet search vs. people search). We think this simplified experience makes it easier to find great content on Twitter using your mobile device. <br />
<br />
A typical search scores items of the same type and picks the top-scoring results. In a blended search experience, this is not straightforward. The scores of different content types are computed by different services, and thus not directly comparable for blending. Another challenge is to decide which type of content to mix, as not all content types are always desirable to display. This post discusses our approach to solving these challenges.<br />
<br />
<b>Ranking<br />
</b> <br />
When a user searches, different types of content are searched separately, returning a sequence of candidate results for each content type with a type-specific score for each. For certain content types that are displayed as a single group or gallery unit, such as users or images, we assign the maximum score of results as the representative score of this content type. The result sequences for some content types may be trimmed or discarded entirely at this point.<br />
<br />
Once results of different content types are prepared, each type-specific score is converted into a universally compatible score, called a “uniscore”. Uniscores of different modules are used as a means to blend content types as in a merge-sort, except for the penalization of content type transition. This is to avoid over-diversification of content types in the blended result.<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://3.bp.blogspot.com/-McCkggNJrU0/URKuInWEznI/AAAAAAAAAeE/pNNT8WnWwx8/s1600/Fig%2B1.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"203\" src=\"http://3.bp.blogspot.com/-McCkggNJrU0/URKuInWEznI/AAAAAAAAAeE/pNNT8WnWwx8/s400/Fig%2B1.png\" width=\"400\" /></a></div><span style=\"font-size: x-small;\"><i>Fig. 1: Search ranker chose News1 followed by Tweet1 so far and is presented with three candidatesTweet2, User Group, and News2 to pick the content after Tweet1. News2 has the highest uniscore but search ranker picks Tweet2, instead of News2 as we penalize change in type between consecutive content by decreasing the score of News2 from 0.65 to 0.55, for instance.<br />
</i> </span><br />
<br />
<b>Score unification<br />
</b> <br />
Individual content is assigned a type-specific score, which is called a “raw” score, by its corresponding service. To facilitate blending and ranking content of different types as described above, raw scores are converted into uniscores using type-specific log-linear score conversion functions – where the chance of a converted score to take its value in [0, 1] is at least 95%, as estimated from observed dataset.<br />
<br />
<b>Content selection and boosting<br />
</b> <br />
Certain types of content may not have many relevant items to show for a particular input query, in which case we may choose not to include this type of content in search results. In other cases, for instance if query volume or matched item counts have an unusual spike (what we call a “burst”), we show this type and may also boost it to appear at a higher place in the results. To facilitate this, we represent trends in searches or matching result counts as a single number that is proportional to the level of “burstiness”.<br />
<br />
For example, consider measuring “burstiness” for the number of images and news content matching the query “photos”. We first obtain three sequences of term frequencies, e.g. :<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://3.bp.blogspot.com/-8RGFpYCO0eU/URKtx5XfFBI/AAAAAAAAAd0/RnDQO0Ysc6g/s1600/Fig%2B2.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"223\" src=\"http://3.bp.blogspot.com/-8RGFpYCO0eU/URKtx5XfFBI/AAAAAAAAAd0/RnDQO0Ysc6g/s400/Fig%2B2.png\" width=\"400\" /></a></div><i><span style=\"font-size: x-small;\">Fig. 2 : Three sequences of number of Tweets over eight 15 minute buckets from bucket 1 (2 hours ago) to 8 (most recent).<br />
Tweet : counts of Tweets that match query “photos”.<br />
Image : counts of Tweets that match query “photos” and contain image links.<br />
News : counts of Tweets that match query “photos” and contain news links.<br />
Query “photos” is shown not only to match Tweets with image links more than those with news links but also is increasing over time.</span></i><br />
<br />
Our approach to compute the burstiness of image and news facets is an extension of original work by Jon Kleinberg on bursty structure detection, which is in essence matching current level of burst to one of a predefined set of bursty states, while minimizing too diverse a change in matched states for smooth estimation [1].<br />
<br />
In our extension, burstiness of mixable content types including images, users, news, and tweets are computed simultaneously to reflect relative difference in bursty levels between different types and used the distance of observed rate from each state’s bursty level as state cost. This is because accurately estimating probability of occurrence is infeasible for real-time estimation due to expensive computational cost and possible introduction of zero intervals between probability states due to numerical approximation. Optimal state sequences for images and news are estimated as shown in Fig 3.<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://1.bp.blogspot.com/-LaEnOU0Rkms/URKtqth29GI/AAAAAAAAAdo/wWnnvrvAaCA/s1600/Fig%2B3.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"193\" src=\"http://1.bp.blogspot.com/-LaEnOU0Rkms/URKtqth29GI/AAAAAAAAAdo/wWnnvrvAaCA/s400/Fig%2B3.png\" width=\"400\" /></a></div><i><span style=\"font-size: x-small;\">Fig. 3 : Normalized image and news counts are matched to one of n=5 states : 1 average, 2 above, and 2 below.  Matched states curves show a more stable quantization of original sequence which has the effect of removal of small noisy peaks.</span><br />
</i> <br />
<br />
Finally, burstiness of each content type is computed as an exponential moving average of state IDs in the optimal state sequence. As shown in Fig. 3, jointly optimizing the sum of state cost and transition cost yields a smooth quantization of original sequence, which automatically filters out small noisy peaks in original counts. Also, this maps both trending (bursty) and steadily high sequences to a high burstiness value.<br />
<br />
Burstiness computed this way is used to filter out content types with low or no bursts. It’s also used to boost the score of corresponding content types, as a feature for a multi-class classifier that predicts the most likely content type for a query, and in additional components of the ranking system.<br />
<br />
<b>References<br />
</b><br />
[1] J. Kleinberg, Bursty and Hierarchical Structure in Streams, Proc. 8th ACM SIGKDD Intl. Conf. on Knowledge Discovery and Data Mining, 2002. (<a href=\"http://www.cs.cornell.edu/home/kleinber/bhs.pdf\">PDF</a>)<br />
<br />
Posted by <a href=\"http://twitter.com/glassyocean\">Youngin Shin</a><br />
Search-Quality Team") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6494524750527558541"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6494524750527558541"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2013/02/new-twitter-search-results.html") (title . "New Twitter search results "))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://3.bp.blogspot.com/-McCkggNJrU0/URKuInWEznI/AAAAAAAAAeE/pNNT8WnWwx8/s72-c/Fig%2B1.png") (height . "72") (width . "72"))))) ("Introducing Flight: a web application framework" "Last year we rolled out a <a href=\"http://engineering.twitter.com/2012/05/improving-performance-on-twittercom.html\">major reimplementation</a> of the Twitter website. In addition to shifting the rendering of our page content to the server (which achieved significant performance gains), we re-envisioned the entire client-side infrastructure with a clean, robust and easy-to-learn framework which we call <a href=\"http://twitter.github.com/flight/\">Flight</a>. Today we're making Flight available to the open source community under the liberal <a href=\"https://github.com/twitter/flight/blob/master/LICENSE\">MIT license</a> as a framework for structuring web applications. <br />
<br />
Whether you use Flight as the JavaScript framework for your next web project, or just as source for new ideas, we look forward to learning from diverse perspectives via community feedback and contributions on <a href=\"https://github.com/twitter/flight\">GitHub</a>.<br />
<br />
<b><span style=\"font-size: large;\">Why Flight?<br />
</span></b><br />
Flight is distinct from existing frameworks in that it doesn't prescribe or provide any particular approach to rendering or providing data to a web application. It's agnostic on how requests are routed, which templating language you use, or even if you render your HTML on the client or the server. While some web frameworks encourage developers to arrange their code around a prescribed model layer, Flight is organized around the existing DOM model with functionality mapped directly to DOM nodes.<br />
<br />
Not only does this obviate the need for additional data structures that will inevitably influence the broader architecture, but by mapping our functionality directly onto the native web we get to take advantage of native features. For example, we get custom event propagation for free by piggybacking off DOM event bubbling, and our event handling infrastructure works equally well with both native and custom events.<br />
<br />
<b><span style=\"font-size: large;\">How does it work?<br />
</span></b><br />
Flight enforces strict separation of concerns. When you create a component you don't get a handle to it. Consequently, components cannot be referenced by other components and cannot become properties of the global object tree. This is by design. Components do not engage each other directly; instead, they broadcast their actions as events which are subscribed to by other components. <br />
<br />
<b>Why events?<br />
</b><br />
Events are open-ended. When a component triggers an event, it has no knowledge of how its request will be satisfied or by whom. This enforced decoupling of functionality allows the engineer to consider each component in isolation rather than having to reason about the growing complexity of the application as a whole.<br />
<br />
By making DOM node events proxies for component events, we let the web work for us:<br />
<br />
<ul><li>we get event propagation for free</li>
<li>a component can subscribe to a given event type at the document level or it can choose to listen only those events originating from within a specified DOM Node</li>
<li>subscribing components do not distinguish between custom events from other components (e.g. 'dataMailItemsServed') and native DOM node events (e.g. 'click'), and process both types of event in an identical fashion.</li>
</ul><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://3.bp.blogspot.com/-kOtb8efsqvs/UQqgWfqxXhI/AAAAAAAAAdI/2lNVUu3dIyU/s1600/ss1.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"292\" width=\"400\" src=\"http://3.bp.blogspot.com/-kOtb8efsqvs/UQqgWfqxXhI/AAAAAAAAAdI/2lNVUu3dIyU/s400/ss1.png\" /></a></div><br />
<b>Mobility and testing<br />
</b><br />
Each component is a module that, aside from a minimal set of standard dependencies (relevant Flight utilities and mixins), has no reference to the outside world. Thus a given component will respond to a given event in the same way, regardless of environment. This makes testing simple and reliable — events are essentially the only variable, and a production event is easy to replicate in testing. You can even debug a component by triggering events in the console.<br />
<br />
<b>Mixins<br />
</b><br />
A mixin defines a set of functionality that is useful to more than one object. Flight comes with built-in support for <a href=\"http://javascriptweblog.wordpress.com/2011/05/31/a-fresh-look-at-javascript-mixins/\">functional mixins</a>, including protection against unintentional overrides and duplicate mixins. While classical JavaScript patterns support only single inheritance, a component prototype (or other object) can have multiple mixins applied to it. Moreover, mixins requires a fraction of the boilerplate required to form traditional classical hierarchies out of constructor-prototypes hybrids, and don't suffer the leaky abstractions of the latter ('super', 'static', 'const' etc.)<br />
<br />
<b><span style=\"font-size: large;\">Documentation and demo<br />
</span></b><br />
Our GitHub page includes <a href=\"https://github.com/twitter/flight/blob/master/README.md\">full documentation</a> as well as a <a href=\"https://github.com/twitter/flight/tree/gh-pages/demo\">sample app</a> in the form of an <a href=\"http://twitter.github.com/flight/demo/\">email client</a>:<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-jG6yq1qafBc/UQqgcn9JrsI/AAAAAAAAAdU/IqsPjTLGg1Q/s1600/ss2.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"164\" width=\"400\" src=\"http://4.bp.blogspot.com/-jG6yq1qafBc/UQqgcn9JrsI/AAAAAAAAAdU/IqsPjTLGg1Q/s400/ss2.png\" /></a></div><br />
<b><span style=\"font-size: large;\">Future work<br />
</span></b><br />
Flight is an ongoing and evolving project. We’re planning to add a full testing framework and make available more of the utilities that we use for the Twitter website frontend. We also look forward to your contributions and comments. We know we haven’t thought of everything, and with your help we can continue to improve Flight for the benefit of everyone.  <br />
<br />
<b><span style=\"font-size: large;\">Acknowledgments<br />
</span></b><br />
Flight was a group effort. These folks have contributed to the project: Angus Croll (<a href=\"https://twitter.com/angustweets\">@angustweets</a>), Dan Webb (<a href=\"https://twitter.com/danwrong\">@danwrong</a>), Kenneth Kufluk (<a href=\"https://twitter.com/kpk\">@kpk</a>), along with other members the Twitter web team. A special thank you to <a href=\"https://github.com/twitter/flight#authors\">folks in the web community</a> who took the time to review the code.<br />
<br />
On behalf of the Web Core team,<br />
— Angus Croll, Engineer (<a href=\"https://twitter.com/angustweets\">@angustweets</a>)" "http://www.blogger.com/feeds/5340805191653517637/posts/default/4185766333414693779" (20746 41162) old 4 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-4185766333414693779") (published nil "2013-01-31T08:50:00.000-08:00") (updated nil "2013-01-31T08:50:18.943-08:00") (title ((type . "text")) "Introducing Flight: a web application framework") (content ((type . "html")) "Last year we rolled out a <a href=\"http://engineering.twitter.com/2012/05/improving-performance-on-twittercom.html\">major reimplementation</a> of the Twitter website. In addition to shifting the rendering of our page content to the server (which achieved significant performance gains), we re-envisioned the entire client-side infrastructure with a clean, robust and easy-to-learn framework which we call <a href=\"http://twitter.github.com/flight/\">Flight</a>. Today we're making Flight available to the open source community under the liberal <a href=\"https://github.com/twitter/flight/blob/master/LICENSE\">MIT license</a> as a framework for structuring web applications. <br />
<br />
Whether you use Flight as the JavaScript framework for your next web project, or just as source for new ideas, we look forward to learning from diverse perspectives via community feedback and contributions on <a href=\"https://github.com/twitter/flight\">GitHub</a>.<br />
<br />
<b><span style=\"font-size: large;\">Why Flight?<br />
</span></b><br />
Flight is distinct from existing frameworks in that it doesn't prescribe or provide any particular approach to rendering or providing data to a web application. It's agnostic on how requests are routed, which templating language you use, or even if you render your HTML on the client or the server. While some web frameworks encourage developers to arrange their code around a prescribed model layer, Flight is organized around the existing DOM model with functionality mapped directly to DOM nodes.<br />
<br />
Not only does this obviate the need for additional data structures that will inevitably influence the broader architecture, but by mapping our functionality directly onto the native web we get to take advantage of native features. For example, we get custom event propagation for free by piggybacking off DOM event bubbling, and our event handling infrastructure works equally well with both native and custom events.<br />
<br />
<b><span style=\"font-size: large;\">How does it work?<br />
</span></b><br />
Flight enforces strict separation of concerns. When you create a component you don't get a handle to it. Consequently, components cannot be referenced by other components and cannot become properties of the global object tree. This is by design. Components do not engage each other directly; instead, they broadcast their actions as events which are subscribed to by other components. <br />
<br />
<b>Why events?<br />
</b><br />
Events are open-ended. When a component triggers an event, it has no knowledge of how its request will be satisfied or by whom. This enforced decoupling of functionality allows the engineer to consider each component in isolation rather than having to reason about the growing complexity of the application as a whole.<br />
<br />
By making DOM node events proxies for component events, we let the web work for us:<br />
<br />
<ul><li>we get event propagation for free</li>
<li>a component can subscribe to a given event type at the document level or it can choose to listen only those events originating from within a specified DOM Node</li>
<li>subscribing components do not distinguish between custom events from other components (e.g. 'dataMailItemsServed') and native DOM node events (e.g. 'click'), and process both types of event in an identical fashion.</li>
</ul><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://3.bp.blogspot.com/-kOtb8efsqvs/UQqgWfqxXhI/AAAAAAAAAdI/2lNVUu3dIyU/s1600/ss1.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"292\" width=\"400\" src=\"http://3.bp.blogspot.com/-kOtb8efsqvs/UQqgWfqxXhI/AAAAAAAAAdI/2lNVUu3dIyU/s400/ss1.png\" /></a></div><br />
<b>Mobility and testing<br />
</b><br />
Each component is a module that, aside from a minimal set of standard dependencies (relevant Flight utilities and mixins), has no reference to the outside world. Thus a given component will respond to a given event in the same way, regardless of environment. This makes testing simple and reliable — events are essentially the only variable, and a production event is easy to replicate in testing. You can even debug a component by triggering events in the console.<br />
<br />
<b>Mixins<br />
</b><br />
A mixin defines a set of functionality that is useful to more than one object. Flight comes with built-in support for <a href=\"http://javascriptweblog.wordpress.com/2011/05/31/a-fresh-look-at-javascript-mixins/\">functional mixins</a>, including protection against unintentional overrides and duplicate mixins. While classical JavaScript patterns support only single inheritance, a component prototype (or other object) can have multiple mixins applied to it. Moreover, mixins requires a fraction of the boilerplate required to form traditional classical hierarchies out of constructor-prototypes hybrids, and don't suffer the leaky abstractions of the latter ('super', 'static', 'const' etc.)<br />
<br />
<b><span style=\"font-size: large;\">Documentation and demo<br />
</span></b><br />
Our GitHub page includes <a href=\"https://github.com/twitter/flight/blob/master/README.md\">full documentation</a> as well as a <a href=\"https://github.com/twitter/flight/tree/gh-pages/demo\">sample app</a> in the form of an <a href=\"http://twitter.github.com/flight/demo/\">email client</a>:<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-jG6yq1qafBc/UQqgcn9JrsI/AAAAAAAAAdU/IqsPjTLGg1Q/s1600/ss2.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"164\" width=\"400\" src=\"http://4.bp.blogspot.com/-jG6yq1qafBc/UQqgcn9JrsI/AAAAAAAAAdU/IqsPjTLGg1Q/s400/ss2.png\" /></a></div><br />
<b><span style=\"font-size: large;\">Future work<br />
</span></b><br />
Flight is an ongoing and evolving project. We’re planning to add a full testing framework and make available more of the utilities that we use for the Twitter website frontend. We also look forward to your contributions and comments. We know we haven’t thought of everything, and with your help we can continue to improve Flight for the benefit of everyone.  <br />
<br />
<b><span style=\"font-size: large;\">Acknowledgments<br />
</span></b><br />
Flight was a group effort. These folks have contributed to the project: Angus Croll (<a href=\"https://twitter.com/angustweets\">@angustweets</a>), Dan Webb (<a href=\"https://twitter.com/danwrong\">@danwrong</a>), Kenneth Kufluk (<a href=\"https://twitter.com/kpk\">@kpk</a>), along with other members the Twitter web team. A special thank you to <a href=\"https://github.com/twitter/flight#authors\">folks in the web community</a> who took the time to review the code.<br />
<br />
On behalf of the Web Core team,<br />
— Angus Croll, Engineer (<a href=\"https://twitter.com/angustweets\">@angustweets</a>)") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/4185766333414693779"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/4185766333414693779"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2013/01/introducing-flight-web-application.html") (title . "Introducing Flight: a web application framework"))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://3.bp.blogspot.com/-kOtb8efsqvs/UQqgWfqxXhI/AAAAAAAAAdI/2lNVUu3dIyU/s72-c/ss1.png") (height . "72") (width . "72"))))) ("Braindump" "<h2 style=\"background-color: white; color: black; display: inline; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<span style=\"font-size: small;\"><i><span style=\"font-family: &quot;Helvetica Neue&quot;,Arial,Helvetica,sans-serif;\"><span style=\"font-weight: normal;\">Cross-posted from <a href=\"http://blog.oskarsson.nu/post/40196324612/the-twitter-stack\">@skr's blog</a>.&nbsp; </span></span></i></span></h2>
<br />
<br />
<h2 style=\"background-color: white; color: black; display: inline; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<span style=\"font-family: &quot;Helvetica Neue&quot;,Arial,Helvetica,sans-serif;\">The Twitter stack</span></h2>
<br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
For various reasons, including performance and cost, Twitter has poured significant engineering effort into breaking down the site backend into smaller JVM based services. As a nice side effect we’ve been able to open source several of the libraries and other useful tools that came out of this effort.</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
While there is a fair amount of information about these projects available as docs or slides I found no simple, high level introduction to what we can unofficially call the Twitter stack. So here it is. It’s worth noting that all this information is about open source projects, that it is public already and that I am not writing this as part of my job at Twitter or on their behalf.</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Now, granted these were not all conceived at Twitter and plenty of other companies have similar solutions. However I think the software mentioned below is quite powerful and with most of it released as open source it is a fairly compelling platform to base new services off of.</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
I will describe the projects from a Scala perspective, but quite a few are useful in Java programs as well. See the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://twitter.github.com/scala_school/\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Twitter Scala</a><span class=\"Apple-converted-space\">&nbsp;</span>school for an intro to the language, although that is not required to understand this post.</div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Finagle</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
At the heart of a service lies the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/finagle\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Finagle</a><span class=\"Apple-converted-space\">&nbsp;</span>library. By abstracting away the fundamental underpinnings of an RPC system, Finagle greatly reduces the complexity that service developers have to deal with. It allows us to focus on writing application-specific business logic instead of dwelling on lower level details of distributed systems. Ultimately the website itself uses these services to perform operations or fetch data needed to render the HTML. At Twitter the internal services use the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://thrift.apache.org/\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Thrift</a><span class=\"Apple-converted-space\">&nbsp;</span>protocol, but Finagle supports other protocols too such as Protocol buffers and HTTP.<br />
<br />
<b style=\"font-style: normal; font-weight: 700;\">Setting up a service using Finagle</b><br />
A quick dive into how you would set up a Thrift service using Finagle.</div>
<ol style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; list-style: decimal; margin: 10px 0px 10px 30px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<li style=\"margin: 0px; padding: 0px;\">Write a Thrift file defining your API. It should contain the structs, exceptions and methods needed to describe the service functionality. See<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://thrift.apache.org/docs/idl/\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Thrift Interface Description Language (IDL) docs</a>, in particular the examples at the end for more info.</li>
<li style=\"margin: 0px; padding: 0px;\">Use the Thrift file as input for a code generator that spits out code in your language. For Scala and Finagle based projects I would recommend<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/scrooge\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Scrooge</a>.</li>
<li style=\"margin: 0px; padding: 0px;\">Implement the Scala trait generated from your Thrift IDL. This is where the actual functionality of your service goes.</li>
<li style=\"margin: 0px; padding: 0px;\">Provide the Finagle server builder an instance of the implementation above, a port to bind to and any other settings you might need and start it up.</li>
</ol>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<br />
That looks pretty similar to just using plain Thrift without Finagle. However, there are quite a few improvements such as excellent monitoring support, tracing and Finagle makes it easy to write your service in an asynchronous fashion. More about these features later.<br />
<br />
You can also use Finagle as a client. It takes care of all the boring stuff such as timeouts, retries and load balancing for you.</div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Ostrich</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
So let’s say we have a Finagle Thrift service running. It’s doing very important work. Obviously you want to make sure it keeps doing that work and that it performs well. This is where<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/ostrich\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Ostrich</a><span class=\"Apple-converted-space\">&nbsp;</span>comes in.<br />
<br />
<b style=\"font-style: normal; font-weight: 700;\">Metrics</b><br />
Ostrich makes it easy to expose various metrics from your service. Let’s say you want to count how many times a particular piece of code is run. In your service you’d write a line of code that looks something like this:<br />
<br />
<code style=\"font-family: Monaco, 'Andale Mono', 'Liberation Mono', 'Courier New', monotype; font-size: 11px; font-style: normal; font-variant: normal; font-weight: normal; line-height: normal;\">Stats.incr(“some_important_counter”)</code><br />
<br />
As simple as that. The counter named some_important_counter will be incremented by 1.<span class=\"Apple-converted-space\">&nbsp;</span><br />
<br />
In addition to just straight up counters you can get gauges that report on the value of a variable:<br />
<br />
<code style=\"font-family: Monaco, 'Andale Mono', 'Liberation Mono', 'Courier New', monotype; font-size: 11px; font-style: normal; font-variant: normal; font-weight: normal; line-height: normal;\">Stats.addGauge(\"current_temperature\") { myThermometer.temperature }</code><br />
<br />
or you can time a snippet of code to track the performance<br />
<br />
<code style=\"font-family: Monaco, 'Andale Mono', 'Liberation Mono', 'Courier New', monotype; font-size: 11px; font-style: normal; font-variant: normal; font-weight: normal; line-height: normal;\">Stats.time(\"translation\") {<br />
&nbsp;document.translate(\"de\", \"en\")<br />
}</code><br />
<br />
Those and other examples can be found in the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/ostrich\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Ostrich readme</a>.<br />
<br />
<b style=\"font-style: normal; font-weight: 700;\">Export metrics</b><br />
Ostrich runs a small http admin interface to expose these metrics and other functionality. To fetch them you would simply hit http://hostname:port/stats.json to get the current snapshot of the metrics as JSON. At Twitter the stats from each service will be ingested from Ostrich by our internal observability stack, providing us with fancy graphs, alerting and so on.<br />
<br />
To tie this back to our previous section: If you provide a Finagle client or server builder with an Ostrich backed StatsReceiver it’ll happily splurt out tons of metrics about how the service is performing, the latencies for the RPC calls and the number of calls to each method to name a few.<br />
<br />
Ostrich can also deal with configuring your service, shutting down all the components gracefully and more.</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<br />
<img height=\"415px;\" src=\"https://lh4.googleusercontent.com/erHY9IvhEPTsi8rcfTc_dN38Fooa-fyN-N_YHCW3XR0WDtd8K9aGsQwXyH4bRwXWniWcesbpi37uQ9RDtEh45EC2XzlsEAjN3p7twM7THqrM3pdTEoY\" style=\"border: 0px;\" width=\"595px;\" /><br />
This is an example of what a dashboard could look like with stats gathered from Ostrich by our observability stack. Screenshot from @raffi’s<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://www.slideshare.net/raffikrikorian/realtime-systems-at-twitter\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">presentation</a><span class=\"Apple-converted-space\">&nbsp;</span>deck.<br />
<br /></div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Zipkin</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Ostrich and Finagle combined gives us good service level metrics. However, one downside of a more service oriented architecture is that it’s hard to get a high level performance overview of a single request throughout the stack.<br />
Perhaps you are a developer tasked with improving performance of a particular external api endpoint. With Zipkin you can get a visual representation of where most of the time to fulfill the request was spent. Think Firebug or Chrome developer tools for the back end.<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/zipkin/\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Zipkin</a><span class=\"Apple-converted-space\">&nbsp;</span>is a implementation of a tracing system based off of the Google Dapper paper.<br />
<br />
<b style=\"font-style: normal; font-weight: 700;\">Finagle-Zipkin</b><br />
So how does it work? There’s a<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/finagle/tree/master/finagle-zipkin\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">finagle-zipkin</a><span class=\"Apple-converted-space\">&nbsp;</span>module that will hook into the transmission logic of Finagle and time each operation performed by the service. It also passes request identifiers down to any services it relies on, this is how we can tie all the tracing data together. The tracing data is logged to the Zipkin backend and finally we can display and visualize that data in the Zipkin UI.<br />
<br />
Let’s say we use Zipkin to inspect a request and we see that it spent most of it’s time waiting for a query to a MySQL database. We could then also see the actual SQL query sent and draw some conclusions from it. Other times perhaps a GC in a Scala service was a fault. Either way, the hope is that a glance at the trace view will reveal where the developer should spend effort improving performance.<br />
<br />
Enabling tracing for Finagle services is often as simple as adding</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<code style=\"font-family: Monaco, 'Andale Mono', 'Liberation Mono', 'Courier New', monotype; font-size: 11px; font-style: normal; font-variant: normal; font-weight: normal; line-height: normal;\">.tracerFactory(ZipkinTracer())</code></div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
to your ClientBuilder or ServerBuilder. Setting up the whole Zipkin stack is a bit more work though, check out the docs for further assistance.</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<br />
<img height=\"334px;\" src=\"https://lh4.googleusercontent.com/LtHgQzXNOwMGI-2O1mVV_c3gklOziYL99p6Nbg6A2RbnkC7c5OMkHipHcc3KZE2jPg30_VXAy3axWpyben4Nndo8DKCnwOnX2HQbsiBPP9mDmnNjRl8\" style=\"border: 0px;\" width=\"614px;\" /><br />
Trace view, taken from my Strange loop<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://www.slideshare.net/johanoskarsson/zipkin-strangeloop\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">talk</a><span class=\"Apple-converted-space\">&nbsp;</span>about Zipkin.</div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Mesos</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<a href=\"http://incubator.apache.org/mesos/\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Mesos</a><span class=\"Apple-converted-space\">&nbsp;</span>describes itself as “a cluster manager that provides efficient resource isolation and sharing across distributed applications, or frameworks”. I’ll try to go through this section without using buzzwords such as “private cloud”, although technically I just did.<br />
<br />
The core Mesos project is an open source Apache incubator project. On top of it you can run schedulers that deal with more specific technologies, for example Storm and Hadoop. The idea being that the same hardware can be used for multiple purposes, reducing wasted resources.<br />
<br />
In addition to using<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://storm-project.net/\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Storm</a><span class=\"Apple-converted-space\">&nbsp;</span>on top of Mesos we deploy some of our JVM-based services to internal Mesos clusters. With the proper configuration it takes care of concerns such as rack diversity, rescheduling if a machine goes down and so on.<span class=\"Apple-converted-space\">&nbsp;</span><br />
<br />
The constraints imposed by Mesos have the positive side effect of enforcing adherence to various good distributed systems practices. For example:</div>
<ul style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; list-style: disc; margin: 10px 0px 10px 30px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<li style=\"margin: 0px; padding: 0px;\">Service owners shouldn’t make any assumptions about jobs’ lifetimes, as the Mesos scheduler can move jobs to new hosts at any time.</li>
<li style=\"margin: 0px; padding: 0px;\">Jobs shouldn’t write to local disk, since persistence is not guaranteed.</li>
<li style=\"margin: 0px; padding: 0px;\">Deploy tooling and configs shouldn’t use static server lists, since Mesos implies deployment to a dynamic environment.</li>
</ul>
<br />
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Iago</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Before putting your new service into production you might want to check how it performs under load. That’s where<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/iago\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Iago</a><span class=\"Apple-converted-space\">&nbsp;</span>(formerly Parrot) comes in handy. It’s a load testing framework that is pretty easy to use.<br />
<br />
The process might look something like this:</div>
<ol style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; list-style: decimal; margin: 10px 0px 10px 30px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<li style=\"margin: 0px; padding: 0px;\">Collect relevant traffic logs that you want to use as the basis for your load test.</li>
<li style=\"margin: 0px; padding: 0px;\">Write a configuration file for the test. It contains the hostnames to send load to, the number of requests per second, the load pattern and so on.</li>
<li style=\"margin: 0px; padding: 0px;\">Write the actual load test. It receives a log line, you transform that into a request to a client.</li>
<li style=\"margin: 0px; padding: 0px;\">Run the load test. At Twitter this will start up a few tasks in a Mesos cluster, send the traffic and log metrics.</li>
</ol>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<br />
<b style=\"font-style: normal; font-weight: 700;\">Example</b><br />
A load test class could be as simple as this:<br />
<br />
<code style=\"font-family: Monaco, 'Andale Mono', 'Liberation Mono', 'Courier New', monotype; font-size: 11px; font-style: normal; font-variant: normal; font-weight: normal; line-height: normal;\">class LoadTest(parrotService: ParrotService[ParrotRequest, Array[Byte]]) extends <br />
&nbsp;ThriftRecordProcessor(parrotService) {<br />
<br />
&nbsp;val client = new YourService.FinagledClient(service, new TBinaryProtocol.Factory())<br />
<br />
&nbsp;def processLines(job: ParrotJob, lines: Seq[String]) {<br />
&nbsp;&nbsp;&nbsp;lines foreach {line =&gt;client.doSomething(line) }<br />
&nbsp;}<br />
}<span class=\"Apple-converted-space\">&nbsp;</span></code><br />
<br />
This class will feed each log line to your service’s doSomething method, according to the parameters defined in the configuration of parrotService.</div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
ZooKeeper</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
ZooKeeper is an Apache project that is handy for all kinds of distributed systems coordination.<span class=\"Apple-converted-space\">&nbsp;</span><br />
<br />
One use case for ZooKeeper within Twitter is service discovery. Finagle services register themselves in ZooKeeper using our ServerSet library, see<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/finagle/tree/master/finagle-serversets\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">finagle-serversets</a>. This allows clients to simply say they’d like to communicate with “the production cluster for service a in data centre b” and the ServerSet implementation will ensure an up-to-date host list is available. Whenever new capacity is added the client will automatically be aware and will start load balancing across all servers.<br />
<br /></div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Scalding</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
From the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/scalding\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Scalding</a><span class=\"Apple-converted-space\">&nbsp;</span>github page: “Scalding is a Scala library that makes it easy to write MapReduce jobs in Hadoop. Instead of forcing you to write raw map and reduce functions, Scalding allows you to write code that looks like natural Scala”.<br />
<br />
As it turns out services that receive a lot of traffic generate tons of log entries. These can provide useful insights into user behavior or perhaps you need to transform them to be suitable as Iago load test input.<br />
<br />
I have to admit I was a bit sceptical about Scalding at first. It seemed there were already plenty of ways to write Hadoop jobs. Pig, Hive, plain MapReduce, Cascading and so on. However, when the rest of your project is in Scala it is very handy to be able to write Hadoop jobs in the same language. The syntax is often very close to the one used by Scala’s collection library, so you feel right at home, the difference being that with Scalding you might process terabytes of data with the same lines of code.<br />
<br />
A simple word count example from their tutorial:</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
&nbsp;<span class=\"Apple-converted-space\">&nbsp;</span><code style=\"font-family: Monaco, 'Andale Mono', 'Liberation Mono', 'Courier New', monotype; font-size: 11px; font-style: normal; font-variant: normal; font-weight: normal; line-height: normal;\">TextLine(args(\"input\"))<br />
&nbsp;&nbsp;&nbsp;.read<br />
&nbsp;&nbsp;&nbsp;.flatMap('line -&gt; 'word){ line : String =&gt; line.split(\"\\\\s\")}<br />
&nbsp;&nbsp;&nbsp;.groupBy('word){group =&gt; group.size}<br />
&nbsp;&nbsp;&nbsp;.write(Tsv(args(\"output\")))</code></div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
jvmgcprof</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
One of the well known downsides of relying on the JVM for time sensitive requests is that garbage collection pauses could ruin your day. If you’re unlucky a GC pause might hit at the wrong time, causing some requests to perform poorly or even timeout. Worst case that might have knock on effects that leads to downtime.<br />
<br />
As a first line of defence against GC issues you should of course tweak your JVM startup parameters to suit the kind of work the service is undertaking. I’ve found these<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://www.slideshare.net/aszegedi/everything-i-ever-learned-about-jvm-performance-tuning-twitter\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">slides</a><span class=\"Apple-converted-space\">&nbsp;</span>from Twitter alumni Attila Szegedi extremely helpful.<br />
<br />
Of course, you could minimize GC issues by reducing the amount of garbage your service generates. Start your service with jvmgcprof and it’ll help you reach that goal. If you already use Ostrich to track metrics in your service you can tell jvmgcprof which metric represents the work completed. For example you might want to know how many kilobytes of garbage is generated per incoming Thrift request. The jvmgcprof output for that could look something like this.<br />
<br />
2797MB w=101223 (231MB/s 28kB/w)<br />
50.00% &nbsp;8 &nbsp;&nbsp;297<br />
90.00% &nbsp;14 &nbsp;542<br />
95.00% &nbsp;15 &nbsp;572<br />
99.00% &nbsp;61 &nbsp;2237<br />
99.90% &nbsp;2620 &nbsp;&nbsp;&nbsp;94821<br />
99.99% &nbsp;2652 &nbsp;&nbsp;&nbsp;95974<br />
<br />
On the first line you can see that the number requests or work were 101223 for the period monitored, with 231MB/s of garbage or 28kB per request. The garbage per request can easily be compared after changes has been made to see if they had a positive or negative impact on garbage generation. See the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/jvmgcprof\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">jvmgcprof readme</a><span class=\"Apple-converted-space\">&nbsp;</span>for more information.</div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Summary</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
It’s no surprise, but it turns out that having a common stack is very beneficial. Improvements and bug fixes made by one team will benefit others. There is of course another side to that coin, sometimes bugs are introduced that might just be triggered in your service. However, as an example, when developing Zipkin it was immensely helpful to be able to assume that everyone used Finagle. That way they would get tracing for free once we were done.<br />
<br />
I have left out some of the benefits of the Twitter stack and how we use Scala, such as the very convenient way Futures allow you to deal with results from asynchronous requests. I hope to write a more in depth post on how to set up a Twitter style service that would deal with the details omitted in this article. In the meantime you can check out the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://twitter.github.com/scala_school/\">Scala school</a><span class=\"Apple-converted-space\">&nbsp;</span>for more information.<br />
<br />
Thanks to everyone who worked on the projects mentioned in this article, too many to name but you know who you are.<br />
<br />
Posted by <a href=\"https://twitter.com/skr\">Johan Oskarsson</a></div>" "http://www.blogger.com/feeds/5340805191653517637/posts/default/1769042099084361630" (20743 2457) old 5 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-1769042099084361630") (published nil "2013-01-28T15:28:00.000-08:00") (updated nil "2013-01-28T15:28:25.958-08:00") (title ((type . "text")) "Braindump") (content ((type . "html")) "<h2 style=\"background-color: white; color: black; display: inline; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<span style=\"font-size: small;\"><i><span style=\"font-family: &quot;Helvetica Neue&quot;,Arial,Helvetica,sans-serif;\"><span style=\"font-weight: normal;\">Cross-posted from <a href=\"http://blog.oskarsson.nu/post/40196324612/the-twitter-stack\">@skr's blog</a>.&nbsp; </span></span></i></span></h2>
<br />
<br />
<h2 style=\"background-color: white; color: black; display: inline; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<span style=\"font-family: &quot;Helvetica Neue&quot;,Arial,Helvetica,sans-serif;\">The Twitter stack</span></h2>
<br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
For various reasons, including performance and cost, Twitter has poured significant engineering effort into breaking down the site backend into smaller JVM based services. As a nice side effect we’ve been able to open source several of the libraries and other useful tools that came out of this effort.</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
While there is a fair amount of information about these projects available as docs or slides I found no simple, high level introduction to what we can unofficially call the Twitter stack. So here it is. It’s worth noting that all this information is about open source projects, that it is public already and that I am not writing this as part of my job at Twitter or on their behalf.</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Now, granted these were not all conceived at Twitter and plenty of other companies have similar solutions. However I think the software mentioned below is quite powerful and with most of it released as open source it is a fairly compelling platform to base new services off of.</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
I will describe the projects from a Scala perspective, but quite a few are useful in Java programs as well. See the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://twitter.github.com/scala_school/\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Twitter Scala</a><span class=\"Apple-converted-space\">&nbsp;</span>school for an intro to the language, although that is not required to understand this post.</div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Finagle</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
At the heart of a service lies the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/finagle\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Finagle</a><span class=\"Apple-converted-space\">&nbsp;</span>library. By abstracting away the fundamental underpinnings of an RPC system, Finagle greatly reduces the complexity that service developers have to deal with. It allows us to focus on writing application-specific business logic instead of dwelling on lower level details of distributed systems. Ultimately the website itself uses these services to perform operations or fetch data needed to render the HTML. At Twitter the internal services use the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://thrift.apache.org/\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Thrift</a><span class=\"Apple-converted-space\">&nbsp;</span>protocol, but Finagle supports other protocols too such as Protocol buffers and HTTP.<br />
<br />
<b style=\"font-style: normal; font-weight: 700;\">Setting up a service using Finagle</b><br />
A quick dive into how you would set up a Thrift service using Finagle.</div>
<ol style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; list-style: decimal; margin: 10px 0px 10px 30px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<li style=\"margin: 0px; padding: 0px;\">Write a Thrift file defining your API. It should contain the structs, exceptions and methods needed to describe the service functionality. See<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://thrift.apache.org/docs/idl/\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Thrift Interface Description Language (IDL) docs</a>, in particular the examples at the end for more info.</li>
<li style=\"margin: 0px; padding: 0px;\">Use the Thrift file as input for a code generator that spits out code in your language. For Scala and Finagle based projects I would recommend<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/scrooge\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Scrooge</a>.</li>
<li style=\"margin: 0px; padding: 0px;\">Implement the Scala trait generated from your Thrift IDL. This is where the actual functionality of your service goes.</li>
<li style=\"margin: 0px; padding: 0px;\">Provide the Finagle server builder an instance of the implementation above, a port to bind to and any other settings you might need and start it up.</li>
</ol>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<br />
That looks pretty similar to just using plain Thrift without Finagle. However, there are quite a few improvements such as excellent monitoring support, tracing and Finagle makes it easy to write your service in an asynchronous fashion. More about these features later.<br />
<br />
You can also use Finagle as a client. It takes care of all the boring stuff such as timeouts, retries and load balancing for you.</div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Ostrich</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
So let’s say we have a Finagle Thrift service running. It’s doing very important work. Obviously you want to make sure it keeps doing that work and that it performs well. This is where<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/ostrich\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Ostrich</a><span class=\"Apple-converted-space\">&nbsp;</span>comes in.<br />
<br />
<b style=\"font-style: normal; font-weight: 700;\">Metrics</b><br />
Ostrich makes it easy to expose various metrics from your service. Let’s say you want to count how many times a particular piece of code is run. In your service you’d write a line of code that looks something like this:<br />
<br />
<code style=\"font-family: Monaco, 'Andale Mono', 'Liberation Mono', 'Courier New', monotype; font-size: 11px; font-style: normal; font-variant: normal; font-weight: normal; line-height: normal;\">Stats.incr(“some_important_counter”)</code><br />
<br />
As simple as that. The counter named some_important_counter will be incremented by 1.<span class=\"Apple-converted-space\">&nbsp;</span><br />
<br />
In addition to just straight up counters you can get gauges that report on the value of a variable:<br />
<br />
<code style=\"font-family: Monaco, 'Andale Mono', 'Liberation Mono', 'Courier New', monotype; font-size: 11px; font-style: normal; font-variant: normal; font-weight: normal; line-height: normal;\">Stats.addGauge(\"current_temperature\") { myThermometer.temperature }</code><br />
<br />
or you can time a snippet of code to track the performance<br />
<br />
<code style=\"font-family: Monaco, 'Andale Mono', 'Liberation Mono', 'Courier New', monotype; font-size: 11px; font-style: normal; font-variant: normal; font-weight: normal; line-height: normal;\">Stats.time(\"translation\") {<br />
&nbsp;document.translate(\"de\", \"en\")<br />
}</code><br />
<br />
Those and other examples can be found in the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/ostrich\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Ostrich readme</a>.<br />
<br />
<b style=\"font-style: normal; font-weight: 700;\">Export metrics</b><br />
Ostrich runs a small http admin interface to expose these metrics and other functionality. To fetch them you would simply hit http://hostname:port/stats.json to get the current snapshot of the metrics as JSON. At Twitter the stats from each service will be ingested from Ostrich by our internal observability stack, providing us with fancy graphs, alerting and so on.<br />
<br />
To tie this back to our previous section: If you provide a Finagle client or server builder with an Ostrich backed StatsReceiver it’ll happily splurt out tons of metrics about how the service is performing, the latencies for the RPC calls and the number of calls to each method to name a few.<br />
<br />
Ostrich can also deal with configuring your service, shutting down all the components gracefully and more.</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<br />
<img height=\"415px;\" src=\"https://lh4.googleusercontent.com/erHY9IvhEPTsi8rcfTc_dN38Fooa-fyN-N_YHCW3XR0WDtd8K9aGsQwXyH4bRwXWniWcesbpi37uQ9RDtEh45EC2XzlsEAjN3p7twM7THqrM3pdTEoY\" style=\"border: 0px;\" width=\"595px;\" /><br />
This is an example of what a dashboard could look like with stats gathered from Ostrich by our observability stack. Screenshot from @raffi’s<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://www.slideshare.net/raffikrikorian/realtime-systems-at-twitter\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">presentation</a><span class=\"Apple-converted-space\">&nbsp;</span>deck.<br />
<br /></div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Zipkin</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Ostrich and Finagle combined gives us good service level metrics. However, one downside of a more service oriented architecture is that it’s hard to get a high level performance overview of a single request throughout the stack.<br />
Perhaps you are a developer tasked with improving performance of a particular external api endpoint. With Zipkin you can get a visual representation of where most of the time to fulfill the request was spent. Think Firebug or Chrome developer tools for the back end.<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/zipkin/\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Zipkin</a><span class=\"Apple-converted-space\">&nbsp;</span>is a implementation of a tracing system based off of the Google Dapper paper.<br />
<br />
<b style=\"font-style: normal; font-weight: 700;\">Finagle-Zipkin</b><br />
So how does it work? There’s a<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/finagle/tree/master/finagle-zipkin\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">finagle-zipkin</a><span class=\"Apple-converted-space\">&nbsp;</span>module that will hook into the transmission logic of Finagle and time each operation performed by the service. It also passes request identifiers down to any services it relies on, this is how we can tie all the tracing data together. The tracing data is logged to the Zipkin backend and finally we can display and visualize that data in the Zipkin UI.<br />
<br />
Let’s say we use Zipkin to inspect a request and we see that it spent most of it’s time waiting for a query to a MySQL database. We could then also see the actual SQL query sent and draw some conclusions from it. Other times perhaps a GC in a Scala service was a fault. Either way, the hope is that a glance at the trace view will reveal where the developer should spend effort improving performance.<br />
<br />
Enabling tracing for Finagle services is often as simple as adding</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<code style=\"font-family: Monaco, 'Andale Mono', 'Liberation Mono', 'Courier New', monotype; font-size: 11px; font-style: normal; font-variant: normal; font-weight: normal; line-height: normal;\">.tracerFactory(ZipkinTracer())</code></div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
to your ClientBuilder or ServerBuilder. Setting up the whole Zipkin stack is a bit more work though, check out the docs for further assistance.</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<br />
<img height=\"334px;\" src=\"https://lh4.googleusercontent.com/LtHgQzXNOwMGI-2O1mVV_c3gklOziYL99p6Nbg6A2RbnkC7c5OMkHipHcc3KZE2jPg30_VXAy3axWpyben4Nndo8DKCnwOnX2HQbsiBPP9mDmnNjRl8\" style=\"border: 0px;\" width=\"614px;\" /><br />
Trace view, taken from my Strange loop<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://www.slideshare.net/johanoskarsson/zipkin-strangeloop\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">talk</a><span class=\"Apple-converted-space\">&nbsp;</span>about Zipkin.</div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Mesos</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<a href=\"http://incubator.apache.org/mesos/\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Mesos</a><span class=\"Apple-converted-space\">&nbsp;</span>describes itself as “a cluster manager that provides efficient resource isolation and sharing across distributed applications, or frameworks”. I’ll try to go through this section without using buzzwords such as “private cloud”, although technically I just did.<br />
<br />
The core Mesos project is an open source Apache incubator project. On top of it you can run schedulers that deal with more specific technologies, for example Storm and Hadoop. The idea being that the same hardware can be used for multiple purposes, reducing wasted resources.<br />
<br />
In addition to using<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://storm-project.net/\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Storm</a><span class=\"Apple-converted-space\">&nbsp;</span>on top of Mesos we deploy some of our JVM-based services to internal Mesos clusters. With the proper configuration it takes care of concerns such as rack diversity, rescheduling if a machine goes down and so on.<span class=\"Apple-converted-space\">&nbsp;</span><br />
<br />
The constraints imposed by Mesos have the positive side effect of enforcing adherence to various good distributed systems practices. For example:</div>
<ul style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; list-style: disc; margin: 10px 0px 10px 30px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<li style=\"margin: 0px; padding: 0px;\">Service owners shouldn’t make any assumptions about jobs’ lifetimes, as the Mesos scheduler can move jobs to new hosts at any time.</li>
<li style=\"margin: 0px; padding: 0px;\">Jobs shouldn’t write to local disk, since persistence is not guaranteed.</li>
<li style=\"margin: 0px; padding: 0px;\">Deploy tooling and configs shouldn’t use static server lists, since Mesos implies deployment to a dynamic environment.</li>
</ul>
<br />
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Iago</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Before putting your new service into production you might want to check how it performs under load. That’s where<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/iago\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Iago</a><span class=\"Apple-converted-space\">&nbsp;</span>(formerly Parrot) comes in handy. It’s a load testing framework that is pretty easy to use.<br />
<br />
The process might look something like this:</div>
<ol style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; list-style: decimal; margin: 10px 0px 10px 30px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<li style=\"margin: 0px; padding: 0px;\">Collect relevant traffic logs that you want to use as the basis for your load test.</li>
<li style=\"margin: 0px; padding: 0px;\">Write a configuration file for the test. It contains the hostnames to send load to, the number of requests per second, the load pattern and so on.</li>
<li style=\"margin: 0px; padding: 0px;\">Write the actual load test. It receives a log line, you transform that into a request to a client.</li>
<li style=\"margin: 0px; padding: 0px;\">Run the load test. At Twitter this will start up a few tasks in a Mesos cluster, send the traffic and log metrics.</li>
</ol>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
<br />
<b style=\"font-style: normal; font-weight: 700;\">Example</b><br />
A load test class could be as simple as this:<br />
<br />
<code style=\"font-family: Monaco, 'Andale Mono', 'Liberation Mono', 'Courier New', monotype; font-size: 11px; font-style: normal; font-variant: normal; font-weight: normal; line-height: normal;\">class LoadTest(parrotService: ParrotService[ParrotRequest, Array[Byte]]) extends <br />
&nbsp;ThriftRecordProcessor(parrotService) {<br />
<br />
&nbsp;val client = new YourService.FinagledClient(service, new TBinaryProtocol.Factory())<br />
<br />
&nbsp;def processLines(job: ParrotJob, lines: Seq[String]) {<br />
&nbsp;&nbsp;&nbsp;lines foreach {line =&gt;client.doSomething(line) }<br />
&nbsp;}<br />
}<span class=\"Apple-converted-space\">&nbsp;</span></code><br />
<br />
This class will feed each log line to your service’s doSomething method, according to the parameters defined in the configuration of parrotService.</div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
ZooKeeper</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
ZooKeeper is an Apache project that is handy for all kinds of distributed systems coordination.<span class=\"Apple-converted-space\">&nbsp;</span><br />
<br />
One use case for ZooKeeper within Twitter is service discovery. Finagle services register themselves in ZooKeeper using our ServerSet library, see<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/finagle/tree/master/finagle-serversets\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">finagle-serversets</a>. This allows clients to simply say they’d like to communicate with “the production cluster for service a in data centre b” and the ServerSet implementation will ensure an up-to-date host list is available. Whenever new capacity is added the client will automatically be aware and will start load balancing across all servers.<br />
<br /></div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Scalding</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
From the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/scalding\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">Scalding</a><span class=\"Apple-converted-space\">&nbsp;</span>github page: “Scalding is a Scala library that makes it easy to write MapReduce jobs in Hadoop. Instead of forcing you to write raw map and reduce functions, Scalding allows you to write code that looks like natural Scala”.<br />
<br />
As it turns out services that receive a lot of traffic generate tons of log entries. These can provide useful insights into user behavior or perhaps you need to transform them to be suitable as Iago load test input.<br />
<br />
I have to admit I was a bit sceptical about Scalding at first. It seemed there were already plenty of ways to write Hadoop jobs. Pig, Hive, plain MapReduce, Cascading and so on. However, when the rest of your project is in Scala it is very handy to be able to write Hadoop jobs in the same language. The syntax is often very close to the one used by Scala’s collection library, so you feel right at home, the difference being that with Scalding you might process terabytes of data with the same lines of code.<br />
<br />
A simple word count example from their tutorial:</div>
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 0px 0px 10px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
&nbsp;<span class=\"Apple-converted-space\">&nbsp;</span><code style=\"font-family: Monaco, 'Andale Mono', 'Liberation Mono', 'Courier New', monotype; font-size: 11px; font-style: normal; font-variant: normal; font-weight: normal; line-height: normal;\">TextLine(args(\"input\"))<br />
&nbsp;&nbsp;&nbsp;.read<br />
&nbsp;&nbsp;&nbsp;.flatMap('line -&gt; 'word){ line : String =&gt; line.split(\"\\\\s\")}<br />
&nbsp;&nbsp;&nbsp;.groupBy('word){group =&gt; group.size}<br />
&nbsp;&nbsp;&nbsp;.write(Tsv(args(\"output\")))</code></div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
jvmgcprof</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
One of the well known downsides of relying on the JVM for time sensitive requests is that garbage collection pauses could ruin your day. If you’re unlucky a GC pause might hit at the wrong time, causing some requests to perform poorly or even timeout. Worst case that might have knock on effects that leads to downtime.<br />
<br />
As a first line of defence against GC issues you should of course tweak your JVM startup parameters to suit the kind of work the service is undertaking. I’ve found these<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://www.slideshare.net/aszegedi/everything-i-ever-learned-about-jvm-performance-tuning-twitter\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">slides</a><span class=\"Apple-converted-space\">&nbsp;</span>from Twitter alumni Attila Szegedi extremely helpful.<br />
<br />
Of course, you could minimize GC issues by reducing the amount of garbage your service generates. Start your service with jvmgcprof and it’ll help you reach that goal. If you already use Ostrich to track metrics in your service you can tell jvmgcprof which metric represents the work completed. For example you might want to know how many kilobytes of garbage is generated per incoming Thrift request. The jvmgcprof output for that could look something like this.<br />
<br />
2797MB w=101223 (231MB/s 28kB/w)<br />
50.00% &nbsp;8 &nbsp;&nbsp;297<br />
90.00% &nbsp;14 &nbsp;542<br />
95.00% &nbsp;15 &nbsp;572<br />
99.00% &nbsp;61 &nbsp;2237<br />
99.90% &nbsp;2620 &nbsp;&nbsp;&nbsp;94821<br />
99.99% &nbsp;2652 &nbsp;&nbsp;&nbsp;95974<br />
<br />
On the first line you can see that the number requests or work were 101223 for the period monitored, with 231MB/s of garbage or 28kB per request. The garbage per request can easily be compared after changes has been made to see if they had a positive or negative impact on garbage generation. See the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"https://github.com/twitter/jvmgcprof\" style=\"color: #666666; outline: rgb(0, 0, 0); text-decoration: initial;\">jvmgcprof readme</a><span class=\"Apple-converted-space\">&nbsp;</span>for more information.</div>
<h1 style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 20px; font-style: normal; font-variant: normal; font-weight: bold; letter-spacing: normal; line-height: normal; margin: 0px 5px 0px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
Summary</h1>
<span style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; display: inline !important; float: none; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"></span><br />
<div style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: white; color: black; font-family: 'Helvetica Neue', Helvetica, Arial, 'Liberation Sans', FreeSans, sans-serif; font-size: 13px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; margin: 10px 0px; orphans: 2; padding: 0px; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\">
It’s no surprise, but it turns out that having a common stack is very beneficial. Improvements and bug fixes made by one team will benefit others. There is of course another side to that coin, sometimes bugs are introduced that might just be triggered in your service. However, as an example, when developing Zipkin it was immensely helpful to be able to assume that everyone used Finagle. That way they would get tracing for free once we were done.<br />
<br />
I have left out some of the benefits of the Twitter stack and how we use Scala, such as the very convenient way Futures allow you to deal with results from asynchronous requests. I hope to write a more in depth post on how to set up a Twitter style service that would deal with the details omitted in this article. In the meantime you can check out the<span class=\"Apple-converted-space\">&nbsp;</span><a href=\"http://twitter.github.com/scala_school/\">Scala school</a><span class=\"Apple-converted-space\">&nbsp;</span>for more information.<br />
<br />
Thanks to everyone who worked on the projects mentioned in this article, too many to name but you know who you are.<br />
<br />
Posted by <a href=\"https://twitter.com/skr\">Johan Oskarsson</a></div>
") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/1769042099084361630"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/1769042099084361630"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2013/01/braindump.html") (title . "Braindump"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))))) ("Improving Twitter search with real-time human computation" "One of the magical things about Twitter is that it opens a window to the world in <i>real-time</i>. An event happens, and seconds later, people share it across the planet.<br />
<p>Consider, for example, what happened when Flight 1549 crashed in the Hudson River: <br />
<p><blockquote class=\"twitter-tweet\"><a href=\"http://twitpic.com/135xa\">http://twitpic.com/135xa</a> - There's a plane in the Hudson. I'm on the ferry going to pick up the people. Crazy.<br />
— Janis Krums (@jkrums) <a data-datetime=\"2009-01-15T20:36:04+00:00\" href=\"https://twitter.com/jkrums/status/1121915133\">January 15, 2009</a></blockquote><script async=\"async\" charset=\"utf-8\" src=\"//platform.twitter.com/widgets.js\"></script><br />
Or when Osama bin Laden was killed:<br />
<br />
<blockquote class=\"twitter-tweet\">Helicopter hovering above Abbottabad at 1AM (is a rare event).<br />
— Sohaib Athar (@ReallyVirtual) <a data-datetime=\"2011-05-01T19:58:24+00:00\" href=\"https://twitter.com/ReallyVirtual/status/64780730286358528\">May 1, 2011</a></blockquote><script async=\"async\" charset=\"utf-8\" src=\"//platform.twitter.com/widgets.js\"></script><br />
Or when Obama was re-elected:<br />
<br />
<blockquote class=\"twitter-tweet\">Four more years. <a href=\"http://t.co/bAJE6Vom\" title=\"http://twitter.com/BarackObama/status/266031293945503744/photo/1\">twitter.com/BarackObama/st…</a><br />
— Barack Obama (@BarackObama) <a data-datetime=\"2012-11-07T04:16:18+00:00\" href=\"https://twitter.com/BarackObama/status/266031293945503744\">November 7, 2012</a></blockquote><script async=\"async\" charset=\"utf-8\" src=\"//platform.twitter.com/widgets.js\"></script><br />
When each of these events happened, people <i>instantly</i> came to Twitter, and in particular searched on Twitter to discover what was happening.<br />
<p>From a search and advertising perspective, however, these sudden events pose several challenges:<br />
<ol><li>The queries people perform have probably never before been seen, so it's impossible to know without very specific context what they mean. How would you know that #bindersfullofwomen refers to politics, and not office accessories, or that people searching for \"horses and bayonets\" are interested in the Presidential debates?<br />
<br />
<li>Since these spikes in search queries are so <a href=\"http://arxiv.org/abs/1205.6855\">short-lived</a>, there’s only a small window of opportunity to learn what they mean.<br />
</ol>So an event happens, people instantly come to Twitter to search for the event, and we need to teach our systems what these queries mean as quickly as we can — because in just a few hours, the search spike will be gone. <p>How do we do this? We’ve built a real-time human computation engine to help us identify search queries as soon as they're trending, send these queries to real humans to be judged, and then incorporate the human annotations into our back-end models.  <p><b>Overview</b> <p>Before we delve into the details, here's an overview of how the system works.  <ol><li>First, we monitor for which search queries are currently popular.<br />
Behind the scenes: we run a <a href=\"http://engineering.twitter.com/2011/08/storm-is-coming-more-details-and-plans.html\">Storm</a> topology that tracks statistics on search queries.<br />
For example, the query [Big Bird] may suddenly see a spike in searches from the US.<br />
<br />
<li>As soon as we discover a new popular search query, we send it to our human evaluators, who are asked a variety of questions about the query.<br />
Behind the scenes: when the Storm topology detects that a query has reached sufficient popularity, it connects to a Thrift API that dispatches the query to Amazon's Mechanical Turk service, and then polls Mechanical Turk for a response.<br />
For example: as soon as we notice \"Big Bird\" spiking, we may ask judges on Mechanical Turk to categorize the query, or provide other information (e.g., whether there are likely to be interesting pictures of the query, or whether the query is about a person or an event) that helps us serve relevant Tweets and ads.<br />
<br />
<li>Finally, after a response from an evaluator is received, we push the information to our backend systems, so that the next time a user searches for a query, our machine learning models will make use of the additional information. For example, suppose our evaluators tell us that [Big Bird] is related to politics; the next time someone performs this search, we know to surface ads by @barackobama or @mittromney, not ads about Dora the Explorer.<br />
</ol><b>Monitoring for popular queries</b>  <p><a href=\"https://github.com/nathanmarz/storm\">Storm</a> is a distributed system for real-time computation. In contrast to <i>batch</i> systems like Hadoop, which often introduce delays of hours or more, Storm allows us to run online data processing algorithms to discover search spikes as soon as they happen.  In brief, running a job on Storm involves creating a Storm topology that describes the processing steps that must occur, and deploying this topology to a Storm cluster. A topology itself consists of three things: <ol><li><i>Tuple streams</i> of data. In our case, these may be tuples of (search query, timestamp).<br />
<br />
<li><i>Spouts</i> that produce these tuple streams. In our case, we attach spouts to our search logs, which get written to every time a search occurs.<br />
<br />
<li><i>Bolts</i> that process tuple streams. In our case, we use bolts for operations like updating total query counts, filtering out non-English queries, and checking whether an ad is currently being served up for the query.<br />
</ol>Here’s a step-by-step walkthrough of how our query topology works:  <ol><li>Whenever you perform a search on Twitter, the search request gets logged to a <a href=\"http://kafka.apache.org/\">Kafka queue</a>.<br />
<br />
<li>The Storm topology attaches a spout to this Kafka queue, and the spout emits a tuple containing the query and other metadata (e.g., the time the query was issued and its location) to a bolt for processing.<br />
<br />
<li>This bolt updates the count of the number of times we've seen this query, checks whether the query is \"currently popular\" (using various statistics like time-decayed counts, the geographic distribution of the query, and the last time this query was sent for annotations), and dispatches it to our human computation pipeline if so.<br />
</ol>One interesting feature of our popularity algorithm is that we often re-judge queries that have been annotated before, since the intent of a search can change. For example, people may normally search for [Clint Eastwood] because they're interested in his movies, but during the 2012 Republican National Convention users may have wanted to see Tweets related to his speech there.  <p><b>Human evaluation of popular search queries</b> <p>We use human computation for a variety of tasks. (See also <a href=\"http://engineering.twitter.com/2012/08/crowdsourced-data-analysis-with.html\">Clockwork Raven</a>, an open-source project we built that makes launching tasks easier.) For example, we often run experiments to measure ad relevance and search quality, we use it to gather data to train and evaluate our machine learning models. In this section we'll describe how we use it to boost our understanding of popular search queries. <p>Suppose that our Storm topology has detected that the query [Big Bird] is suddenly spiking. Since the query may remain popular for only a few hours, we send it off to live humans, who can help us quickly understand what it means; this dispatch is performed via a Thrift service that allows us to design our tasks in a <a href=\"http://engineering.twitter.com/2012/08/crowdsourced-data-analysis-with.html\">web frontend</a>, and later programmatically submit them to Mechanical Turk using any of the different languages we use across Twitter. <p>On Mechanical Turk, judges are asked several questions about the query that help us serve better ads. Without going into the exact questions, here are flavors of a few possibilities: <p>- What category does the query belong to? For example, [Stanford] may typically be an education-related query, but perhaps there's a football game between Stanford and Berkeley at the moment, in which case the current search intent would be sports. <p>- Does the query refer to a person? If so, who? And, what is their Twitter handle if they have one? For example, the query [Happy Birthday Harry] may be trending, but it's hard to know beforehand which of the numerous celebrities named Harry it's referring to. Is it <a href=\"https://twitter.com/onedirection\">One Direction</a>'s <a href=\"https://twitter.com/Harry_Styles\">Harry Styles</a>, in which case the searcher is likely to be interested in teen pop? Harry Potter, in which case the searcher is likely to be interested in fantasy novels? Or someone else entirely? <p><b>Turkers in the machine</b> <p>Since humans are core to this system, our workforce was designed to give us fast and reliable results. <p>For completing all our tasks, we use a small <i>custom</i> pool of Mechanical Turk judges to ensure high quality. Other typical possibilities in the crowdsourcing world are to use a static set of in-house judges, to use the standard worker filters that Amazon provides, or to go through an outside company like <a href=\"http://crowdflower.com/\">Crowdflower</a>. We've experimented with these other solutions, and while they have their own benefits, we found that a custom pool fit our needs best for a few reasons: <p>- A typical industry standard for human evaluation is to use in-house judges. They usually provide high-quality work as they become experts at the evaluation task domain. In-house judges are unfortunately hard to scale as they require standardized hiring processes to be in place. They also tend to be relatively more expensive, it can be harder to communicate with them, and their schedules can be difficult to work with. <p>- Using the standard sets of workers that Mechanical Turk or other crowdsourcing platforms provide makes it easy to scale the workforce, but we’ve found that their quality doesn’t always meet our needs. Two methods of ensuring high quality are to seed gold-standard examples for which you know the true response throughout your task, or to use statistical analysis to determine which workers are the good ones. But these can be time-consuming and expensive to create, and we often run tasks that can have free-response or require some background research, for which these solutions don't work. Another problem is that using these filters gives you a <i>fluid</i> and constantly changing set of workers — which makes them hard to train. <p>In contrast: <p>- Our custom pool of judges work virtually all day. For many of them, this is a full-time job, and they're geographically distributed, so our tasks complete quickly at all hours. We can easily ask for thousands of judgments before lunch, and have them finished by the time we need, which makes iterating on our experiments much easier. <p>- We have several forums, mailing lists, and even live chat rooms set up, all of which makes it easy for judges to ask us questions and to respond to feedback. Our judges will even give <i>us</i> suggestions on how to improve our tasks; for example, when we run categorization tasks, they'll often report helpful categories that we should add. <p>- Since we only launch tasks on demand, and Amazon provides a ready source of workers if we ever need more, our judges are never twiddling their thumbs waiting for tasks or completing busywork, and our jobs are rarely backlogged. <p>- Because our judges are culled from the best of Mechanical Turk, they're experts at the kinds of tasks we send, and can often provide higher quality at a faster rate than what even in-house judges provide. For example, they'll often use the forums and chatrooms to collaborate amongst themselves to give us the best judgments, and they're already familiar with the Firefox and  Chrome scripts that help them be the most efficient at their work. <p>All the benefits described above are especially valuable in this real-time search annotation case: <p>- Having highly trusted workers means we don't need to wait for multiple annotations on a single search query to confirm  validity, so we can send responses to our backend as soon as a single judge responds. This entire pipeline is design for <i>real-time</i>, after all, so the lower the latency on the human evaluation part, the better. <p>- The static nature of our custom pool means that the judges are already familiar with our questions, and don't need to be trained again. <p>- Because our workers aren't limited to a fixed schedule or location, they can work anywhere, anytime — which is a requirement for this system, since global event spikes on Twitter are not limited to a standard 40-hour work week. <p>- And with the multiple easy avenues of communication we have set up, it's easy for us to answer questions that might arise when we add new questions or modify existing ones. <p><b>Singing telegram summary</b> <p>As an example of the kind of top quality our workers provide, we crowdsourced a singing telegram to celebrate the project's launch. Here's what they came up with:  <iframe allowfullscreen=\"allowfullscreen\" frameborder=\"0\" height=\"315\" src=\"http://www.youtube.com/embed/EIK8iVnU5EU\" width=\"420\"></iframe> <p>This video was created entirely by our workers, from the crowdsourced lyrics, to the crowdsourced graphics, and even the piano playing and singing. Special thanks in particular to our amazing Turker, workasaurusrex, the musician and silky smooth crooner who brought the masterpiece together. <p>Many thanks to the Revenue and Storm teams, as well as our Turkers, for their help in launching this project. <p>Posted by <a href=\"https://twitter.com/echen\">Edwin Chen</a> and <a href=\"https://twitter.com/alpa\">Alpa Jain</a>" "http://www.blogger.com/feeds/5340805191653517637/posts/default/264900056363370138" (20716 39137) old 6 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-264900056363370138") (published nil "2013-01-08T12:30:00.001-08:00") (updated nil "2013-01-08T14:08:33.443-08:00") (title ((type . "text")) "Improving Twitter search with real-time human computation") (content ((type . "html")) "One of the magical things about Twitter is that it opens a window to the world in <i>real-time</i>. An event happens, and seconds later, people share it across the planet.<br />
<p>Consider, for example, what happened when Flight 1549 crashed in the Hudson River: <br />
<p><blockquote class=\"twitter-tweet\"><a href=\"http://twitpic.com/135xa\">http://twitpic.com/135xa</a> - There's a plane in the Hudson. I'm on the ferry going to pick up the people. Crazy.<br />
— Janis Krums (@jkrums) <a data-datetime=\"2009-01-15T20:36:04+00:00\" href=\"https://twitter.com/jkrums/status/1121915133\">January 15, 2009</a></blockquote><script async=\"async\" charset=\"utf-8\" src=\"//platform.twitter.com/widgets.js\"></script><br />
Or when Osama bin Laden was killed:<br />
<br />
<blockquote class=\"twitter-tweet\">Helicopter hovering above Abbottabad at 1AM (is a rare event).<br />
— Sohaib Athar (@ReallyVirtual) <a data-datetime=\"2011-05-01T19:58:24+00:00\" href=\"https://twitter.com/ReallyVirtual/status/64780730286358528\">May 1, 2011</a></blockquote><script async=\"async\" charset=\"utf-8\" src=\"//platform.twitter.com/widgets.js\"></script><br />
Or when Obama was re-elected:<br />
<br />
<blockquote class=\"twitter-tweet\">Four more years. <a href=\"http://t.co/bAJE6Vom\" title=\"http://twitter.com/BarackObama/status/266031293945503744/photo/1\">twitter.com/BarackObama/st…</a><br />
— Barack Obama (@BarackObama) <a data-datetime=\"2012-11-07T04:16:18+00:00\" href=\"https://twitter.com/BarackObama/status/266031293945503744\">November 7, 2012</a></blockquote><script async=\"async\" charset=\"utf-8\" src=\"//platform.twitter.com/widgets.js\"></script><br />
When each of these events happened, people <i>instantly</i> came to Twitter, and in particular searched on Twitter to discover what was happening.<br />
<p>From a search and advertising perspective, however, these sudden events pose several challenges:<br />
<ol><li>The queries people perform have probably never before been seen, so it's impossible to know without very specific context what they mean. How would you know that #bindersfullofwomen refers to politics, and not office accessories, or that people searching for \"horses and bayonets\" are interested in the Presidential debates?<br />
<br />
<li>Since these spikes in search queries are so <a href=\"http://arxiv.org/abs/1205.6855\">short-lived</a>, there’s only a small window of opportunity to learn what they mean.<br />
</ol>So an event happens, people instantly come to Twitter to search for the event, and we need to teach our systems what these queries mean as quickly as we can — because in just a few hours, the search spike will be gone. <p>How do we do this? We’ve built a real-time human computation engine to help us identify search queries as soon as they're trending, send these queries to real humans to be judged, and then incorporate the human annotations into our back-end models.  <p><b>Overview</b> <p>Before we delve into the details, here's an overview of how the system works.  <ol><li>First, we monitor for which search queries are currently popular.<br />
Behind the scenes: we run a <a href=\"http://engineering.twitter.com/2011/08/storm-is-coming-more-details-and-plans.html\">Storm</a> topology that tracks statistics on search queries.<br />
For example, the query [Big Bird] may suddenly see a spike in searches from the US.<br />
<br />
<li>As soon as we discover a new popular search query, we send it to our human evaluators, who are asked a variety of questions about the query.<br />
Behind the scenes: when the Storm topology detects that a query has reached sufficient popularity, it connects to a Thrift API that dispatches the query to Amazon's Mechanical Turk service, and then polls Mechanical Turk for a response.<br />
For example: as soon as we notice \"Big Bird\" spiking, we may ask judges on Mechanical Turk to categorize the query, or provide other information (e.g., whether there are likely to be interesting pictures of the query, or whether the query is about a person or an event) that helps us serve relevant Tweets and ads.<br />
<br />
<li>Finally, after a response from an evaluator is received, we push the information to our backend systems, so that the next time a user searches for a query, our machine learning models will make use of the additional information. For example, suppose our evaluators tell us that [Big Bird] is related to politics; the next time someone performs this search, we know to surface ads by @barackobama or @mittromney, not ads about Dora the Explorer.<br />
</ol><b>Monitoring for popular queries</b>  <p><a href=\"https://github.com/nathanmarz/storm\">Storm</a> is a distributed system for real-time computation. In contrast to <i>batch</i> systems like Hadoop, which often introduce delays of hours or more, Storm allows us to run online data processing algorithms to discover search spikes as soon as they happen.  In brief, running a job on Storm involves creating a Storm topology that describes the processing steps that must occur, and deploying this topology to a Storm cluster. A topology itself consists of three things: <ol><li><i>Tuple streams</i> of data. In our case, these may be tuples of (search query, timestamp).<br />
<br />
<li><i>Spouts</i> that produce these tuple streams. In our case, we attach spouts to our search logs, which get written to every time a search occurs.<br />
<br />
<li><i>Bolts</i> that process tuple streams. In our case, we use bolts for operations like updating total query counts, filtering out non-English queries, and checking whether an ad is currently being served up for the query.<br />
</ol>Here’s a step-by-step walkthrough of how our query topology works:  <ol><li>Whenever you perform a search on Twitter, the search request gets logged to a <a href=\"http://kafka.apache.org/\">Kafka queue</a>.<br />
<br />
<li>The Storm topology attaches a spout to this Kafka queue, and the spout emits a tuple containing the query and other metadata (e.g., the time the query was issued and its location) to a bolt for processing.<br />
<br />
<li>This bolt updates the count of the number of times we've seen this query, checks whether the query is \"currently popular\" (using various statistics like time-decayed counts, the geographic distribution of the query, and the last time this query was sent for annotations), and dispatches it to our human computation pipeline if so.<br />
</ol>One interesting feature of our popularity algorithm is that we often re-judge queries that have been annotated before, since the intent of a search can change. For example, people may normally search for [Clint Eastwood] because they're interested in his movies, but during the 2012 Republican National Convention users may have wanted to see Tweets related to his speech there.  <p><b>Human evaluation of popular search queries</b> <p>We use human computation for a variety of tasks. (See also <a href=\"http://engineering.twitter.com/2012/08/crowdsourced-data-analysis-with.html\">Clockwork Raven</a>, an open-source project we built that makes launching tasks easier.) For example, we often run experiments to measure ad relevance and search quality, we use it to gather data to train and evaluate our machine learning models. In this section we'll describe how we use it to boost our understanding of popular search queries. <p>Suppose that our Storm topology has detected that the query [Big Bird] is suddenly spiking. Since the query may remain popular for only a few hours, we send it off to live humans, who can help us quickly understand what it means; this dispatch is performed via a Thrift service that allows us to design our tasks in a <a href=\"http://engineering.twitter.com/2012/08/crowdsourced-data-analysis-with.html\">web frontend</a>, and later programmatically submit them to Mechanical Turk using any of the different languages we use across Twitter. <p>On Mechanical Turk, judges are asked several questions about the query that help us serve better ads. Without going into the exact questions, here are flavors of a few possibilities: <p>- What category does the query belong to? For example, [Stanford] may typically be an education-related query, but perhaps there's a football game between Stanford and Berkeley at the moment, in which case the current search intent would be sports. <p>- Does the query refer to a person? If so, who? And, what is their Twitter handle if they have one? For example, the query [Happy Birthday Harry] may be trending, but it's hard to know beforehand which of the numerous celebrities named Harry it's referring to. Is it <a href=\"https://twitter.com/onedirection\">One Direction</a>'s <a href=\"https://twitter.com/Harry_Styles\">Harry Styles</a>, in which case the searcher is likely to be interested in teen pop? Harry Potter, in which case the searcher is likely to be interested in fantasy novels? Or someone else entirely? <p><b>Turkers in the machine</b> <p>Since humans are core to this system, our workforce was designed to give us fast and reliable results. <p>For completing all our tasks, we use a small <i>custom</i> pool of Mechanical Turk judges to ensure high quality. Other typical possibilities in the crowdsourcing world are to use a static set of in-house judges, to use the standard worker filters that Amazon provides, or to go through an outside company like <a href=\"http://crowdflower.com/\">Crowdflower</a>. We've experimented with these other solutions, and while they have their own benefits, we found that a custom pool fit our needs best for a few reasons: <p>- A typical industry standard for human evaluation is to use in-house judges. They usually provide high-quality work as they become experts at the evaluation task domain. In-house judges are unfortunately hard to scale as they require standardized hiring processes to be in place. They also tend to be relatively more expensive, it can be harder to communicate with them, and their schedules can be difficult to work with. <p>- Using the standard sets of workers that Mechanical Turk or other crowdsourcing platforms provide makes it easy to scale the workforce, but we’ve found that their quality doesn’t always meet our needs. Two methods of ensuring high quality are to seed gold-standard examples for which you know the true response throughout your task, or to use statistical analysis to determine which workers are the good ones. But these can be time-consuming and expensive to create, and we often run tasks that can have free-response or require some background research, for which these solutions don't work. Another problem is that using these filters gives you a <i>fluid</i> and constantly changing set of workers — which makes them hard to train. <p>In contrast: <p>- Our custom pool of judges work virtually all day. For many of them, this is a full-time job, and they're geographically distributed, so our tasks complete quickly at all hours. We can easily ask for thousands of judgments before lunch, and have them finished by the time we need, which makes iterating on our experiments much easier. <p>- We have several forums, mailing lists, and even live chat rooms set up, all of which makes it easy for judges to ask us questions and to respond to feedback. Our judges will even give <i>us</i> suggestions on how to improve our tasks; for example, when we run categorization tasks, they'll often report helpful categories that we should add. <p>- Since we only launch tasks on demand, and Amazon provides a ready source of workers if we ever need more, our judges are never twiddling their thumbs waiting for tasks or completing busywork, and our jobs are rarely backlogged. <p>- Because our judges are culled from the best of Mechanical Turk, they're experts at the kinds of tasks we send, and can often provide higher quality at a faster rate than what even in-house judges provide. For example, they'll often use the forums and chatrooms to collaborate amongst themselves to give us the best judgments, and they're already familiar with the Firefox and  Chrome scripts that help them be the most efficient at their work. <p>All the benefits described above are especially valuable in this real-time search annotation case: <p>- Having highly trusted workers means we don't need to wait for multiple annotations on a single search query to confirm  validity, so we can send responses to our backend as soon as a single judge responds. This entire pipeline is design for <i>real-time</i>, after all, so the lower the latency on the human evaluation part, the better. <p>- The static nature of our custom pool means that the judges are already familiar with our questions, and don't need to be trained again. <p>- Because our workers aren't limited to a fixed schedule or location, they can work anywhere, anytime — which is a requirement for this system, since global event spikes on Twitter are not limited to a standard 40-hour work week. <p>- And with the multiple easy avenues of communication we have set up, it's easy for us to answer questions that might arise when we add new questions or modify existing ones. <p><b>Singing telegram summary</b> <p>As an example of the kind of top quality our workers provide, we crowdsourced a singing telegram to celebrate the project's launch. Here's what they came up with:  <iframe allowfullscreen=\"allowfullscreen\" frameborder=\"0\" height=\"315\" src=\"http://www.youtube.com/embed/EIK8iVnU5EU\" width=\"420\"></iframe> <p>This video was created entirely by our workers, from the crowdsourced lyrics, to the crowdsourced graphics, and even the piano playing and singing. Special thanks in particular to our amazing Turker, workasaurusrex, the musician and silky smooth crooner who brought the masterpiece together. <p>Many thanks to the Revenue and Storm teams, as well as our Turkers, for their help in launching this project. <p>Posted by <a href=\"https://twitter.com/echen\">Edwin Chen</a> and <a href=\"https://twitter.com/alpa\">Alpa Jain</a>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/264900056363370138"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/264900056363370138"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2013/01/improving-twitter-search-with-real-time.html") (title . "Improving Twitter search with real-time human computation"))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://img.youtube.com/vi/EIK8iVnU5EU/default.jpg") (height . "72") (width . "72"))))) ("Right-to-left support for Twitter Mobile" "Thanks to the efforts of our <a href=\"https://translate.twitter.com/welcome\">translation volunteers</a>, last week we were able to <a href=\"http://blog.twitter.com/2012/03/twitter-now-available-in-arabic-farsi.html\">launch</a> right-to-left language support for our mobile website in Arabic and Farsi. Two interesting challenges came up during development for this feature:<br />
<br />
1)  We needed to support a timeline that has both right-to-left (RTL) and left-to-right (LTR) tweets. We also needed to make sure that specific parts of each tweet, such as usernames and URLs, are always displayed as LTR.<br />
<br />
2) For our touch website, we wanted to flip our UI so that it was truly an RTL experience. But this meant we would need to change a lot of our CSS rules to have reversed values for properties like padding, margins, etc. — both time-consuming and unsustainable for future development. We needed a solution that would let us make changes without having to worry about adding in new CSS rules for RTL every time.<br />
<br />
In this post, I detail how we handled these two challenges and offer some general RTL tips and other findings we gleaned during development.<br />
<br />
<b>General RTL tips</b><br />
<br />
The basis for supporting RTL lies in the dir element attribute, which can be set to either ltr or rtl. This allows you to set an element’s content direction, so that any text/children nodes would render in the orientation specified. You can see the difference below:<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://3.bp.blogspot.com/-VeYcasPQ_Dw/UNTaXWC_OHI/AAAAAAAAAcU/G8HJyzd6s4I/s1600/RTL1.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"64\" src=\"http://3.bp.blogspot.com/-VeYcasPQ_Dw/UNTaXWC_OHI/AAAAAAAAAcU/G8HJyzd6s4I/s400/RTL1.png\" width=\"400\" /></a></div>
<br />
In the first row, the text in the LTR column is correct, but in the second it’s the text in the RTL column. <br />
<br />
Since this attribute can be used on any element, it can a) be used to change the <span style=\"font-family: inherit;\">direction</span> of inline elements, such as links (see “Handling bidirectional tweet content” below) and b) if added to the root html node then the browser will flip the order of all the elements on the page automatically (see “Creating a right-to-left UI” below).<br />
<br />
The other way to change content direction lies in the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">direction</span> and <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">unicode-bidi</span> CSS properties. Just like the dir attribute, the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">direction</span> property allows you to specify the direction within an element. However, there is one key difference: while <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">direction</span> will affect any block-level elements, for it to affect inline elements the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">unicode-bidi</span> property must be set to <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">embed</span> or <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">override</span>. Using the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">dir</span> attribute acts as if both those properties were applied, and is the preferred method as bidi should be considered a document change, not a styling one.<br />
<br />
For more on this, see the “W3C directionality specs” section below.<br />
<br />
<b>Handling bidirectional tweet content</b><br />
<br />
One of the things we had to think about was how to properly align each tweet depending on the dominant directionality of the content characters. For example, a tweet with mostly RTL characters should be right-aligned and read from right to left. To figure out which chars were RTL, we used this regex:<br />
<br />
<span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">/[\\u0600-\\u06FF]|[\\u0750-\\u077F]|[\\u0590-\\u05FF]|[\\uFE70-\\uFEFF]/m</span><br />
<br />
Then depending on how many chars matched, we could figure out the direction we’d want to apply to the tweet. <br />
<br />
However, this would also affect the different entities that are in a tweet’s content. Tweet entities are special parts included in the text that has their own context applied to them, such as usernames and hashtags. Usernames and URLs should always be displayed as LTR, while hashtags may be RTL or LTR depending on what the first character is. To solve this, while parsing out entities we also make sure that the correct direction was applied to the element the entities were contained in.<br />
<br />
If you are looking to add RTL support for your site and you have dynamic text with mixed directionality, besides using the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">dir</span> attribute or <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">direction</span> property, you could also look into the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">\\u200e</span> (<b id=\"internal-source-marker_0.7591470791958272\" style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; color: black; font-family: Times; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"><span style=\"background-color: transparent; color: black; font-family: 'Courier New'; font-size: 15px; font-style: normal; font-variant: normal; font-weight: normal; text-decoration: initial; vertical-align: baseline; white-space: pre-wrap;\">&amp;lrm;</span></b>‎) and the<span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\"> \\u200f</span> (‏<b id=\"internal-source-marker_0.7591470791958272\" style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; color: black; font-family: Times; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"><span style=\"background-color: transparent; color: black; font-family: 'Courier New'; font-size: 15px; font-style: normal; font-variant: normal; font-weight: normal; text-decoration: initial; vertical-align: baseline; white-space: pre-wrap;\">&amp;lrm;</span></b>) characters. These are invisible control markers that tell the browser how the following text should be displayed. But be careful; conflicts can arise if both the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">dir / direction</span> and character marker methods are used together. Or if you are using Ruby, Twitter has a great localization gem called <a href=\"https://github.com/twitter/twitter-cldr-rb\">TwitterCldr</a> which can take a string and insert these markers appropriately.<br />
<br />
<b>Creating a right-to-left UI </b><br />
<br />
For our mobile touch website, we would first detect what language the user’s browser is set in. When it’s one of our supported RTL languages, we add the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">dir</span> attribute to our page. The browser will then flip the layout of the site so that everything was rendered on the right-hand side first. <br />
<br />
This worked fairly well on basic alignment of the page; however, this did not change how all the elements are styled. Properties like padding, margin, text-align, and float will all have the same values, which means that the layout will look just plain wrong in areas where these are applied. This can be the most cumbersome part of adding RTL support to a website, as it usually means adding special rules to your stylesheets to handle this flipped layout. <br />
<br />
For our mobile touch website, we are using<a href=\"http://code.google.com/p/closure-stylesheets/\"> Google Closure</a> as our stylesheet compiler. This has an extremely convenient flag called <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">--output-orientation</span>, which will go through your stylesheets and adjust the rules according to the value (LTR or RTL) you pass in. By running the stylesheet compilation twice, once with this flag set to RTL, we get two stylesheets that are the mirror images of each other. This fixed nearly all styling issues that came from needing to flip CSS values. In the end, there were only two extra rules that we needed to add to the RTL stylesheet - those were put into<span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\"> rtl.css</span> which gets added on as the last input file for the RTL compilation, thusly overriding any previous rules that were generated.<br />
<br />
After that, it’s just a matter of including the right stylesheet for the user’s language and voila! a very nicely RTL’d site with minimal extra effort on the development side.<br />
<br />
One last thing that we needed to think about was element manipulation with JS. Since elements will now be pushed as far to the right as possible instead of to the far left, the origin point in which an element starts at may be very different than what you'd expect - possibly even out of the visible area in a container. <br />
<br />
For example, we had to change the way that the media strip in our photo gallery moved based on the page’s directionality. Besides coordinates changing, an LTR user would drag starting from the right, then ending to the left in order to see more photos. For an RTL user, the natural inclination would be to start at a left point and drag to the right. This is something that can’t be handled automatically as with our stylesheet compiler, so it comes down to good old-fashioned programming to figure out how we wanted elements to move.<br />
<br />
<b>Improving translations</b><br />
<br />
We would like to thank our amazing translations community for helping us get to this point. Without your efforts,we would not have been able to launch this feature onto mobile Twitter. And although we've made great strides in supporting RTL, we still have more work to do. <br />
<br />
We would love to have more translations for other languages that are not complete yet, such as our other two RTL languages Hebrew and Urdu. Visit <a href=\"http://translate.twitter.com/\">translate.twitter.com</a> to see how you can help us add more languages to Twitter.<br />
<br />
<b>Helpful Resources</b><br />
<br />
W3C directionality specs:<br />
<ul>
<li><a href=\"http://www.w3.org/TR/2004/WD-xhtml2-20040722/mod-bidi.html\">dir</a> </li>
<li><a href=\"http://www.w3.org/TR/CSS2/visuren.html#direction\">direction / unicode-bidi </a></li>
<li><a href=\"http://www.w3.org/International/questions/qa-bidi-css-markup\">dir versus direction</a></li>
</ul>
More resources:<br />
<ul>
<li><a href=\"https://developer.mozilla.org/en-US/docs/CSS/direction\">Mozilla</a></li>
<li><a href=\"https://github.com/twitter/twitter-cldr-rb\">TwitterCLDR Ruby Gem</a> </li>
<li><a href=\"http://code.google.com/p/closure-stylesheets/\">Google Closure Stylesheets</a></li>
<li><a href=\"http://xkcd.com/1137/\">XKCD’s example of another control character </a></li>
</ul>
<br />
Posted by Christine Tieu (@ctieu)<br />
Engineer, Mobile Web Team" "http://www.blogger.com/feeds/5340805191653517637/posts/default/6064921610291059483" (20692 57585) old 7 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-6064921610291059483") (published nil "2012-12-21T14:11:00.000-08:00") (updated nil "2012-12-21T14:21:37.607-08:00") (title ((type . "text")) "Right-to-left support for Twitter Mobile") (content ((type . "html")) "Thanks to the efforts of our <a href=\"https://translate.twitter.com/welcome\">translation volunteers</a>, last week we were able to <a href=\"http://blog.twitter.com/2012/03/twitter-now-available-in-arabic-farsi.html\">launch</a> right-to-left language support for our mobile website in Arabic and Farsi. Two interesting challenges came up during development for this feature:<br />
<br />
1)  We needed to support a timeline that has both right-to-left (RTL) and left-to-right (LTR) tweets. We also needed to make sure that specific parts of each tweet, such as usernames and URLs, are always displayed as LTR.<br />
<br />
2) For our touch website, we wanted to flip our UI so that it was truly an RTL experience. But this meant we would need to change a lot of our CSS rules to have reversed values for properties like padding, margins, etc. — both time-consuming and unsustainable for future development. We needed a solution that would let us make changes without having to worry about adding in new CSS rules for RTL every time.<br />
<br />
In this post, I detail how we handled these two challenges and offer some general RTL tips and other findings we gleaned during development.<br />
<br />
<b>General RTL tips</b><br />
<br />
The basis for supporting RTL lies in the dir element attribute, which can be set to either ltr or rtl. This allows you to set an element’s content direction, so that any text/children nodes would render in the orientation specified. You can see the difference below:<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://3.bp.blogspot.com/-VeYcasPQ_Dw/UNTaXWC_OHI/AAAAAAAAAcU/G8HJyzd6s4I/s1600/RTL1.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"64\" src=\"http://3.bp.blogspot.com/-VeYcasPQ_Dw/UNTaXWC_OHI/AAAAAAAAAcU/G8HJyzd6s4I/s400/RTL1.png\" width=\"400\" /></a></div>
<br />
In the first row, the text in the LTR column is correct, but in the second it’s the text in the RTL column. <br />
<br />
Since this attribute can be used on any element, it can a) be used to change the <span style=\"font-family: inherit;\">direction</span> of inline elements, such as links (see “Handling bidirectional tweet content” below) and b) if added to the root html node then the browser will flip the order of all the elements on the page automatically (see “Creating a right-to-left UI” below).<br />
<br />
The other way to change content direction lies in the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">direction</span> and <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">unicode-bidi</span> CSS properties. Just like the dir attribute, the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">direction</span> property allows you to specify the direction within an element. However, there is one key difference: while <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">direction</span> will affect any block-level elements, for it to affect inline elements the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">unicode-bidi</span> property must be set to <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">embed</span> or <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">override</span>. Using the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">dir</span> attribute acts as if both those properties were applied, and is the preferred method as bidi should be considered a document change, not a styling one.<br />
<br />
For more on this, see the “W3C directionality specs” section below.<br />
<br />
<b>Handling bidirectional tweet content</b><br />
<br />
One of the things we had to think about was how to properly align each tweet depending on the dominant directionality of the content characters. For example, a tweet with mostly RTL characters should be right-aligned and read from right to left. To figure out which chars were RTL, we used this regex:<br />
<br />
<span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">/[\\u0600-\\u06FF]|[\\u0750-\\u077F]|[\\u0590-\\u05FF]|[\\uFE70-\\uFEFF]/m</span><br />
<br />
Then depending on how many chars matched, we could figure out the direction we’d want to apply to the tweet. <br />
<br />
However, this would also affect the different entities that are in a tweet’s content. Tweet entities are special parts included in the text that has their own context applied to them, such as usernames and hashtags. Usernames and URLs should always be displayed as LTR, while hashtags may be RTL or LTR depending on what the first character is. To solve this, while parsing out entities we also make sure that the correct direction was applied to the element the entities were contained in.<br />
<br />
If you are looking to add RTL support for your site and you have dynamic text with mixed directionality, besides using the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">dir</span> attribute or <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">direction</span> property, you could also look into the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">\\u200e</span> (<b id=\"internal-source-marker_0.7591470791958272\" style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; color: black; font-family: Times; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"><span style=\"background-color: transparent; color: black; font-family: 'Courier New'; font-size: 15px; font-style: normal; font-variant: normal; font-weight: normal; text-decoration: initial; vertical-align: baseline; white-space: pre-wrap;\">&amp;lrm;</span></b>‎) and the<span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\"> \\u200f</span> (‏<b id=\"internal-source-marker_0.7591470791958272\" style=\"-webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; color: black; font-family: Times; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px;\"><span style=\"background-color: transparent; color: black; font-family: 'Courier New'; font-size: 15px; font-style: normal; font-variant: normal; font-weight: normal; text-decoration: initial; vertical-align: baseline; white-space: pre-wrap;\">&amp;lrm;</span></b>) characters. These are invisible control markers that tell the browser how the following text should be displayed. But be careful; conflicts can arise if both the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">dir / direction</span> and character marker methods are used together. Or if you are using Ruby, Twitter has a great localization gem called <a href=\"https://github.com/twitter/twitter-cldr-rb\">TwitterCldr</a> which can take a string and insert these markers appropriately.<br />
<br />
<b>Creating a right-to-left UI </b><br />
<br />
For our mobile touch website, we would first detect what language the user’s browser is set in. When it’s one of our supported RTL languages, we add the <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">dir</span> attribute to our page. The browser will then flip the layout of the site so that everything was rendered on the right-hand side first. <br />
<br />
This worked fairly well on basic alignment of the page; however, this did not change how all the elements are styled. Properties like padding, margin, text-align, and float will all have the same values, which means that the layout will look just plain wrong in areas where these are applied. This can be the most cumbersome part of adding RTL support to a website, as it usually means adding special rules to your stylesheets to handle this flipped layout. <br />
<br />
For our mobile touch website, we are using<a href=\"http://code.google.com/p/closure-stylesheets/\"> Google Closure</a> as our stylesheet compiler. This has an extremely convenient flag called <span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\">--output-orientation</span>, which will go through your stylesheets and adjust the rules according to the value (LTR or RTL) you pass in. By running the stylesheet compilation twice, once with this flag set to RTL, we get two stylesheets that are the mirror images of each other. This fixed nearly all styling issues that came from needing to flip CSS values. In the end, there were only two extra rules that we needed to add to the RTL stylesheet - those were put into<span style=\"font-family: &quot;Courier New&quot;,Courier,monospace;\"> rtl.css</span> which gets added on as the last input file for the RTL compilation, thusly overriding any previous rules that were generated.<br />
<br />
After that, it’s just a matter of including the right stylesheet for the user’s language and voila! a very nicely RTL’d site with minimal extra effort on the development side.<br />
<br />
One last thing that we needed to think about was element manipulation with JS. Since elements will now be pushed as far to the right as possible instead of to the far left, the origin point in which an element starts at may be very different than what you'd expect - possibly even out of the visible area in a container. <br />
<br />
For example, we had to change the way that the media strip in our photo gallery moved based on the page’s directionality. Besides coordinates changing, an LTR user would drag starting from the right, then ending to the left in order to see more photos. For an RTL user, the natural inclination would be to start at a left point and drag to the right. This is something that can’t be handled automatically as with our stylesheet compiler, so it comes down to good old-fashioned programming to figure out how we wanted elements to move.<br />
<br />
<b>Improving translations</b><br />
<br />
We would like to thank our amazing translations community for helping us get to this point. Without your efforts,we would not have been able to launch this feature onto mobile Twitter. And although we've made great strides in supporting RTL, we still have more work to do. <br />
<br />
We would love to have more translations for other languages that are not complete yet, such as our other two RTL languages Hebrew and Urdu. Visit <a href=\"http://translate.twitter.com/\">translate.twitter.com</a> to see how you can help us add more languages to Twitter.<br />
<br />
<b>Helpful Resources</b><br />
<br />
W3C directionality specs:<br />
<ul>
<li><a href=\"http://www.w3.org/TR/2004/WD-xhtml2-20040722/mod-bidi.html\">dir</a> </li>
<li><a href=\"http://www.w3.org/TR/CSS2/visuren.html#direction\">direction / unicode-bidi </a></li>
<li><a href=\"http://www.w3.org/International/questions/qa-bidi-css-markup\">dir versus direction</a></li>
</ul>
More resources:<br />
<ul>
<li><a href=\"https://developer.mozilla.org/en-US/docs/CSS/direction\">Mozilla</a></li>
<li><a href=\"https://github.com/twitter/twitter-cldr-rb\">TwitterCLDR Ruby Gem</a> </li>
<li><a href=\"http://code.google.com/p/closure-stylesheets/\">Google Closure Stylesheets</a></li>
<li><a href=\"http://xkcd.com/1137/\">XKCD’s example of another control character </a></li>
</ul>
<br />
Posted by Christine Tieu (@ctieu)<br />
Engineer, Mobile Web Team") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6064921610291059483"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6064921610291059483"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/12/right-to-left-support-for-twitter-mobile.html") (title . "Right-to-left support for Twitter Mobile"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://3.bp.blogspot.com/-VeYcasPQ_Dw/UNTaXWC_OHI/AAAAAAAAAcU/G8HJyzd6s4I/s72-c/RTL1.png") (height . "72") (width . "72"))))) ("How our photo filters came into focus" "<p>The old adage “a picture is worth a thousand words” is very apt for Twitter:  a single photo can express what otherwise might require many Tweets. Photos help capture whatever we’re up to: kids’ birthday parties, having fun with our friends, the world we see when we travel.</p><p>Like so many of you, lots of us here at Twitter really love sharing filtered photos in our tweets. As we got into doing it more often, we began to wonder if we could make that experience better, easier and faster. After all, the now-familiar process for tweeting a filtered photo has required a few steps:</p>1. Take the photo (with an app)<br />
2. Filter the photo (probably another app)<br />
3. Finally, tweet it! <br />
<p>Constantly needing to switch apps takes time, and results in frustration and wasted photo opportunities. So we challenged ourselves to make the experience as fast and simple as possible. We wanted everyone to be able to easily tweet photos that are beautiful, timeless, and meaningful.</p><p>With last week’s photo filters release, we think we accomplished that on the latest versions of Twitter for Android and Twitter for iPhone. Now we'd like to tell you a little more about what went on behind the scenes in order to develop this new photo filtering experience.</p><p><b>It’s all about the filters</b></p><p>Our guiding principle: to create filters that amplify what you want to express, and to help that expression stand the test of time. We began with research, user stories, and sketches. We designed and tested multiple iterations of the photo-taking experience, and relied heavily on user research to make decisions about everything from filters nomenclature and iconography to the overall flow. We refined and distilled until we felt we had the experience right. </p><br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://2.bp.blogspot.com/-TdUzWMo2yzw/UNNJfRIT6KI/AAAAAAAAAbc/qlh-4jNypAg/s1600/blog_eng1.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"300\" width=\"400\" src=\"http://2.bp.blogspot.com/-TdUzWMo2yzw/UNNJfRIT6KI/AAAAAAAAAbc/qlh-4jNypAg/s400/blog_eng1.png\" /></a></div><br />
<p>We spent many hours poring over the design of the filters. Since every photo is different, we did our analyses across a wide range of photos including portraits, scenery, indoor, outdoor and low-light shots. We also calibrated details ranging from color shifts, saturation, and contrast, to the shape and blend of the vignettes before handing the specifications over to Aviary, a company specializing in photo editing. They applied their expertise to build the algorithms that matched our filter specs.</p><br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-X9SKAtHFsuo/UNNObx5nrRI/AAAAAAAAAbw/9t31YkNwQ4w/s1600/blog_eng2.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"300\" width=\"400\" src=\"http://4.bp.blogspot.com/-X9SKAtHFsuo/UNNObx5nrRI/AAAAAAAAAbw/9t31YkNwQ4w/s400/blog_eng2.png\" /></a></div><br />
<b>Make it fast!</b><br />
<p>Our new photo filtering system is a tight integration of Aviary's cross-platform GPU-accelerated photo filtering technology with our own user interface and visual specifications for filters. Implementing this new UI presented some unique engineering challenges. The main one was the need to create an experience that feels instant and seamless to use — while working within constraints of memory usage and processing speed available on the wide range of devices our apps support.</p><p>To make our new filtering experience work, our implementation keeps up to four full-screen photo contexts in memory at once: we keep three full-screen versions of the image for when you’re swiping through photos (the one you’re currently looking at plus the next to the right and the left), and the fourth contains nine small versions of the photo for the grid view. And every time you apply or remove a crop or magic enhance, we update the small images in the grid view to reflect those changes, so it’s always up to date.</p><p>Without those, you could experience a lag when scrolling between photos — but mobile phones just don't have a lot of memory. If we weren't careful about when and how we set up these chunks of memory, one result could be running out of memory and crashing the app. So we worked closely with Aviary's engineering team to achieve a balance that would work well for many use cases. </p><b>Test and test some more</b><br />
<p>As soon as engineering kicked off, we rolled out this new feature internally so that we could work out the kinks, sanding down the rough spots in the experience. At first, the team tested it, and then we opened it up to all employees to get lots of feedback. We also engaged people outside the company for user research. All of this was vital to get a good sense about which aspects of the UI would resonate, or wouldn’t.</p><p>After much testing and feedback, we designed an experience in which you can quickly and easily choose between different filtering options – displayed side by side, and in a grid. Auto-enhancement and cropping are both a single tap away in an easy-to-use interface.</p><br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://3.bp.blogspot.com/-h3ui89b-SAo/UNNPRNClFBI/AAAAAAAAAb8/ZRZegKIBLr8/s1600/blog_eng3.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"300\" width=\"400\" src=\"http://3.bp.blogspot.com/-h3ui89b-SAo/UNNPRNClFBI/AAAAAAAAAb8/ZRZegKIBLr8/s400/blog_eng3.png\" /></a></div><br />
<p>Finally, a collaborative team of engineers, designers and product managers were able to ship a set of filters wrapped in a seamless UI that anyone with our Android or iPhone app can enjoy. And over time, we want our filters to evolve so that sharing and connecting become even more delightful. It feels great to be able to share it with all of you at last.</p><br />
Posted by @ryfar<br />
Tweet Composer Team<br />
<br />
<br />
<br />" "http://www.blogger.com/feeds/5340805191653517637/posts/default/445106285386942826" (20691 20829) old 8 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-445106285386942826") (published nil "2012-12-20T09:56:00.001-08:00") (updated nil "2012-12-20T09:56:45.081-08:00") (title ((type . "text")) "How our photo filters came into focus") (content ((type . "html")) "<p>The old adage “a picture is worth a thousand words” is very apt for Twitter:  a single photo can express what otherwise might require many Tweets. Photos help capture whatever we’re up to: kids’ birthday parties, having fun with our friends, the world we see when we travel.</p><p>Like so many of you, lots of us here at Twitter really love sharing filtered photos in our tweets. As we got into doing it more often, we began to wonder if we could make that experience better, easier and faster. After all, the now-familiar process for tweeting a filtered photo has required a few steps:</p>1. Take the photo (with an app)<br />
2. Filter the photo (probably another app)<br />
3. Finally, tweet it! <br />
<p>Constantly needing to switch apps takes time, and results in frustration and wasted photo opportunities. So we challenged ourselves to make the experience as fast and simple as possible. We wanted everyone to be able to easily tweet photos that are beautiful, timeless, and meaningful.</p><p>With last week’s photo filters release, we think we accomplished that on the latest versions of Twitter for Android and Twitter for iPhone. Now we'd like to tell you a little more about what went on behind the scenes in order to develop this new photo filtering experience.</p><p><b>It’s all about the filters</b></p><p>Our guiding principle: to create filters that amplify what you want to express, and to help that expression stand the test of time. We began with research, user stories, and sketches. We designed and tested multiple iterations of the photo-taking experience, and relied heavily on user research to make decisions about everything from filters nomenclature and iconography to the overall flow. We refined and distilled until we felt we had the experience right. </p><br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://2.bp.blogspot.com/-TdUzWMo2yzw/UNNJfRIT6KI/AAAAAAAAAbc/qlh-4jNypAg/s1600/blog_eng1.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"300\" width=\"400\" src=\"http://2.bp.blogspot.com/-TdUzWMo2yzw/UNNJfRIT6KI/AAAAAAAAAbc/qlh-4jNypAg/s400/blog_eng1.png\" /></a></div><br />
<p>We spent many hours poring over the design of the filters. Since every photo is different, we did our analyses across a wide range of photos including portraits, scenery, indoor, outdoor and low-light shots. We also calibrated details ranging from color shifts, saturation, and contrast, to the shape and blend of the vignettes before handing the specifications over to Aviary, a company specializing in photo editing. They applied their expertise to build the algorithms that matched our filter specs.</p><br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-X9SKAtHFsuo/UNNObx5nrRI/AAAAAAAAAbw/9t31YkNwQ4w/s1600/blog_eng2.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"300\" width=\"400\" src=\"http://4.bp.blogspot.com/-X9SKAtHFsuo/UNNObx5nrRI/AAAAAAAAAbw/9t31YkNwQ4w/s400/blog_eng2.png\" /></a></div><br />
<b>Make it fast!</b><br />
<p>Our new photo filtering system is a tight integration of Aviary's cross-platform GPU-accelerated photo filtering technology with our own user interface and visual specifications for filters. Implementing this new UI presented some unique engineering challenges. The main one was the need to create an experience that feels instant and seamless to use — while working within constraints of memory usage and processing speed available on the wide range of devices our apps support.</p><p>To make our new filtering experience work, our implementation keeps up to four full-screen photo contexts in memory at once: we keep three full-screen versions of the image for when you’re swiping through photos (the one you’re currently looking at plus the next to the right and the left), and the fourth contains nine small versions of the photo for the grid view. And every time you apply or remove a crop or magic enhance, we update the small images in the grid view to reflect those changes, so it’s always up to date.</p><p>Without those, you could experience a lag when scrolling between photos — but mobile phones just don't have a lot of memory. If we weren't careful about when and how we set up these chunks of memory, one result could be running out of memory and crashing the app. So we worked closely with Aviary's engineering team to achieve a balance that would work well for many use cases. </p><b>Test and test some more</b><br />
<p>As soon as engineering kicked off, we rolled out this new feature internally so that we could work out the kinks, sanding down the rough spots in the experience. At first, the team tested it, and then we opened it up to all employees to get lots of feedback. We also engaged people outside the company for user research. All of this was vital to get a good sense about which aspects of the UI would resonate, or wouldn’t.</p><p>After much testing and feedback, we designed an experience in which you can quickly and easily choose between different filtering options – displayed side by side, and in a grid. Auto-enhancement and cropping are both a single tap away in an easy-to-use interface.</p><br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://3.bp.blogspot.com/-h3ui89b-SAo/UNNPRNClFBI/AAAAAAAAAb8/ZRZegKIBLr8/s1600/blog_eng3.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"300\" width=\"400\" src=\"http://3.bp.blogspot.com/-h3ui89b-SAo/UNNPRNClFBI/AAAAAAAAAb8/ZRZegKIBLr8/s400/blog_eng3.png\" /></a></div><br />
<p>Finally, a collaborative team of engineers, designers and product managers were able to ship a set of filters wrapped in a seamless UI that anyone with our Android or iPhone app can enjoy. And over time, we want our filters to evolve so that sharing and connecting become even more delightful. It feels great to be able to share it with all of you at last.</p><br />
Posted by @ryfar<br />
Tweet Composer Team<br />
<br />
<br />
<br />
") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/445106285386942826"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/445106285386942826"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/12/how-our-photo-filters-came-into-focus.html") (title . "How our photo filters came into focus"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://2.bp.blogspot.com/-TdUzWMo2yzw/UNNJfRIT6KI/AAAAAAAAAbc/qlh-4jNypAg/s72-c/blog_eng1.png") (height . "72") (width . "72"))))) ("Class project: “Analyzing Big Data with Twitter”" "Twitter partnered with UC Berkeley this past semester to teach <a href=\"http://blogs.ischool.berkeley.edu/i290-abdt-s12/\">Analyzing Big Data with Twitter</a>, a class with <a href=\"http://people.ischool.berkeley.edu/~hearst/\">Prof. Marti Hearst</a>. In the first half of the semester, Twitter engineers went to UC Berkeley to talk about the <a href=\"http://engineering.twitter.com/\">technology behind Twitter</a>: from the basics of <a href=\"http://engineering.twitter.com/2012/06/building-and-profiling-high-performance.html\">scaling</a> up a <a href=\"http://engineering.twitter.com/2012/06/distributed-systems-tracing-with-zipkin.html\">service</a> to the algorithms behind <a href=\"http://engineering.twitter.com/2012/03/generating-recommendations-with.html\">user recommendations</a> and <a href=\"http://engineering.twitter.com/2011/05/engineering-behind-twitters-new-search.html\">search</a>. These talks are available online, on the course <a href=\"http://blogs.ischool.berkeley.edu/i290-abdt-s12/\">website</a>. <br />
<br />
In the second half of the course, students applied their knowledge and creativity to build data-driven applications on top of Twitter. They came up with a range of products that included tracking bands or football teams, monitoring Tweets to find calls for help, and identifying communities on Twitter. Each project was mentored by one of our engineers.<br />
<br />
Last week, 40 of the students came to Twitter HQ to demo their final projects in front of a group of our engineers, designers and engineering leadership team.<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://2.bp.blogspot.com/-HnOe0xampRc/UMoOdW2gAuI/AAAAAAAAAbI/Hl2WnAEbc_A/s1600/IMG_8847.jpg\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"267\" width=\"400\" src=\"http://2.bp.blogspot.com/-HnOe0xampRc/UMoOdW2gAuI/AAAAAAAAAbI/Hl2WnAEbc_A/s400/IMG_8847.jpg\" /></a></div><br />
The students' enthusiasm and creativity inspired and impressed all of us who were involved. The entire experience was really fun, and we hope to work with Berkeley more in the future.<br />
<br />
Many thanks to the volunteer Twitter engineers, to Prof. Hearst, and of course to our fantastic students!<br />
<br />
<blockquote class=\"twitter-tweet\"><p>Cannot believe that I'll be visiting the Twitter HQ tomorrow for our project presentations. Yay! Yes, had to tweet about it. <a href=\"https://twitter.com/search/%23ilovetwitter\">#ilovetwitter</a></p>&mdash; Priya Iyer (@myy_precious) <a href=\"https://twitter.com/myy_precious/status/276513438702923779\" data-datetime=\"2012-12-06T02:28:35+00:00\">December 6, 2012</a></blockquote><script src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><br />
<blockquote class=\"twitter-tweet\" data-in-reply-to=\"276887760420339712\"><p>@<a href=\"https://twitter.com/gilad\">gilad</a> @<a href=\"https://twitter.com/ucbtweeter\">ucbtweeter</a> Truly one of my dreams coming true! Thanks to everyone from Twitter and @<a href=\"https://twitter.com/martihearst\">martihearst</a> for making this happen.</p>&mdash; Seema Hari (@SeemaHari) <a href=\"https://twitter.com/SeemaHari/status/276990164843237376\" data-datetime=\"2012-12-07T10:02:56+00:00\">December 7, 2012</a></blockquote><script src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><br />
<br />
Posted by Gilad Mishne - <a href=\"http://twitter.com/gilad\">@gilad</a><br />
Engineering Manager, Search" "http://www.blogger.com/feeds/5340805191653517637/posts/default/3382965804299186883" (20682 3963) old 9 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-3382965804299186883") (published nil "2012-12-13T09:25:00.000-08:00") (updated nil "2012-12-13T09:25:15.933-08:00") (title ((type . "text")) "Class project: “Analyzing Big Data with Twitter” ") (content ((type . "html")) "Twitter partnered with UC Berkeley this past semester to teach <a href=\"http://blogs.ischool.berkeley.edu/i290-abdt-s12/\">Analyzing Big Data with Twitter</a>, a class with <a href=\"http://people.ischool.berkeley.edu/~hearst/\">Prof. Marti Hearst</a>. In the first half of the semester, Twitter engineers went to UC Berkeley to talk about the <a href=\"http://engineering.twitter.com/\">technology behind Twitter</a>: from the basics of <a href=\"http://engineering.twitter.com/2012/06/building-and-profiling-high-performance.html\">scaling</a> up a <a href=\"http://engineering.twitter.com/2012/06/distributed-systems-tracing-with-zipkin.html\">service</a> to the algorithms behind <a href=\"http://engineering.twitter.com/2012/03/generating-recommendations-with.html\">user recommendations</a> and <a href=\"http://engineering.twitter.com/2011/05/engineering-behind-twitters-new-search.html\">search</a>. These talks are available online, on the course <a href=\"http://blogs.ischool.berkeley.edu/i290-abdt-s12/\">website</a>. <br />
<br />
In the second half of the course, students applied their knowledge and creativity to build data-driven applications on top of Twitter. They came up with a range of products that included tracking bands or football teams, monitoring Tweets to find calls for help, and identifying communities on Twitter. Each project was mentored by one of our engineers.<br />
<br />
Last week, 40 of the students came to Twitter HQ to demo their final projects in front of a group of our engineers, designers and engineering leadership team.<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://2.bp.blogspot.com/-HnOe0xampRc/UMoOdW2gAuI/AAAAAAAAAbI/Hl2WnAEbc_A/s1600/IMG_8847.jpg\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"267\" width=\"400\" src=\"http://2.bp.blogspot.com/-HnOe0xampRc/UMoOdW2gAuI/AAAAAAAAAbI/Hl2WnAEbc_A/s400/IMG_8847.jpg\" /></a></div><br />
The students' enthusiasm and creativity inspired and impressed all of us who were involved. The entire experience was really fun, and we hope to work with Berkeley more in the future.<br />
<br />
Many thanks to the volunteer Twitter engineers, to Prof. Hearst, and of course to our fantastic students!<br />
<br />
<blockquote class=\"twitter-tweet\"><p>Cannot believe that I'll be visiting the Twitter HQ tomorrow for our project presentations. Yay! Yes, had to tweet about it. <a href=\"https://twitter.com/search/%23ilovetwitter\">#ilovetwitter</a></p>&mdash; Priya Iyer (@myy_precious) <a href=\"https://twitter.com/myy_precious/status/276513438702923779\" data-datetime=\"2012-12-06T02:28:35+00:00\">December 6, 2012</a></blockquote><script src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><br />
<blockquote class=\"twitter-tweet\" data-in-reply-to=\"276887760420339712\"><p>@<a href=\"https://twitter.com/gilad\">gilad</a> @<a href=\"https://twitter.com/ucbtweeter\">ucbtweeter</a> Truly one of my dreams coming true! Thanks to everyone from Twitter and @<a href=\"https://twitter.com/martihearst\">martihearst</a> for making this happen.</p>&mdash; Seema Hari (@SeemaHari) <a href=\"https://twitter.com/SeemaHari/status/276990164843237376\" data-datetime=\"2012-12-07T10:02:56+00:00\">December 7, 2012</a></blockquote><script src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><br />
<br />
Posted by Gilad Mishne - <a href=\"http://twitter.com/gilad\">@gilad</a><br />
Engineering Manager, Search") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3382965804299186883"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3382965804299186883"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/12/class-project-analyzing-big-data-with.html") (title . "Class project: “Analyzing Big Data with Twitter” "))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://2.bp.blogspot.com/-HnOe0xampRc/UMoOdW2gAuI/AAAAAAAAAbI/Hl2WnAEbc_A/s72-c/IMG_8847.jpg") (height . "72") (width . "72"))))) ("Blobstore: Twitter’s in-house photo storage system" "Millions of people turn to Twitter to share and discover photos. To make it possible to upload a photo and attach it to your Tweet directly from Twitter, we partnered with Photobucket in 2011. As soon as photos became a more native part of the Twitter experience, more and more people began using this feature to share photos. <br />
<br />
In order to introduce new features and functionality, such as <a href=\"http://blog.twitter.com/2012/12/twitter-photos-put-filter-on-it.html\">filters</a>, and continue to improve the photos experience, Twitter’s Core Storage team began building an in-house photo storage system. In September, we began to use this new system, called Blobstore.<br />
<br />
<b><span style=\"font-size: large;\">What is Blobstore?</span></b><br />
<br />
Blobstore is Twitter’s low-cost and scalable storage system built to store photos and other binary large objects, also known as blobs. When we set out to build Blobstore, we had three design goals in mind:<br />
<br />
<ul>
<li><b>Low Cost:</b> Reduce the amount of money and time Twitter spent on storing Tweets with photos.</li>
<li><b>High Performance:</b> Serve images in the low tens of milliseconds, while maintaining a throughput of hundreds of thousands of requests per second.</li>
<li><b>Easy to Operate:</b> Be able to scale operational overhead with Twitter’s continuously growing infrastructure.</li>
</ul>
<br />
<b><span style=\"font-size: large;\">How does it work?</span></b><br />
<br />
When a user tweets a photo, we send the photo off to one of a set of Blobstore <b>front-end servers</b>. The front-end understands where a given photo needs to be written, and forwards it on to the servers responsible for actually storing the data. These storage servers, which we call <b>storage nodes</b>, write the photo to a disk and then inform a <b>Metadata store t</b>hat the image has been written and instruct it to record the information required to retrieve the photo. This<b> </b>Metadata store, which is a non-relational key-value store cluster with automatic multi-DC synchronization capabilities, spans across all of Twitter’s data centers providing a consistent view of the data that is in Blobstore.<br />
<br />
The brain of Blobstore, the <b>blob manager</b>, runs alongside the front-ends, storage nodes, and index cluster. The blob manager acts as a central coordinator for the management of the cluster. It is the source of all of the front-ends’ knowledge of where files should be stored, and it is responsible for updating this mapping and coordinating data movement when storage nodes are added, or when they are removed due to failures.<br />
<br />
Finally, we rely on <b>Kestrel</b>, Twitter’s existing asynchronous queue server, to handle tasks such as replicating images and ensuring data integrity across our data centers. <br />
<br />
We guarantee that when an image is successfully uploaded to Twitter, it is immediately retrievable from the data center that initially received the image. Within a short period of time, the image is replicated to all of our other data centers, and is retrievable from those as well. Because we rely on a multi-data-center Metadata store for the central index of files within Blobstore, we are aware in a very short amount of time whether an image has been written to its original data center; we can route requests there until the Kestrel queues are able to replicate the data.<br />
<br />
<b><span style=\"font-size: large;\">Blobstore Components</span></b><br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://2.bp.blogspot.com/-ck7Xv1OZygs/UMecZAbUr0I/AAAAAAAAAaY/5Dw0ntVVL4w/s1600/Blobstore%2BComponents.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"330\" src=\"http://2.bp.blogspot.com/-ck7Xv1OZygs/UMecZAbUr0I/AAAAAAAAAaY/5Dw0ntVVL4w/s400/Blobstore%2BComponents.png\" width=\"400\" /></a></div>
<br />
<b><span style=\"font-size: large;\">How is the data found?</span></b><br />
<br />
When an image is requested from Blobstore, we need to determine its location in order to access the data. There are a few approaches to solving this problem, each with its own pros and cons. One such approach is to map or hash each image individually to a given server by some method. This method has a fairly major downside in that it makes managing the movement of images much more complicated. For example, if we were to add or remove a server from Blobstore, we would need to recompute a new location for each individual image affected by the change. This adds operational complexity, as it would necessitate a rather large amount of bookkeeping to perform the data movement.<br />
<br />
We instead created a fixed-sized container for individual blobs of data, called a “<b>virtual bucket</b>”. We map images to these containers, and then we map the containers to the individual storage nodes. We keep  the total number of virtual buckets unchanged for the entire lifespan of our cluster. In order to determine which virtual bucket a given image is stored in, we perform a simple hash on the image’s unique ID. As long as the number of virtual buckets remains the same, this hashing will remain stable. The advantage of this stability is that we can reason about the movement of data at a much more coarsely grained level than the individual image.<br />
<br />
<b><span style=\"font-size: large;\">How do we place the data?</span></b><br />
<br />
When mapping virtual buckets to physical storage nodes, we keep some rules in mind to make sure that we don’t lose data when we lose servers or hard drives. For example, if we were to put all copies of a given image on a single rack of servers, losing that rack would mean that particular image would be unavailable.<br />
<br />
If we were to completely mirror the data on a given storage node on another storage node, it would be unlikely that we would ever have unavailable data, as the likelihood of losing both nodes at once is fairly low. However, whenever we were to lose a node, we would only have a single node to source from to re-replicate the data. We would have to recover slowly, so as to not impact the performance of the single remaining node.<br />
<br />
If we were to take the opposite approach and allow any server in the cluster to share a range of data on all servers, then we would avoid a bottleneck when recovering lost replicas, as we would essentially be able to read from the entire cluster in order to re-replicate data. However, we would also have a very high likelihood of data loss if we were to lose more than the replication factor of the cluster (two) per data center, as the chance that any two nodes would share some piece of data would be high. So, the optimal approach would be somewhere in the middle: for a given piece of data, there would be a limited number of machines that could share the range of data of its replica - more than one but less than the entire cluster.<br />
<br />
We took all of these things into account when we determined the mapping of data to our storage nodes. As a result, we built a library called “<b>libcrunch</b>” which understands the various data placement rules such as rack-awareness, understands how to replicate the data in way that minimizes risk of data loss while also maximizing the throughput of data recovery, and attempts to minimize the amount of data that needs to be moved upon any change in the cluster topology (such as when nodes are added or removed). It also gives us the power to fully map the network topology of our data center, so storage nodes have better data placement and we can take into account rack awareness and placement of replicas across PDU zones and routers.<br />
<br />
Keep an eye out for a blog post with more information on libcrunch.<br />
<br />
<b><span style=\"font-size: large;\">How is the data stored?</span></b><br />
<br />
Once we know where a given piece of data is located, we need to be able to efficiently store and retrieve it. Because of their relatively high storage density, we are using standard hard drives inside our storage nodes (3.5” 7200 RPM disks). Since this means that disk seeks are very expensive, we attempted to minimize the number of disk seeks per read and write.<br />
<br />
We pre-allocate ‘fat’ files on each storage node disk using fallocate(), of around 256MB each. We store each blob of data sequentially within a fat file, along with a small header. The offset and length of the data is then stored in the Metadata store, which uses SSDs internally, as the access pattern for index reads and writes is very well-suited for solid state media. Furthermore, splitting the index from the data saves us from needing to scale out memory on our storage nodes because we don’t need to keep any local indexes in RAM for fast lookups. The only time we end up hitting disk on a storage node is once we already have the fat file location and byte offset for a given piece of data. This means that we can generally guarantee a single disk seek for that read.<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://3.bp.blogspot.com/-c-gnLltkKUM/UMecoVXkGBI/AAAAAAAAAak/P9H75Wc8Cyg/s1600/How%2Bis%2Bthe%2Bdata%2Bstored.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"274\" src=\"http://3.bp.blogspot.com/-c-gnLltkKUM/UMecoVXkGBI/AAAAAAAAAak/P9H75Wc8Cyg/s400/How%2Bis%2Bthe%2Bdata%2Bstored.png\" width=\"400\" /></a></div>
<br />
<b><span style=\"font-size: large;\">Topology Management</span></b><br />
<br />
As the number of disks and nodes increases, the rate of failure increases. Capacity needs to be added, disks and nodes need to be replaced after failures, servers need to be moved. To make Blobstore operationally easy we put a lot of time and effort into libcrunch and the tooling associated with making cluster changes. <br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://4.bp.blogspot.com/-3hbpHmPwUOA/UMecvGKyH7I/AAAAAAAAAaw/irUWMopcGwk/s1600/blobStore_frontend.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"273\" src=\"http://4.bp.blogspot.com/-3hbpHmPwUOA/UMecvGKyH7I/AAAAAAAAAaw/irUWMopcGwk/s400/blobStore_frontend.png\" width=\"400\" /></a></div>
<br />
When a storage node fails, data that was hosted on that node needs to be copied from a surviving replica to restore the correct replication factor. The failed node is marked as unavailable in the cluster topology, and so libcrunch computes a change in the mapping from the virtual buckets to the storage nodes. From this mapping change, the storage nodes are instructed to copy and migrate virtual buckets to new locations.<br />
<br />
<b><span style=\"font-size: large;\">Zookeeper</span></b><br />
Topology and placement rules are stored internally in one of our Zookeeper clusters. The Blob Manager deals with this interaction and it uses this information stored in Zookeeper when an operator makes a change to the system. A topology change can consist of adjusting the replication factor, adding, failing, or removing nodes, as well as adjusting other input parameters for libcrunch. <br />
<br />
<b><span style=\"font-size: large;\">Replication across Data centers</span></b><br />
<br />
Kestrel is used for cross data center replication. Because kestrel is a durable queue, we use it to asynchronously replicate our image data across data centers. <br />
<br />
<span style=\"font-size: large;\"><b>Data center-aware Routing</b></span><br />
<br />
TFE (Twitter Frontend) is one of Twitter’s core components for routing. We wrote a custom plugin for TFE, that extends the default routing rules. Our Metadata store spans multiple data centers, and because the metadata stored per blob is small (a few bytes), we typically replicate this information much faster than the blob data. If a user tries to access a blob that has not been replicated to the nearest data center they are routed to, we look up this metadata information and proxy requests to the nearest data center that has the blob data stored. This gives us the property that if replication gets delayed, we can still route requests to the data center that stored the original blob, serving the user the image at the cost of a little higher latency until it’s replicated to the closer data center.<br />
<br />
<b><span style=\"font-size: large;\">Future work</span></b><br />
<br />
We have shipped the first version of blobstore internally. Although blobstore started with photos, we are adding other features and use cases that require blob storage to blobstore. And we are also continuously iterating on it to make it more robust, scalable, and easier to maintain.<br />
<br />
<b><span style=\"font-size: large;\">Acknowledgments</span></b><br />
<br />
Blobstore was a group effort. The following folks have contributed to the project: Meher Anand (<a href=\"https://twitter.com/meher_anand\">@meher_anand</a>), Ed Ceaser (<a href=\"https://twitter.com/asdf\">@asdf</a>), Harish Doddi (<a href=\"https://twitter.com/thinkingkiddo\">@thinkingkiddo</a>), Chris Goffinet (<a href=\"https://twitter.com/lenn0x\">@lenn0x</a>), Jack Gudenkauf (<a href=\"https://twitter.com/_jg\">@_jg</a>), and Sangjin Lee (<a href=\"https://twitter.com/sjlee\">@sjlee</a>). <br />
<br />
Posted by Armond Bigian <a href=\"https://twitter.com/armondbigian\">@armondbigian</a><br />
Engineering Director, Core Storage &amp; Database Engineering" "http://www.blogger.com/feeds/5340805191653517637/posts/default/169729317243469697" (20679 40674) old 10 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-169729317243469697") (published nil "2012-12-11T12:52:00.000-08:00") (updated nil "2012-12-11T13:00:18.316-08:00") (title ((type . "text")) "Blobstore: Twitter’s in-house photo storage system ") (content ((type . "html")) "Millions of people turn to Twitter to share and discover photos. To make it possible to upload a photo and attach it to your Tweet directly from Twitter, we partnered with Photobucket in 2011. As soon as photos became a more native part of the Twitter experience, more and more people began using this feature to share photos. <br />
<br />
In order to introduce new features and functionality, such as <a href=\"http://blog.twitter.com/2012/12/twitter-photos-put-filter-on-it.html\">filters</a>, and continue to improve the photos experience, Twitter’s Core Storage team began building an in-house photo storage system. In September, we began to use this new system, called Blobstore.<br />
<br />
<b><span style=\"font-size: large;\">What is Blobstore?</span></b><br />
<br />
Blobstore is Twitter’s low-cost and scalable storage system built to store photos and other binary large objects, also known as blobs. When we set out to build Blobstore, we had three design goals in mind:<br />
<br />
<ul>
<li><b>Low Cost:</b> Reduce the amount of money and time Twitter spent on storing Tweets with photos.</li>
<li><b>High Performance:</b> Serve images in the low tens of milliseconds, while maintaining a throughput of hundreds of thousands of requests per second.</li>
<li><b>Easy to Operate:</b> Be able to scale operational overhead with Twitter’s continuously growing infrastructure.</li>
</ul>
<br />
<b><span style=\"font-size: large;\">How does it work?</span></b><br />
<br />
When a user tweets a photo, we send the photo off to one of a set of Blobstore <b>front-end servers</b>. The front-end understands where a given photo needs to be written, and forwards it on to the servers responsible for actually storing the data. These storage servers, which we call <b>storage nodes</b>, write the photo to a disk and then inform a <b>Metadata store t</b>hat the image has been written and instruct it to record the information required to retrieve the photo. This<b> </b>Metadata store, which is a non-relational key-value store cluster with automatic multi-DC synchronization capabilities, spans across all of Twitter’s data centers providing a consistent view of the data that is in Blobstore.<br />
<br />
The brain of Blobstore, the <b>blob manager</b>, runs alongside the front-ends, storage nodes, and index cluster. The blob manager acts as a central coordinator for the management of the cluster. It is the source of all of the front-ends’ knowledge of where files should be stored, and it is responsible for updating this mapping and coordinating data movement when storage nodes are added, or when they are removed due to failures.<br />
<br />
Finally, we rely on <b>Kestrel</b>, Twitter’s existing asynchronous queue server, to handle tasks such as replicating images and ensuring data integrity across our data centers. <br />
<br />
We guarantee that when an image is successfully uploaded to Twitter, it is immediately retrievable from the data center that initially received the image. Within a short period of time, the image is replicated to all of our other data centers, and is retrievable from those as well. Because we rely on a multi-data-center Metadata store for the central index of files within Blobstore, we are aware in a very short amount of time whether an image has been written to its original data center; we can route requests there until the Kestrel queues are able to replicate the data.<br />
<br />
<b><span style=\"font-size: large;\">Blobstore Components</span></b><br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://2.bp.blogspot.com/-ck7Xv1OZygs/UMecZAbUr0I/AAAAAAAAAaY/5Dw0ntVVL4w/s1600/Blobstore%2BComponents.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"330\" src=\"http://2.bp.blogspot.com/-ck7Xv1OZygs/UMecZAbUr0I/AAAAAAAAAaY/5Dw0ntVVL4w/s400/Blobstore%2BComponents.png\" width=\"400\" /></a></div>
<br />
<b><span style=\"font-size: large;\">How is the data found?</span></b><br />
<br />
When an image is requested from Blobstore, we need to determine its location in order to access the data. There are a few approaches to solving this problem, each with its own pros and cons. One such approach is to map or hash each image individually to a given server by some method. This method has a fairly major downside in that it makes managing the movement of images much more complicated. For example, if we were to add or remove a server from Blobstore, we would need to recompute a new location for each individual image affected by the change. This adds operational complexity, as it would necessitate a rather large amount of bookkeeping to perform the data movement.<br />
<br />
We instead created a fixed-sized container for individual blobs of data, called a “<b>virtual bucket</b>”. We map images to these containers, and then we map the containers to the individual storage nodes. We keep  the total number of virtual buckets unchanged for the entire lifespan of our cluster. In order to determine which virtual bucket a given image is stored in, we perform a simple hash on the image’s unique ID. As long as the number of virtual buckets remains the same, this hashing will remain stable. The advantage of this stability is that we can reason about the movement of data at a much more coarsely grained level than the individual image.<br />
<br />
<b><span style=\"font-size: large;\">How do we place the data?</span></b><br />
<br />
When mapping virtual buckets to physical storage nodes, we keep some rules in mind to make sure that we don’t lose data when we lose servers or hard drives. For example, if we were to put all copies of a given image on a single rack of servers, losing that rack would mean that particular image would be unavailable.<br />
<br />
If we were to completely mirror the data on a given storage node on another storage node, it would be unlikely that we would ever have unavailable data, as the likelihood of losing both nodes at once is fairly low. However, whenever we were to lose a node, we would only have a single node to source from to re-replicate the data. We would have to recover slowly, so as to not impact the performance of the single remaining node.<br />
<br />
If we were to take the opposite approach and allow any server in the cluster to share a range of data on all servers, then we would avoid a bottleneck when recovering lost replicas, as we would essentially be able to read from the entire cluster in order to re-replicate data. However, we would also have a very high likelihood of data loss if we were to lose more than the replication factor of the cluster (two) per data center, as the chance that any two nodes would share some piece of data would be high. So, the optimal approach would be somewhere in the middle: for a given piece of data, there would be a limited number of machines that could share the range of data of its replica - more than one but less than the entire cluster.<br />
<br />
We took all of these things into account when we determined the mapping of data to our storage nodes. As a result, we built a library called “<b>libcrunch</b>” which understands the various data placement rules such as rack-awareness, understands how to replicate the data in way that minimizes risk of data loss while also maximizing the throughput of data recovery, and attempts to minimize the amount of data that needs to be moved upon any change in the cluster topology (such as when nodes are added or removed). It also gives us the power to fully map the network topology of our data center, so storage nodes have better data placement and we can take into account rack awareness and placement of replicas across PDU zones and routers.<br />
<br />
Keep an eye out for a blog post with more information on libcrunch.<br />
<br />
<b><span style=\"font-size: large;\">How is the data stored?</span></b><br />
<br />
Once we know where a given piece of data is located, we need to be able to efficiently store and retrieve it. Because of their relatively high storage density, we are using standard hard drives inside our storage nodes (3.5” 7200 RPM disks). Since this means that disk seeks are very expensive, we attempted to minimize the number of disk seeks per read and write.<br />
<br />
We pre-allocate ‘fat’ files on each storage node disk using fallocate(), of around 256MB each. We store each blob of data sequentially within a fat file, along with a small header. The offset and length of the data is then stored in the Metadata store, which uses SSDs internally, as the access pattern for index reads and writes is very well-suited for solid state media. Furthermore, splitting the index from the data saves us from needing to scale out memory on our storage nodes because we don’t need to keep any local indexes in RAM for fast lookups. The only time we end up hitting disk on a storage node is once we already have the fat file location and byte offset for a given piece of data. This means that we can generally guarantee a single disk seek for that read.<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://3.bp.blogspot.com/-c-gnLltkKUM/UMecoVXkGBI/AAAAAAAAAak/P9H75Wc8Cyg/s1600/How%2Bis%2Bthe%2Bdata%2Bstored.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"274\" src=\"http://3.bp.blogspot.com/-c-gnLltkKUM/UMecoVXkGBI/AAAAAAAAAak/P9H75Wc8Cyg/s400/How%2Bis%2Bthe%2Bdata%2Bstored.png\" width=\"400\" /></a></div>
<br />
<b><span style=\"font-size: large;\">Topology Management</span></b><br />
<br />
As the number of disks and nodes increases, the rate of failure increases. Capacity needs to be added, disks and nodes need to be replaced after failures, servers need to be moved. To make Blobstore operationally easy we put a lot of time and effort into libcrunch and the tooling associated with making cluster changes. <br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://4.bp.blogspot.com/-3hbpHmPwUOA/UMecvGKyH7I/AAAAAAAAAaw/irUWMopcGwk/s1600/blobStore_frontend.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"273\" src=\"http://4.bp.blogspot.com/-3hbpHmPwUOA/UMecvGKyH7I/AAAAAAAAAaw/irUWMopcGwk/s400/blobStore_frontend.png\" width=\"400\" /></a></div>
<br />
When a storage node fails, data that was hosted on that node needs to be copied from a surviving replica to restore the correct replication factor. The failed node is marked as unavailable in the cluster topology, and so libcrunch computes a change in the mapping from the virtual buckets to the storage nodes. From this mapping change, the storage nodes are instructed to copy and migrate virtual buckets to new locations.<br />
<br />
<b><span style=\"font-size: large;\">Zookeeper</span></b><br />
Topology and placement rules are stored internally in one of our Zookeeper clusters. The Blob Manager deals with this interaction and it uses this information stored in Zookeeper when an operator makes a change to the system. A topology change can consist of adjusting the replication factor, adding, failing, or removing nodes, as well as adjusting other input parameters for libcrunch. <br />
<br />
<b><span style=\"font-size: large;\">Replication across Data centers</span></b><br />
<br />
Kestrel is used for cross data center replication. Because kestrel is a durable queue, we use it to asynchronously replicate our image data across data centers. <br />
<br />
<span style=\"font-size: large;\"><b>Data center-aware Routing</b></span><br />
<br />
TFE (Twitter Frontend) is one of Twitter’s core components for routing. We wrote a custom plugin for TFE, that extends the default routing rules. Our Metadata store spans multiple data centers, and because the metadata stored per blob is small (a few bytes), we typically replicate this information much faster than the blob data. If a user tries to access a blob that has not been replicated to the nearest data center they are routed to, we look up this metadata information and proxy requests to the nearest data center that has the blob data stored. This gives us the property that if replication gets delayed, we can still route requests to the data center that stored the original blob, serving the user the image at the cost of a little higher latency until it’s replicated to the closer data center.<br />
<br />
<b><span style=\"font-size: large;\">Future work</span></b><br />
<br />
We have shipped the first version of blobstore internally. Although blobstore started with photos, we are adding other features and use cases that require blob storage to blobstore. And we are also continuously iterating on it to make it more robust, scalable, and easier to maintain.<br />
<br />
<b><span style=\"font-size: large;\">Acknowledgments</span></b><br />
<br />
Blobstore was a group effort. The following folks have contributed to the project: Meher Anand (<a href=\"https://twitter.com/meher_anand\">@meher_anand</a>), Ed Ceaser (<a href=\"https://twitter.com/asdf\">@asdf</a>), Harish Doddi (<a href=\"https://twitter.com/thinkingkiddo\">@thinkingkiddo</a>), Chris Goffinet (<a href=\"https://twitter.com/lenn0x\">@lenn0x</a>), Jack Gudenkauf (<a href=\"https://twitter.com/_jg\">@_jg</a>), and Sangjin Lee (<a href=\"https://twitter.com/sjlee\">@sjlee</a>). <br />
<br />
Posted by Armond Bigian <a href=\"https://twitter.com/armondbigian\">@armondbigian</a><br />
Engineering Director, Core Storage &amp; Database Engineering ") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/169729317243469697"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/169729317243469697"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/12/blobstore-twitters-in-house-photo.html") (title . "Blobstore: Twitter’s in-house photo storage system "))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://2.bp.blogspot.com/-ck7Xv1OZygs/UMecZAbUr0I/AAAAAAAAAaY/5Dw0ntVVL4w/s72-c/Blobstore%2BComponents.png") (height . "72") (width . "72"))))) ("Implementing pushState for twitter.com" "<p>As part of our <a href=\"http://engineering.twitter.com/2012/05/improving-performance-on-twittercom.html\">continuing effort to improve the performance of twitter.com</a>, we've recently implemented <a href=\"https://developer.mozilla.org/en-US/docs/DOM/Manipulating_the_browser_history#Adding_and_modifying_history_entries\">pushState</a>. With this change, users experience a perceivable decrease in latency when navigating between sections of twitter.com; in some cases near zero latency, as we're now caching responses on the client.</p><p>This post provides an overview of the pushState API, a summary of our implementation, and details some of the pitfalls and gotchas we experienced along the way.</p><h3>API Overview</h3><p>pushState is part of the <a href=\"https://developer.mozilla.org/en-US/docs/DOM/Manipulating_the_browser_history\">HTML 5 History API</a>&mdash; a set of tools for managing state on the client. The pushState() method enables mapping of a state object to a URL. The address bar is updated to match the specified URL without actually loading the page.</p><code>history.pushState([page data], [page title], [page URL])</code><br />
<p>While the pushState() method is used when navigating forward from A to B, the History API also provides a \"popstate\" event&mdash;used to mange back/forward button navigation. The event's \"state\" property maps to the data passed as the first argument to pushState().</p><p>If the user presses the back button to return to the initial point from which he/she first navigated via pushState, the \"state\" property of the \"popstate\" event will be undefined. To set the state for the initial, full-page load use the replaceState() method. It accepts the same arguments as the pushState() method.</p><code>history.replaceState([page data], [page title], [page URL])</code><br />
<p>The following diagram illustrates how usage of the History API comes together.</p><br />
<img src=\"http://4.bp.blogspot.com/-CHAZTpf_8hc/UMJV4axe9dI/AAAAAAAAAC8/S2rT5DIt-ok/s500/history-api-diagram-2.png\"  alt=\"Diagram illustrating use of the HTML 5 History API\" /><br />
<br />
<h3>Progressive Enhancement</h3><p>Our pushState implementation is a <a href=\"http://en.wikipedia.org/wiki/Progressive_enhancement\">progressive enhancement</a> on top of <a href=\"http://engineering.twitter.com/2012/05/improving-performance-on-twittercom.html\">our previous work</a>, and could be described as <a href=\"http://en.wikipedia.org/wiki/Hijax\">Hijax</a> + server-side rendering. By maintaining view logic on the server, we keep the client light, and maintain support for browsers that don't support pushState with the same URLs. This approach provides the additional benefit of enabling us to disable pushState at any time without jeopardizing any functionality.</p><h3>On the Server</h3><p>On the server, we configured each endpoint to return either full-page responses, or a JSON payload containing a partial, server-side rendered view, along with its corresponding JavaScript components. The decision of what response to send is determined by checking the Accept header and looking for \"application/json.\"</p><p>The same views are used to render both types of requests; to support pushState the views format the pieces used for the full-page responses into JSON.</p><p>Here are two example responses for the Interactions page to illustrate the point:</p><h4>pushState response</h4><pre><code>{
// Server-rendered HTML for the view
<b>page</b>: \"<div>&hellip;</div>\",
// Path to the JavaScript module for the associated view
<b>module</b>: \"app/pages/connect/interactions\",
// Initialization data for the current view
<b>init_data</b>: {&hellip;},
<b>title</b>: \"Twitter / Interactions\"
}
</code>
</pre><h4>Full page response</h4><pre><code><html>
<head>
<title><b>{{title}}</b></title>
</head>
<body>
<div id=\"page-container\"><b>{{page}}</b></div>
</body>
</html>
<script>
using(<b>{{module}}</b>, function (pageModule) {
pageModule<b>({{init_data}}</b>);
});
</script>
</code>
</pre><h3>Client Architecture</h3><p>Several aspects of our existing client architecture made it particularly easy to enhance twitter.com with pushState.</p><p>By contract, our components attach themselves to a single DOM node, listen to events via delegation, fire events on the DOM, and those events are broadcast to other components via DOM event bubbling. This allows our components to be even more loosely coupled&mdash;a component doesn't need a reference to another component in order to listen for its events.</p><p>Secondly, all of our components are defined using AMD, enabling the client to make decisions about what components to load.</p><p>With this client architecture we implemented pushState by adding two components: one responsible for managing the UI, the other data. Both are attached to the document, listen for events across the entire page, and broadcast events available to all components.</p><h4>UI Component</h4><ul><li>Manages the decision to pushState URLs by listening for document-wide clicks, and keyboard shortcuts</li>
<li>Broadcasts an event to initiate pushState navigation</li>
<li>Updates the UI in response to events from the data component</li>
</ul><h4>DATA Component</h4><ul><li>Only included if we're using pushState</li>
<li>Manages XHRs and caching of responses</li>
<li>Provides eventing around the HTML 5 history API to provide a single interface for UI components</li>
</ul><h4>Example pushState() Navigation LifeCycle</h4><ol><li>The user clicks on link with a specialized class (we choose \"js-nav\"), the click is caught by the UI component which prevents the default behavior and triggers a custom event to initiate pushState navigation.</li>
<li>The data component listens for that event and&hellip;<br />
<ol><li>Writes the current view to cache and, only before initial pushState navigation, calls replaceState() to set the state data for the view</li>
<li>Fetches the JSON payload for the requested URL (either via XHR or from cache)</li>
<li>Update the cache for the URL</li>
<li>Call pushState() to update the URL</li>
<li>Trigger an event indicating the UI should be updated</li>
</ol></li>
<li>The UI component resumes control by handling the event from the data component and&hellip;<br />
<ol><li>JavaScript components for the current view are torn down (event listeners detached, associated state is cleaned up)</li>
<li>The HTML for the current view is replaced with the new HTML</li>
<li>The script loader only fetches modules not already loaded</li>
<li>The JavaScript components for the current view are initialized</li>
<li>An event is triggered to alert all components that the view is rendered and initialized</li>
</ol></li>
</ol><h3>Pitfalls, Gotchas, etc.</h3><p>It'll come as no surprise to any experienced frontend engineers that the majority of the problems and annoyances with implementing pushState stem from either 1) inconsistencies in browser implementations of the HTML 5 History API, or 2) having to replicate behaviors or functionality you would otherwise get for free with full-page reloads.</p><h4>Don't believe the API, title updates are manual</h4><p>All browsers currently disregard the title attribute passed to the pushState() and replaceState() methods. Any updates to the page title need to be done manually.</p><h4>popstate Event Inconsistencies</h4><p>At the time of this writing, WebKit (and only WebKit) fires an extraneous popstate event after initial page load. This appears to be <a href=\"https://bugs.webkit.org/show_bug.cgi?id=93506\">a known bug in WebKit</a>, and is easy to work around by ignoring popstate events if the \"state\" property is undefined.</p><h4>State Object Size Limits</h4><p>Firefox imposes <a href=\"https://developer.mozilla.org/en-US/docs/DOM/Manipulating_the_browser_history#The_pushState().C2.A0method\">640KB character limit</a> on the serialized state object passed to pushState(), and will throw an exception if that limit is exceeded. We hit this limit in the early days of our implementation, and moved to storing state in memory. We limit the size of the serialized JSON we cache on the client per URL, and can adjust that number via a server-owned config.</p><p>It's worth noting that due to the aforementioned popstate bug in WebKit, we pass an empty object as the first argument to pushState() to distinguish WebKit's extraneous popstate events from those triggered in response to back/forward navigation.</p><h4>Thoughtful State Management Around Caching</h4><p>The bulk of the work implementing pushState went into designing a simple client framework that would facilitate caching and provide the right events to enable components to both prepare themselves to be cached, and restore themselves from cache. This was solved through a few simple design decisions:</p><ol><li>All events that trigger navigation (clicks on links, keyboard shortcuts, and back/forward button presses) are abstracted by the pushState UI component, routed through the same path in the data component, and subsequently fire the same events. This allows the UI to be both cached and handle updates in a uniform way.</li>
<li>The pushState UI component fires events around the rendering of updates: one before the DOM is updated, and another after the update is complete. The former enables UI components such as dialogs and menus to be collapsed in advance of the page being cached; the later enables UI components like timelines to update their timestamps when rendered from cache.</li>
<li>POST & DELETE operations bust the client-side cache.</li>
</ol><h4>Re-implementing Browser Functionality</h4><p>As is often the case, changing the browser's default behavior in an effort to make the experience faster or simpler for the end-user typically requires more work on behalf of developers and designers. Here are some pieces of browser functionality that we had to re-implement:</p><ul><li>Managing the position of the scrollbar as the user navigates forward and backward.</li>
<li>Preserving context menu functionality when preventing a link's default click behavior.</li>
<li>Accounting for especially fast, indecisive user clicks by ensuring the response you're rendering is in sync with the last requested URL.</li>
<li>Canceling outbound XHRs when the user requests a new page to avoid unnecessary UI updates.</li>
<li>Implementing the <a href=\"http://preloaders.net/\">canonical AJAX spinner</a>, so the user knows the page is loading.</li>
</ul><h3>Final Thoughts</h3><p>Despite the usual browser inconsistencies and other gotchas, we're pretty happy with the HTML 5 History API. Our implementation has enabled us to deliver the fast initial page rendering times and robustness we associate with traditional, server-side rendered sites and the lightening quick in-app navigation and state changes associate with client-side rendered web applications.</p><h3>Helpful Resources</h3><ul><li>Mozilla's (<a href=\"https://twitter.com/mozilla\">@Mozilla</a>) <a href=\"https://developer.mozilla.org/en-US/docs/DOM/Manipulating_the_browser_history\">HTML 5 History API documentation</a></li>
<li>Chris Wanstrath's (<a href=\"https://twitter.com/defunkt\">@defunkt</a>) <a href=\"https://github.com/defunkt/jquery-pjax/\">pjax (pushState + ajax = pjax) plugin for jQuery project on GitHub</a></li>
<li>Benjamin Lupton's (<a href=\"https://twitter.com/balupton\">@balupton</a>) <a href=\"https://github.com/balupton/History.js/\">history.js project on GitHub</a></li>
<li>Modernizr's (<a href=\"https://twitter.com/Modernizr\">@Modernizr</a>) <a href=\"https://github.com/Modernizr/Modernizr\">pushState capability detection</a></li>
</ul><p>&mdash;Todd Kloots, Engineer, Web Core team (<a href=\"https://twitter.com/todd\">@todd</a>)</p>" "http://www.blogger.com/feeds/5340805191653517637/posts/default/3827306517110644259" (20674 22054) old 11 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-3827306517110644259") (published nil "2012-12-07T10:15:00.000-08:00") (updated nil "2012-12-07T12:48:38.589-08:00") (title ((type . "text")) "Implementing pushState for twitter.com") (content ((type . "html")) "<p>As part of our <a href=\"http://engineering.twitter.com/2012/05/improving-performance-on-twittercom.html\">continuing effort to improve the performance of twitter.com</a>, we've recently implemented <a href=\"https://developer.mozilla.org/en-US/docs/DOM/Manipulating_the_browser_history#Adding_and_modifying_history_entries\">pushState</a>. With this change, users experience a perceivable decrease in latency when navigating between sections of twitter.com; in some cases near zero latency, as we're now caching responses on the client.</p><p>This post provides an overview of the pushState API, a summary of our implementation, and details some of the pitfalls and gotchas we experienced along the way.</p><h3>API Overview</h3><p>pushState is part of the <a href=\"https://developer.mozilla.org/en-US/docs/DOM/Manipulating_the_browser_history\">HTML 5 History API</a>&mdash; a set of tools for managing state on the client. The pushState() method enables mapping of a state object to a URL. The address bar is updated to match the specified URL without actually loading the page.</p><code>history.pushState([page data], [page title], [page URL])</code><br />
<p>While the pushState() method is used when navigating forward from A to B, the History API also provides a \"popstate\" event&mdash;used to mange back/forward button navigation. The event's \"state\" property maps to the data passed as the first argument to pushState().</p><p>If the user presses the back button to return to the initial point from which he/she first navigated via pushState, the \"state\" property of the \"popstate\" event will be undefined. To set the state for the initial, full-page load use the replaceState() method. It accepts the same arguments as the pushState() method.</p><code>history.replaceState([page data], [page title], [page URL])</code><br />
<p>The following diagram illustrates how usage of the History API comes together.</p><br />
<img src=\"http://4.bp.blogspot.com/-CHAZTpf_8hc/UMJV4axe9dI/AAAAAAAAAC8/S2rT5DIt-ok/s500/history-api-diagram-2.png\"  alt=\"Diagram illustrating use of the HTML 5 History API\" /><br />
<br />
<h3>Progressive Enhancement</h3><p>Our pushState implementation is a <a href=\"http://en.wikipedia.org/wiki/Progressive_enhancement\">progressive enhancement</a> on top of <a href=\"http://engineering.twitter.com/2012/05/improving-performance-on-twittercom.html\">our previous work</a>, and could be described as <a href=\"http://en.wikipedia.org/wiki/Hijax\">Hijax</a> + server-side rendering. By maintaining view logic on the server, we keep the client light, and maintain support for browsers that don't support pushState with the same URLs. This approach provides the additional benefit of enabling us to disable pushState at any time without jeopardizing any functionality.</p><h3>On the Server</h3><p>On the server, we configured each endpoint to return either full-page responses, or a JSON payload containing a partial, server-side rendered view, along with its corresponding JavaScript components. The decision of what response to send is determined by checking the Accept header and looking for \"application/json.\"</p><p>The same views are used to render both types of requests; to support pushState the views format the pieces used for the full-page responses into JSON.</p><p>Here are two example responses for the Interactions page to illustrate the point:</p><h4>pushState response</h4><pre><code>{
  // Server-rendered HTML for the view
  <b>page</b>: \"&#60;div&#62;&hellip;&#60;/div&#62;\",
  // Path to the JavaScript module for the associated view
  <b>module</b>: \"app/pages/connect/interactions\",
  // Initialization data for the current view
  <b>init_data</b>: {&hellip;},
  <b>title</b>: \"Twitter / Interactions\"
}
</code>
</pre><h4>Full page response</h4><pre><code>&#60;html&#62;
  &#60;head&#62;
    &#60;title&#62;<b>{{title}}</b>&#60;/title&#62;
  &#60;/head&#62;
  &#60;body&#62;
    &#60;div id=\"page-container\"><b>{{page}}</b>&#60;/div&#62;
  &#60;/body&#62;
&#60;/html&#62;
&#60;script&#62;
  using(<b>{{module}}</b>, function (pageModule) {
    pageModule<b>({{init_data}}</b>);
  });
&#60;/script&#62;
</code>
</pre><h3>Client Architecture</h3><p>Several aspects of our existing client architecture made it particularly easy to enhance twitter.com with pushState.</p><p>By contract, our components attach themselves to a single DOM node, listen to events via delegation, fire events on the DOM, and those events are broadcast to other components via DOM event bubbling. This allows our components to be even more loosely coupled&mdash;a component doesn't need a reference to another component in order to listen for its events.</p><p>Secondly, all of our components are defined using AMD, enabling the client to make decisions about what components to load.</p><p>With this client architecture we implemented pushState by adding two components: one responsible for managing the UI, the other data. Both are attached to the document, listen for events across the entire page, and broadcast events available to all components.</p><h4>UI Component</h4><ul><li>Manages the decision to pushState URLs by listening for document-wide clicks, and keyboard shortcuts</li>
<li>Broadcasts an event to initiate pushState navigation</li>
<li>Updates the UI in response to events from the data component</li>
</ul><h4>DATA Component</h4><ul><li>Only included if we're using pushState</li>
<li>Manages XHRs and caching of responses</li>
<li>Provides eventing around the HTML 5 history API to provide a single interface for UI components</li>
</ul><h4>Example pushState() Navigation LifeCycle</h4><ol><li>The user clicks on link with a specialized class (we choose \"js-nav\"), the click is caught by the UI component which prevents the default behavior and triggers a custom event to initiate pushState navigation.</li>
<li>The data component listens for that event and&hellip;<br />
<ol><li>Writes the current view to cache and, only before initial pushState navigation, calls replaceState() to set the state data for the view</li>
<li>Fetches the JSON payload for the requested URL (either via XHR or from cache)</li>
<li>Update the cache for the URL</li>
<li>Call pushState() to update the URL</li>
<li>Trigger an event indicating the UI should be updated</li>
</ol></li>
<li>The UI component resumes control by handling the event from the data component and&hellip;<br />
<ol><li>JavaScript components for the current view are torn down (event listeners detached, associated state is cleaned up)</li>
<li>The HTML for the current view is replaced with the new HTML</li>
<li>The script loader only fetches modules not already loaded</li>
<li>The JavaScript components for the current view are initialized</li>
<li>An event is triggered to alert all components that the view is rendered and initialized</li>
</ol></li>
</ol><h3>Pitfalls, Gotchas, etc.</h3><p>It'll come as no surprise to any experienced frontend engineers that the majority of the problems and annoyances with implementing pushState stem from either 1) inconsistencies in browser implementations of the HTML 5 History API, or 2) having to replicate behaviors or functionality you would otherwise get for free with full-page reloads.</p><h4>Don't believe the API, title updates are manual</h4><p>All browsers currently disregard the title attribute passed to the pushState() and replaceState() methods. Any updates to the page title need to be done manually.</p><h4>popstate Event Inconsistencies</h4><p>At the time of this writing, WebKit (and only WebKit) fires an extraneous popstate event after initial page load. This appears to be <a href=\"https://bugs.webkit.org/show_bug.cgi?id=93506\">a known bug in WebKit</a>, and is easy to work around by ignoring popstate events if the \"state\" property is undefined.</p><h4>State Object Size Limits</h4><p>Firefox imposes <a href=\"https://developer.mozilla.org/en-US/docs/DOM/Manipulating_the_browser_history#The_pushState().C2.A0method\">640KB character limit</a> on the serialized state object passed to pushState(), and will throw an exception if that limit is exceeded. We hit this limit in the early days of our implementation, and moved to storing state in memory. We limit the size of the serialized JSON we cache on the client per URL, and can adjust that number via a server-owned config.</p><p>It's worth noting that due to the aforementioned popstate bug in WebKit, we pass an empty object as the first argument to pushState() to distinguish WebKit's extraneous popstate events from those triggered in response to back/forward navigation.</p><h4>Thoughtful State Management Around Caching</h4><p>The bulk of the work implementing pushState went into designing a simple client framework that would facilitate caching and provide the right events to enable components to both prepare themselves to be cached, and restore themselves from cache. This was solved through a few simple design decisions:</p><ol><li>All events that trigger navigation (clicks on links, keyboard shortcuts, and back/forward button presses) are abstracted by the pushState UI component, routed through the same path in the data component, and subsequently fire the same events. This allows the UI to be both cached and handle updates in a uniform way.</li>
<li>The pushState UI component fires events around the rendering of updates: one before the DOM is updated, and another after the update is complete. The former enables UI components such as dialogs and menus to be collapsed in advance of the page being cached; the later enables UI components like timelines to update their timestamps when rendered from cache.</li>
<li>POST &#38; DELETE operations bust the client-side cache.</li>
</ol><h4>Re-implementing Browser Functionality</h4><p>As is often the case, changing the browser's default behavior in an effort to make the experience faster or simpler for the end-user typically requires more work on behalf of developers and designers. Here are some pieces of browser functionality that we had to re-implement:</p><ul><li>Managing the position of the scrollbar as the user navigates forward and backward.</li>
<li>Preserving context menu functionality when preventing a link's default click behavior.</li>
<li>Accounting for especially fast, indecisive user clicks by ensuring the response you're rendering is in sync with the last requested URL.</li>
<li>Canceling outbound XHRs when the user requests a new page to avoid unnecessary UI updates.</li>
<li>Implementing the <a href=\"http://preloaders.net/\">canonical AJAX spinner</a>, so the user knows the page is loading.</li>
</ul><h3>Final Thoughts</h3><p>Despite the usual browser inconsistencies and other gotchas, we're pretty happy with the HTML 5 History API. Our implementation has enabled us to deliver the fast initial page rendering times and robustness we associate with traditional, server-side rendered sites and the lightening quick in-app navigation and state changes associate with client-side rendered web applications.</p><h3>Helpful Resources</h3><ul><li>Mozilla's (<a href=\"https://twitter.com/mozilla\">@Mozilla</a>) <a href=\"https://developer.mozilla.org/en-US/docs/DOM/Manipulating_the_browser_history\">HTML 5 History API documentation</a></li>
<li>Chris Wanstrath's (<a href=\"https://twitter.com/defunkt\">@defunkt</a>) <a href=\"https://github.com/defunkt/jquery-pjax/\">pjax (pushState + ajax = pjax) plugin for jQuery project on GitHub</a></li>
<li>Benjamin Lupton's (<a href=\"https://twitter.com/balupton\">@balupton</a>) <a href=\"https://github.com/balupton/History.js/\">history.js project on GitHub</a></li>
<li>Modernizr's (<a href=\"https://twitter.com/Modernizr\">@Modernizr</a>) <a href=\"https://github.com/Modernizr/Modernizr\">pushState capability detection</a></li>
</ul><p>&mdash;Todd Kloots, Engineer, Web Core team (<a href=\"https://twitter.com/todd\">@todd</a>)</p>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3827306517110644259"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3827306517110644259"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/12/implementing-pushstate-for-twittercom_7.html") (title . "Implementing pushState for twitter.com"))) (author nil (name nil "Todd Kloots") (uri nil "https://plus.google.com/116070809214398998458") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://4.bp.blogspot.com/-CHAZTpf_8hc/UMJV4axe9dI/AAAAAAAAAC8/S2rT5DIt-ok/s72-c/history-api-diagram-2.png") (height . "72") (width . "72"))))) ("Twitter and SMS Spoofing" "Over the past two days, <a href=\"http://arstechnica.com/security/2012/12/tweeting-with-sms-can-open-door-to-hacks-on-your-twitter-account/\">a few articles</a> have been published about a potential problem concerning the ability to post false updates to another user's SMS-enabled Twitter account, and it has been misreported that US-based Twitter users are currently vulnerable to this type of attack.<br />
<br />
The general concern is that if a user has a Twitter account configured for <a href=\"https://support.twitter.com/articles/14014-twitter-via-sms-faq#\">SMS updates</a>, and an attacker knows that user's phone number, it could be possible for the attacker to send a fake SMS message to Twitter that looks like it's coming from that user's phone number, which would result in a fake post to that user's timeline.<br />
<br />
Most Twitter users interact over the SMS channel using a \"shortcode.\" In the US, for instance, <a href=\"https://support.twitter.com/articles/20170024\">this shortcode</a> is 40404. &nbsp;Because of the way that shortcodes work, it is not possible to send an SMS message with a fake source addressed to them, which eliminates the possibility of an SMS spoofing attack to those numbers. <br />
<br />
However, in some countries a Twitter shortcode is <a href=\"https://support.twitter.com/articles/14226#\">not yet available</a>, and in those cases Twitter users interact over the SMS channel using a \"longcode.\" A longcode is basically just a normal looking phone number. &nbsp;Given that it <i>is</i> possible to send an SMS message with a fake source address to these numbers, we have offered <a href=\"https://support.twitter.com/groups/34-apps-sms-and-mobile/topics/153-twitter-via-sms/articles/20169928-how-to-use-pins-with-sms#\">PIN protection</a> to users who sign up with a longcode since 2007. &nbsp;As of August of this year, we have additionally disallowed posting through longcodes for users that have an available shortcode.<br />
<br />
It has been misreported that US-based Twitter users are currently vulnerable to a spoofing attack because PIN protection is unavailable for them. &nbsp;By having a shortcode, PIN protection isn't necessary for US-based Twitter users, because they are not vulnerable to SMS spoofing. &nbsp;We only provide the option for PIN protection in cases where a user could have registered with a longcode that is susceptible to SMS spoofing.<br />
<br />
We work hard to protect our users from these kinds of threats and many others, and will continue to keep Twitter a site deserving of your trust.&nbsp; <br />
<br />
Posted by Moxie Marlinspike - <a href=\"https://twitter.com/moxie\">@moxie</a><br />
Engineering Manager, Product Security <br />
<br />" "http://www.blogger.com/feeds/5340805191653517637/posts/default/3288544544817065443" (20670 45141) old 12 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-3288544544817065443") (published nil "2012-12-04T18:13:00.003-08:00") (updated nil "2012-12-04T18:24:21.742-08:00") (title ((type . "text")) "Twitter and SMS Spoofing") (content ((type . "html")) "Over the past two days, <a href=\"http://arstechnica.com/security/2012/12/tweeting-with-sms-can-open-door-to-hacks-on-your-twitter-account/\">a few articles</a> have been published about a potential problem concerning the ability to post false updates to another user's SMS-enabled Twitter account, and it has been misreported that US-based Twitter users are currently vulnerable to this type of attack.<br />
<br />
The general concern is that if a user has a Twitter account configured for <a href=\"https://support.twitter.com/articles/14014-twitter-via-sms-faq#\">SMS updates</a>, and an attacker knows that user's phone number, it could be possible for the attacker to send a fake SMS message to Twitter that looks like it's coming from that user's phone number, which would result in a fake post to that user's timeline.<br />
<br />
Most Twitter users interact over the SMS channel using a \"shortcode.\" In the US, for instance, <a href=\"https://support.twitter.com/articles/20170024\">this shortcode</a> is 40404. &nbsp;Because of the way that shortcodes work, it is not possible to send an SMS message with a fake source addressed to them, which eliminates the possibility of an SMS spoofing attack to those numbers. <br />
<br />
However, in some countries a Twitter shortcode is <a href=\"https://support.twitter.com/articles/14226#\">not yet available</a>, and in those cases Twitter users interact over the SMS channel using a \"longcode.\" A longcode is basically just a normal looking phone number. &nbsp;Given that it <i>is</i> possible to send an SMS message with a fake source address to these numbers, we have offered <a href=\"https://support.twitter.com/groups/34-apps-sms-and-mobile/topics/153-twitter-via-sms/articles/20169928-how-to-use-pins-with-sms#\">PIN protection</a> to users who sign up with a longcode since 2007. &nbsp;As of August of this year, we have additionally disallowed posting through longcodes for users that have an available shortcode.<br />
<br />
It has been misreported that US-based Twitter users are currently vulnerable to a spoofing attack because PIN protection is unavailable for them. &nbsp;By having a shortcode, PIN protection isn't necessary for US-based Twitter users, because they are not vulnerable to SMS spoofing. &nbsp;We only provide the option for PIN protection in cases where a user could have registered with a longcode that is susceptible to SMS spoofing.<br />
<br />
We work hard to protect our users from these kinds of threats and many others, and will continue to keep Twitter a site deserving of your trust.&nbsp; <br />
<br />
Posted by Moxie Marlinspike - <a href=\"https://twitter.com/moxie\">@moxie</a><br />
Engineering Manager, Product Security <br />
<br />") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3288544544817065443"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3288544544817065443"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/12/twitter-and-sms-spoofing.html") (title . "Twitter and SMS Spoofing"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))))) ("Discover with a new lens: Twitter cards" "<p>As you already know, there’s a myriad of things shared on Twitter every day, and not just 140 characters of text. There are links to breaking news stories, images from current events, and the latest activity from those you follow.</p><p>We want Discover to be the place where you find the best of that content relevant to you, even if you don’t necessarily know everyone involved. This is why we’ve introduced several improvements to Discover on twitter.com over the last few months. For example we redesigned it to show a <a href=\"http://blog.twitter.com/2012/09/more-tweets-to-discover.html\">continuous stream of Tweets</a> with photos and links to websites, in which you can also now see Tweets from activity, based on what your network favorites. We also added new signals to better blend together all the most relevant Tweets for you, and implemented <a href=\"https://twitter.com/twitter/status/266338665540755457\">polling</a> so you know whenever there are fresh Tweets to see.</p><blockquote class=\"twitter-tweet\"><p>Have you checked Discover lately? A new notification at the top of your stream shows when new Tweets are available. <a href=\"http://t.co/dL2NYafx\" title=\"http://twitter.com/twitter/status/266338665540755457/photo/1\">twitter.com/twitter/status…</a></p>&mdash; Twitter (@twitter) <a href=\"https://twitter.com/twitter/status/266338665540755457\" data-datetime=\"2012-11-08T00:37:41+00:00\">November 8, 2012</a></blockquote><script src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><br />
<p>Today we're introducing a new version of Discover for mobile that brings many of these features to your iPhone or Android phone. For this new release, we've completely re-done the backend and user interface to take advantage of <a href=\"https://dev.twitter.com/docs/cards\">Twitter cards</a>.</p><p>Using Twitter cards, you’ll now see Tweets in Discover with links to news and photos rather than the former story previews which were not interactive. And supporting Twitter cards on the backend means we can more directly improve the user experience in our native apps, too. You’ll see content from cards partners display as a previews in the stream, so that you’ll get headlines and publication names for story summaries and photo previews rather than shortened URLs. </p><p>All of this adds up to fewer taps, fewer screen views and more content for you to enjoy, faster. Of course, you can tap through to the details view for richer story summaries, bigger photos and the ability to reply, favorite or retweet Tweets.</p><p>We think this set of updates delivers the most engaging Discover experience yet, and we hope you enjoy the experience as much as we've enjoyed creating it.</p><p>Posted by Daniel Loreto - <a href=\"https://twitter.com/danielloreto\">@DanielLoreto</a><br />
Engineering Manager, Search and Relevance</p>" "http://www.blogger.com/feeds/5340805191653517637/posts/default/649228845742278151" (20645 31076) old 13 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-649228845742278151") (published nil "2012-11-15T15:23:00.000-08:00") (updated nil "2012-11-15T15:23:16.299-08:00") (title ((type . "text")) "Discover with a new lens: Twitter cards") (content ((type . "html")) "<p>As you already know, there’s a myriad of things shared on Twitter every day, and not just 140 characters of text. There are links to breaking news stories, images from current events, and the latest activity from those you follow.</p><p>We want Discover to be the place where you find the best of that content relevant to you, even if you don’t necessarily know everyone involved. This is why we’ve introduced several improvements to Discover on twitter.com over the last few months. For example we redesigned it to show a <a href=\"http://blog.twitter.com/2012/09/more-tweets-to-discover.html\">continuous stream of Tweets</a> with photos and links to websites, in which you can also now see Tweets from activity, based on what your network favorites. We also added new signals to better blend together all the most relevant Tweets for you, and implemented <a href=\"https://twitter.com/twitter/status/266338665540755457\">polling</a> so you know whenever there are fresh Tweets to see.</p><blockquote class=\"twitter-tweet\"><p>Have you checked Discover lately? A new notification at the top of your stream shows when new Tweets are available. <a href=\"http://t.co/dL2NYafx\" title=\"http://twitter.com/twitter/status/266338665540755457/photo/1\">twitter.com/twitter/status…</a></p>&mdash; Twitter (@twitter) <a href=\"https://twitter.com/twitter/status/266338665540755457\" data-datetime=\"2012-11-08T00:37:41+00:00\">November 8, 2012</a></blockquote><script src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><br />
<p>Today we're introducing a new version of Discover for mobile that brings many of these features to your iPhone or Android phone. For this new release, we've completely re-done the backend and user interface to take advantage of <a href=\"https://dev.twitter.com/docs/cards\">Twitter cards</a>.</p><p>Using Twitter cards, you’ll now see Tweets in Discover with links to news and photos rather than the former story previews which were not interactive. And supporting Twitter cards on the backend means we can more directly improve the user experience in our native apps, too. You’ll see content from cards partners display as a previews in the stream, so that you’ll get headlines and publication names for story summaries and photo previews rather than shortened URLs. </p><p>All of this adds up to fewer taps, fewer screen views and more content for you to enjoy, faster. Of course, you can tap through to the details view for richer story summaries, bigger photos and the ability to reply, favorite or retweet Tweets.</p><p>We think this set of updates delivers the most engaging Discover experience yet, and we hope you enjoy the experience as much as we've enjoyed creating it.</p><p>Posted by Daniel Loreto - <a href=\"https://twitter.com/danielloreto\">@DanielLoreto</a><br />
Engineering Manager, Search and Relevance</p>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/649228845742278151"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/649228845742278151"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/11/discover-with-new-lens-twitter-cards.html") (title . "Discover with a new lens: Twitter cards"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))))) ("Dimension Independent Similarity Computation (DISCO)" "MapReduce is a programming model for processing large data sets, typically used to do distributed computing on clusters of commodity computers. With large amount of processing power at hand, it’s very tempting to solve problems by brute force. However, we often combine clever sampling techniques with the power of MapReduce to extend its utility.<br />
<br />
Consider the problem of finding all pairs of similarities between D indicator (0/1 entries) vectors, each of dimension N. In particular we focus on cosine similarities between all pairs of D vectors in R^N. Further assume that each dimension is L-sparse, meaning each dimension has at most L non-zeros across all points. For example, typical values to compute similarities between all pairs of a subset of Twitter users can be:<br />
<br />
D = 10M<br />
N = 1B<br />
L = 1000<br />
<br />
Since the dimensions are sparse, it is natural to store the points dimension by dimension. To compute cosine similarities, we can easily feed each dimension t into MapReduce by using the following Mapper and Reducer combination<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://4.bp.blogspot.com/-_3IPLL6vJLg/UKFsYMRgbTI/AAAAAAAAAZQ/dqreJhdAjUo/s1600/image02.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"71\" src=\"http://4.bp.blogspot.com/-_3IPLL6vJLg/UKFsYMRgbTI/AAAAAAAAAZQ/dqreJhdAjUo/s640/image02.png\" width=\"512\" /></a></div>
<br />
Where #(w) counts the number of dimensions in which point w occurs, and #(w1, w2) counts the number of dimensions in which w1 and w2 co-occur, i.e., the dot product between w1 and w2. The steps above compute all dot products, which will then be scaled by the cosine normalization factor.<br />
<br />
There are two main complexity measures for MapReduce: “shuffle size”, and “reduce-key complexity”, defined shortly (Ashish Goel and Kamesh Munagala 2012). It can be easily shown that the above mappers will output on the order of O(NL^2) emissions, which for the example parameters we gave is infeasible. The number of emissions in the map phase is called the “shuffle size”, since that data needs to be shuffled around the network to reach the correct reducer.<br />
<br />
Furthermore, the maximum number of items reduced to a single key is at most #(w1, w2), which can be as large as N. Thus the “reduce-key complexity” for the above scheme is N.<br />
<br />
We can drastically reduce the shuffle size and reduce-key complexity by some clever sampling:<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://1.bp.blogspot.com/-34ZR2UwBq58/UKFsEADJLVI/AAAAAAAAAZE/2wSxCTdGU5A/s1600/image01.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"70\" src=\"http://1.bp.blogspot.com/-34ZR2UwBq58/UKFsEADJLVI/AAAAAAAAAZE/2wSxCTdGU5A/s640/image01.png\" width=\"512\" /></a></div>
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://1.bp.blogspot.com/-9E4sZjm3FF8/UKFqmjiPIPI/AAAAAAAAAYs/V6ejserefzs/s1600/image00.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" src=\"http://1.bp.blogspot.com/-9E4sZjm3FF8/UKFqmjiPIPI/AAAAAAAAAYs/V6ejserefzs/s1600/image00.png\" /></a></div>
<br />
Notation: p and ε are oversampling parameters.<br />
<br />
In this case, the output of the reducers are random variables whose expectations are the cosine similarities. Two proofs are needed to justify the effectiveness of this scheme. First, that the expectations are indeed correct and obtained with high probability, and second, that the shuffle size is greatly reduced. <br />
<br />
We prove both of these claims in (Reza Bosagh-Zadeh and Ashish Goel 2012). In particular, in addition to correctness, we prove that the shuffle size of the above scheme is only O(DL log(D)/ε), with no dependence on the “dimension” N, hence the name.<br />
<br />
This means as long as you have enough mappers to read your data, you can use the DISCO sampling scheme to make the shuffle size tractable. Furthermore, each reduce key gets at most O(log(D)/ε) values, thus making the reduce-key complexity tractable too. <br />
<br />
Within Twitter, we use the DISCO sampling scheme to compute similar users. We have also used the scheme to find highly similar pairs of words, by taking each dimension to be the indicator vector that signals in which Tweets the word appears. We further empirically verify the claims and observe large reductions in shuffle size, with details in the <a href=\"http://arxiv.org/abs/1206.2082\">paper</a>.<br />
<br />
Finally, this sampling scheme can be used to implement many other similarity measures. For Jaccard Similarity, we improve the implementation of the well-known MinHash (http://en.wikipedia.org/wiki/MinHash) scheme on Map-Reduce.<br />
<br />
Posted by <br />
Reza Zadeh (<a href=\"http://twitter.com/Reza_Zadeh\">@Reza_Zadeh</a>) and Ashish Goel (<a href=\"http://twitter.com/ashishgoel\">@ashishgoel</a>) - Personalization &amp; Recommendation Systems Group and Revenue Group<br />
<br />
<br />
<i>Bosagh-Zadeh, Reza and Goel, Ashish (2012), <a href=\"http://arxiv.org/abs/1206.2082\">Dimension Independent Similarity Computation, arXiv:1206.2082</a><br />
<br />
Goel, Ashish and Munagala, Kamesh (2012), <a href=\"http://www.stanford.edu/~ashishg/papers/mapreducecomplexity.pdf\">Complexity Measures for Map-Reduce, and Comparison to Parallel Computing</a>, http://www.stanford.edu/~ashishg/papers/mapreducecomplexity.pdf</i>" "http://www.blogger.com/feeds/5340805191653517637/posts/default/3117912966130251114" (20641 28650) old 14 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-3117912966130251114") (published nil "2012-11-12T13:32:00.000-08:00") (updated nil "2012-11-12T13:53:46.809-08:00") (title ((type . "text")) "Dimension Independent Similarity Computation (DISCO)") (content ((type . "html")) "MapReduce is a programming model for processing large data sets, typically used to do distributed computing on clusters of commodity computers. With large amount of processing power at hand, it’s very tempting to solve problems by brute force. However, we often combine clever sampling techniques with the power of MapReduce to extend its utility.<br />
<br />
Consider the problem of finding all pairs of similarities between D indicator (0/1 entries) vectors, each of dimension N. In particular we focus on cosine similarities between all pairs of D vectors in R^N. Further assume that each dimension is L-sparse, meaning each dimension has at most L non-zeros across all points. For example, typical values to compute similarities between all pairs of a subset of Twitter users can be:<br />
<br />
D = 10M<br />
N = 1B<br />
L = 1000<br />
<br />
Since the dimensions are sparse, it is natural to store the points dimension by dimension. To compute cosine similarities, we can easily feed each dimension t into MapReduce by using the following Mapper and Reducer combination<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://4.bp.blogspot.com/-_3IPLL6vJLg/UKFsYMRgbTI/AAAAAAAAAZQ/dqreJhdAjUo/s1600/image02.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"71\" src=\"http://4.bp.blogspot.com/-_3IPLL6vJLg/UKFsYMRgbTI/AAAAAAAAAZQ/dqreJhdAjUo/s640/image02.png\" width=\"512\" /></a></div>
<br />
Where #(w) counts the number of dimensions in which point w occurs, and #(w1, w2) counts the number of dimensions in which w1 and w2 co-occur, i.e., the dot product between w1 and w2. The steps above compute all dot products, which will then be scaled by the cosine normalization factor.<br />
<br />
There are two main complexity measures for MapReduce: “shuffle size”, and “reduce-key complexity”, defined shortly (Ashish Goel and Kamesh Munagala 2012). It can be easily shown that the above mappers will output on the order of O(NL^2) emissions, which for the example parameters we gave is infeasible. The number of emissions in the map phase is called the “shuffle size”, since that data needs to be shuffled around the network to reach the correct reducer.<br />
<br />
Furthermore, the maximum number of items reduced to a single key is at most #(w1, w2), which can be as large as N. Thus the “reduce-key complexity” for the above scheme is N.<br />
<br />
We can drastically reduce the shuffle size and reduce-key complexity by some clever sampling:<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://1.bp.blogspot.com/-34ZR2UwBq58/UKFsEADJLVI/AAAAAAAAAZE/2wSxCTdGU5A/s1600/image01.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" height=\"70\" src=\"http://1.bp.blogspot.com/-34ZR2UwBq58/UKFsEADJLVI/AAAAAAAAAZE/2wSxCTdGU5A/s640/image01.png\" width=\"512\" /></a></div>
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\">
<a href=\"http://1.bp.blogspot.com/-9E4sZjm3FF8/UKFqmjiPIPI/AAAAAAAAAYs/V6ejserefzs/s1600/image00.png\" imageanchor=\"1\" style=\"margin-left: 1em; margin-right: 1em;\"><img border=\"0\" src=\"http://1.bp.blogspot.com/-9E4sZjm3FF8/UKFqmjiPIPI/AAAAAAAAAYs/V6ejserefzs/s1600/image00.png\" /></a></div>
<br />
Notation: p and ε are oversampling parameters.<br />
<br />
In this case, the output of the reducers are random variables whose expectations are the cosine similarities. Two proofs are needed to justify the effectiveness of this scheme. First, that the expectations are indeed correct and obtained with high probability, and second, that the shuffle size is greatly reduced. <br />
<br />
We prove both of these claims in (Reza Bosagh-Zadeh and Ashish Goel 2012). In particular, in addition to correctness, we prove that the shuffle size of the above scheme is only O(DL log(D)/ε), with no dependence on the “dimension” N, hence the name.<br />
<br />
This means as long as you have enough mappers to read your data, you can use the DISCO sampling scheme to make the shuffle size tractable. Furthermore, each reduce key gets at most O(log(D)/ε) values, thus making the reduce-key complexity tractable too. <br />
<br />
Within Twitter, we use the DISCO sampling scheme to compute similar users. We have also used the scheme to find highly similar pairs of words, by taking each dimension to be the indicator vector that signals in which Tweets the word appears. We further empirically verify the claims and observe large reductions in shuffle size, with details in the <a href=\"http://arxiv.org/abs/1206.2082\">paper</a>.<br />
<br />
Finally, this sampling scheme can be used to implement many other similarity measures. For Jaccard Similarity, we improve the implementation of the well-known MinHash (http://en.wikipedia.org/wiki/MinHash) scheme on Map-Reduce.<br />
<br />
Posted by <br />
Reza Zadeh (<a href=\"http://twitter.com/Reza_Zadeh\">@Reza_Zadeh</a>) and Ashish Goel (<a href=\"http://twitter.com/ashishgoel\">@ashishgoel</a>) - Personalization &amp; Recommendation Systems Group and Revenue Group<br />
<br />
<br />
<i>Bosagh-Zadeh, Reza and Goel, Ashish (2012), <a href=\"http://arxiv.org/abs/1206.2082\">Dimension Independent Similarity Computation, arXiv:1206.2082</a><br />
<br />
Goel, Ashish and Munagala, Kamesh (2012), <a href=\"http://www.stanford.edu/~ashishg/papers/mapreducecomplexity.pdf\">Complexity Measures for Map-Reduce, and Comparison to Parallel Computing</a>, http://www.stanford.edu/~ashishg/papers/mapreducecomplexity.pdf</i>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3117912966130251114"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3117912966130251114"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/11/dimension-independent-similarity.html") (title . "Dimension Independent Similarity Computation (DISCO)"))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://4.bp.blogspot.com/-_3IPLL6vJLg/UKFsYMRgbTI/AAAAAAAAAZQ/dqreJhdAjUo/s72-c/image02.png") (height . "72") (width . "72"))))) ("Bolstering our infrastructure" "Last night, the world tuned in to Twitter to share the election results as U.S. voters chose a president and settled many other campaigns. Throughout the day, people sent more than 31 million election-related Tweets (which contained certain key terms and relevant hashtags). And as results rolled in, we tracked the surge in election-related Tweets at 327,452 Tweets per minute (TPM). These numbers reflect the largest election-related Twitter conversation during our 6 years of existence, though they don’t capture the total volume of all Tweets yesterday.<br />
<br />
As an engineering team, we keep an eye on all of the activity across the platform –– in particular, on the number of Tweets per second (TPS). Last night, Twitter averaged about 9,965 TPS from 8:11pm to 9:11pm PT, with a one-second peak of 15,107 TPS at 8:20pm PT and a one-minute peak of 874,560 TPM. Seeing a sustained peak over the course of an entire event is a change from the way people have previously turned to Twitter during live events. <br />
<br />
In the past, we’ve generally experienced short-lived roars related to the clock striking midnight on <a href=\"http://blog.twitter.com/2011/01/celebrating-new-year-with-new-tweet.html\">New Year’s Eve</a> (6,939 Tweets per second, or TPS), the <a href=\"https://twitter.com/twitter/status/92754546824200193\">end of a soccer game</a> (7,196 TPS), or <a href=\"https://twitter.com/twitter/status/92754546824200193\">Beyonce’s pregnancy announcement</a> (8,868 TPS). Those spikes tended to last seconds, maybe minutes at most. Now, rather than brief spikes, we are seeing sustained peaks for hours. Last night is just another example of the traffic pattern we’ve experienced this year –– we also saw this during the <a href=\"http://blog.twitter.com/2012/06/courtside-tweets.html\">NBA Finals</a>, <a href=\"http://blog.twitter.com/2012/08/olympic-and-twitter-records.html\">Olympics Closing Ceremonies</a>, <a href=\"http://blog.twitter.com/2012/09/the-vmas-look-back-via-twitter.html\">VMAs</a>, and <a href=\"http://blog.twitter.com/2012/10/twitters-hip-hop-firmament-barsandstars.html\">Hip-Hop Awards</a>.<br />
<br />
Last night’s numbers demonstrate that as Twitter usage patterns change, Twitter the service can remain resilient. Over time, we have been working to build an infrastructure that can withstand an ever-increasing load. For example, we’ve been steadily <a href=\"http://engineering.twitter.com/2011/03/building-faster-ruby-garbage-collector.html\">optimizing the Ruby runtime</a>. And, as part of our ongoing migration away from Ruby, we’ve reconfigured the service so traffic from our mobile clients hits the Java Virtual Machine (JVM) stack, avoiding the Ruby stack altogether. <br />
<br />
Of course, we still have plenty more to do. We’ll continue to measure and evaluate event-based traffic spikes, including their size and duration. We’ll continue studying the best ways to accommodate expected and unexpected traffic surges and high volume conversation during planned real-time events such as elections and championship games, as well as unplanned events such as natural disasters.<br />
<br />
The bottom line: No matter when, where or how people use Twitter, we need to remain accessible 24/7, around the world. We’re hard at work delivering on that vision.<br />
<br />
- Mazen Rawashdeh, VP of Infrastructure Operations Engineering (<a href=\"http://twitter.com/mazenra\">@mazenra</a>)" "http://www.blogger.com/feeds/5340805191653517637/posts/default/3939144769853576444" (20634 47430) old 15 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-3939144769853576444") (published nil "2012-11-07T11:40:00.000-08:00") (updated nil "2012-11-07T11:40:54.499-08:00") (title ((type . "text")) "Bolstering our infrastructure") (content ((type . "html")) "Last night, the world tuned in to Twitter to share the election results as U.S. voters chose a president and settled many other campaigns. Throughout the day, people sent more than 31 million election-related Tweets (which contained certain key terms and relevant hashtags). And as results rolled in, we tracked the surge in election-related Tweets at 327,452 Tweets per minute (TPM). These numbers reflect the largest election-related Twitter conversation during our 6 years of existence, though they don’t capture the total volume of all Tweets yesterday.<br />
<br />
As an engineering team, we keep an eye on all of the activity across the platform –– in particular, on the number of Tweets per second (TPS). Last night, Twitter averaged about 9,965 TPS from 8:11pm to 9:11pm PT, with a one-second peak of 15,107 TPS at 8:20pm PT and a one-minute peak of 874,560 TPM. Seeing a sustained peak over the course of an entire event is a change from the way people have previously turned to Twitter during live events. <br />
<br />
In the past, we’ve generally experienced short-lived roars related to the clock striking midnight on <a href=\"http://blog.twitter.com/2011/01/celebrating-new-year-with-new-tweet.html\">New Year’s Eve</a> (6,939 Tweets per second, or TPS), the <a href=\"https://twitter.com/twitter/status/92754546824200193\">end of a soccer game</a> (7,196 TPS), or <a href=\"https://twitter.com/twitter/status/92754546824200193\">Beyonce’s pregnancy announcement</a> (8,868 TPS). Those spikes tended to last seconds, maybe minutes at most. Now, rather than brief spikes, we are seeing sustained peaks for hours. Last night is just another example of the traffic pattern we’ve experienced this year –– we also saw this during the <a href=\"http://blog.twitter.com/2012/06/courtside-tweets.html\">NBA Finals</a>, <a href=\"http://blog.twitter.com/2012/08/olympic-and-twitter-records.html\">Olympics Closing Ceremonies</a>, <a href=\"http://blog.twitter.com/2012/09/the-vmas-look-back-via-twitter.html\">VMAs</a>, and <a href=\"http://blog.twitter.com/2012/10/twitters-hip-hop-firmament-barsandstars.html\">Hip-Hop Awards</a>.<br />
<br />
Last night’s numbers demonstrate that as Twitter usage patterns change, Twitter the service can remain resilient. Over time, we have been working to build an infrastructure that can withstand an ever-increasing load. For example, we’ve been steadily <a href=\"http://engineering.twitter.com/2011/03/building-faster-ruby-garbage-collector.html\">optimizing the Ruby runtime</a>. And, as part of our ongoing migration away from Ruby, we’ve reconfigured the service so traffic from our mobile clients hits the Java Virtual Machine (JVM) stack, avoiding the Ruby stack altogether. <br />
<br />
Of course, we still have plenty more to do. We’ll continue to measure and evaluate event-based traffic spikes, including their size and duration. We’ll continue studying the best ways to accommodate expected and unexpected traffic surges and high volume conversation during planned real-time events such as elections and championship games, as well as unplanned events such as natural disasters.<br />
<br />
The bottom line: No matter when, where or how people use Twitter, we need to remain accessible 24/7, around the world. We’re hard at work delivering on that vision.<br />
<br />
- Mazen Rawashdeh, VP of Infrastructure Operations Engineering (<a href=\"http://twitter.com/mazenra\">@mazenra</a>)") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3939144769853576444"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3939144769853576444"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/11/bolstering-our-infrastructure.html") (title . "Bolstering our infrastructure"))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))))) ("Open Sourcing Clutch.IO" "Clutch is an easy-to-integrate library for native iOS applications designed to help you develop faster, deploy instantly and run A/B tests. When Clutch co-founders Eric Florenzano (<a href=\"http://twitter.com/ericflo\">@ericflo</a>) and Eric Maguire (<a href=\"http://twitter.com/etmaguire\">@etmaguire</a>) recently joined the flock, they <a href=\"http://blog.clutch.io/post/29340796276/clutch-joins-the-flock\">promised</a> that everything you need to run Clutch on your own infrastructure would be available.<br />
<br />
<blockquote class=\"twitter-tweet\"><p>We are incredibly excited to announce that Twitter has acquired the IP of Clutch.io and we start work there today! <a href=\"http://t.co/chQ1iatB\" title=\"http://blog.clutch.io/post/29340796276/clutch-joins-the-flock\">blog.clutch.io/post/293407962…</a></p>&mdash; Clutch IO (<a href=\"http://twitter.com/clutchio\">@clutchio</a>) <a href=\"https://twitter.com/clutchio/status/235043048952840192\" data-datetime=\"2012-08-13T16:00:04+00:00\">August 13, 2012</a></blockquote><script src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><br />
<br />
Today, we’ve open-sourced the <a href=\"https://github.com/clutchio\">code</a> on GitHub under the Apache Public License 2.0, now with improved documentation to help get you started. As a reminder the hosted service will be active and supported until November 1. After that you can use the open-sourced code to run it on your own and modify it to your needs. Read more about how to <a href=\"https://github.com/clutchio/clutch\">set up your instance on GitHub</a> and ask any questions on the <a href=\"https://groups.google.com/forum/#!forum/clutchio\">mailing list</a> or on Twitter via <a href=\"http://twitter.com/clutchio\">@clutchio</a>.<br />
<br />
Releasing this code as an open source project is just the beginning. There are still plenty of areas for improvement from better documentation to an easier setup process. Now that the project is publicly available, we look forward to seeing a community blossom and grow the project into something greater.<br />
<br />
- Chris Aniszczyk, Manager of Open Source (<a href=\"http://twitter.com/cra\">@cra</a>)" "http://www.blogger.com/feeds/5340805191653517637/posts/default/6800954039717501337" (20598 64736) old 16 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-6800954039717501337") (published nil "2012-10-11T10:05:00.000-07:00") (updated nil "2012-10-11T10:07:44.399-07:00") (title ((type . "text")) "Open Sourcing Clutch.IO") (content ((type . "html")) "Clutch is an easy-to-integrate library for native iOS applications designed to help you develop faster, deploy instantly and run A/B tests. When Clutch co-founders Eric Florenzano (<a href=\"http://twitter.com/ericflo\">@ericflo</a>) and Eric Maguire (<a href=\"http://twitter.com/etmaguire\">@etmaguire</a>) recently joined the flock, they <a href=\"http://blog.clutch.io/post/29340796276/clutch-joins-the-flock\">promised</a> that everything you need to run Clutch on your own infrastructure would be available.<br />
<br />
<blockquote class=\"twitter-tweet\"><p>We are incredibly excited to announce that Twitter has acquired the IP of Clutch.io and we start work there today! <a href=\"http://t.co/chQ1iatB\" title=\"http://blog.clutch.io/post/29340796276/clutch-joins-the-flock\">blog.clutch.io/post/293407962…</a></p>&mdash; Clutch IO (<a href=\"http://twitter.com/clutchio\">@clutchio</a>) <a href=\"https://twitter.com/clutchio/status/235043048952840192\" data-datetime=\"2012-08-13T16:00:04+00:00\">August 13, 2012</a></blockquote><script src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><br />
<br />
Today, we’ve open-sourced the <a href=\"https://github.com/clutchio\">code</a> on GitHub under the Apache Public License 2.0, now with improved documentation to help get you started. As a reminder the hosted service will be active and supported until November 1. After that you can use the open-sourced code to run it on your own and modify it to your needs. Read more about how to <a href=\"https://github.com/clutchio/clutch\">set up your instance on GitHub</a> and ask any questions on the <a href=\"https://groups.google.com/forum/#!forum/clutchio\">mailing list</a> or on Twitter via <a href=\"http://twitter.com/clutchio\">@clutchio</a>.<br />
<br />
Releasing this code as an open source project is just the beginning. There are still plenty of areas for improvement from better documentation to an easier setup process. Now that the project is publicly available, we look forward to seeing a community blossom and grow the project into something greater.<br />
<br />
- Chris Aniszczyk, Manager of Open Source (<a href=\"http://twitter.com/cra\">@cra</a>)") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6800954039717501337"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6800954039717501337"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/10/open-sourcing-clutchio.html") (title . "Open Sourcing Clutch.IO"))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))))) ("Scalding 0.8.0 and Algebird" "<p>Earlier this year we open sourced <a href=\"https://github.com/twitter/scalding\">Scalding</a>, a Scala API for <a href=\"http://www.cascading.org/\">Cascading</a> that makes it easy to write big data jobs in a syntax that’s simple and concise. We use Scalding heavily — for everything from custom ad targeting algorithms to PageRank on the Twitter graph. Since open sourcing Scalding, we’ve been improving our documentation by adding a <a href=\"https://github.com/twitter/scalding/wiki/Getting-Started\">Getting Started</a> guide and a <a href=\"https://github.com/twitter/scalding/wiki/Rosetta-Code\">Rosetta Code</a> page that contains several MapReduce tasks translated from other frameworks (e.g., Pig and Hadoop Streaming) into Scalding. </p><p>Today we are excited to tell you about the 0.8.0 release of Scalding.</p><h3>What's new</h3><p>There are a lot of <a href=\"https://github.com/twitter/scalding/blob/develop/CHANGES.md\">new features</a>, for example, Scalding now includes a <a href=\"https://github.com/twitter/scalding/wiki/Matrix-API-Reference\">type-safe Matrix API</a>. The Matrix API makes expressing matrix sums, products, and simple algorithms like cosine similarity trivial. The <a href=\"https://github.com/twitter/scalding/wiki/Type-safe-api-reference\">type-safe Pipe API</a> has some new functions and a few bug fixes.</p><p>In the familiar <a href=\"https://github.com/twitter/scalding/wiki/Fields-based-API-Reference\">Fields API</a>, we’ve added the ability to add type information to fields which allows scalding to pick up Ordering instances so that grouping on almost any scala collection becomes easy. There is now a function to estimate set size in groupBy: <a href=\"https://github.com/twitter/scalding/blob/develop/src/main/scala/com/twitter/scalding/ReduceOperations.scala#L62\">approxUniques</a> (a naive implementation requires two groupBys, but this function uses <a href=\"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.142.9475\">HyperLogLog</a>). Since many aggregations are simple transformations of existing Monoids (associative operations with a zero), we added mapPlusMap to simplify implementation of many reducing operations (<a href=\"https://github.com/twitter/scalding/blob/develop/src/main/scala/com/twitter/scalding/ReduceOperations.scala#L50\">count how many functions are implemented in terms of mapPlusMap</a>).</p><p>Cascading and scalding try to optimize your job to some degree, but in some cases for optimal performance, some hand-tuning is needed. This release adds three features to make that easier:<br />
<ul><li><a href=\"https://github.com/twitter/scalding/blob/develop/src/main/scala/com/twitter/scalding/RichPipe.scala#L253\">forceToDisk</a> forces a materialization and helps when you know the prior operation filters almost all data and should not be limited to just before a join or merge. </li>
<li>Map-side aggregation in Cascading is done in memory with a threshold on when to spill and poor tuning can result in performance issues or out of memory errors. To help alleviate these issues, we now expose a function in groupBy to specify the <a href=\"https://github.com/twitter/scalding/blob/develop/src/main/scala/com/twitter/scalding/GroupBuilder.scala#L91\">spillThreshold.</a></li>
<li>We make it easy for Scalding Jobs to control the Hadoop configuration by allowing <a href=\"https://github.com/twitter/scalding/blob/develop/src/main/scala/com/twitter/scalding/Job.scala#L98\">overriding</a> of the config.</li>
</ul></p><h3>Algebird</h3><p><a href=\"https://github.com/twitter/algebird\">Algebird</a> is our lightweight abstract algebra library for Scala and is targeted for building aggregation systems (such as <a href=\"https://github.com/nathanmarz/storm\">Storm</a>). It was originally developed as part of Scalding's Matrix API, but almost all of the common reduce operations we care about in Scalding turn out to be instances of Monoids. This common library gives Map-merge, Set-union, List-concatenation, primitive-type algebra, and some fancy Monoids such as HyperLogLog for set cardinality estimation. Algebird has no dependencies and should be easy to use from any scala project that is doing aggregation of data or data-structures.  For instance in the Algebird repo, type “sbt console” and then:</p><p><pre>scala> import com.twitter.algebird.Operators._
import com.twitter.algebird.Operators._</pre></p><p><pre>scala> Map(1 -> 3, 2 -> 5, 3 -> 7, 5 -> 1) + Map(1 -> 1, 2 -> 1)
res0: scala.collection.immutable.Map[Int,Int] = Map(1 -> 4, 2 -> 6, 3 -> 7, 5 -> 1)</pre></p><p><pre>scala> Set(1,2,3) + Set(3,4,5)
res1: scala.collection.immutable.Set[Int] = Set(5, 1, 2, 3, 4)</pre></p><p><pre>scala> List(1,2,3) + List(3,4,5)
res2: List[Int] = List(1, 2, 3, 3, 4, 5)</pre></p><p><pre>scala> Map(1 -> 3, 2 -> 4, 3 -> 1) * Map(2 -> 2)
res3: scala.collection.immutable.Map[Int,Int] = Map(2 -> 8)</pre></p><p><pre>scala> Map(1 -> Set(2,3), 2 -> Set(1)) + Map(2 -> Set(2,3))
res4: scala.collection.immutable.Map[Int,scala.collection.immutable.Set[Int]] = Map(1 -> Set(2, 3), 2 -> Set(1, 2, 3))</pre></p><h3>Future work</h3><p>We are thrilled to see industry recognition of Scalding; the project has received a <a href=\"http://www.infoworld.com/slideshow/65089/bossie-awards-2012-the-best-open-source-databases-202354#slide3\">Bossie Award</a> and there’s a community building around Scalding, with adopters like Etsy and eBay using it in production. In the near future, we are looking at adding optimized skew joins, refactoring the code base into smaller components and using Thrift and Protobuf lzo compressed data. On the whole, we look forward to improving documentation and nurturing a community around Scalding as we approach a 1.0 release.</p><p>If you’d like to help work on any features or have any bug fixes, we’re always looking for contributions. Just submit a pull request to say hello or reach out to us on the <a href=\"https://groups.google.com/forum/?fromgroups#!forum/cascading-user\">mailing list</a>. If you find something missing or broken, report it in the <a href=\"https://github.com/twitter/scalding/issues\">issue tracker</a>.</p><h3>Acknowledgements</h3><p>Scalding and Algebird are built by a community. We’d like to acknowledge the following folks who contributed to the project: Oscar Boykin (<a href=\"https://twitter.com/posco\">@posco</a>), Avi Bryant (<a href=\"https://twitter.com/avibryant\">@avibryant</a>), Edwin Chen (<a href=\"https://twitter.com/echen\">@echen</a>), Sam Ritchie (<a href=\"https://twitter.com/sritchie\">@sritchie</a>), Flavian Vasile (<a href=\"https://twitter.com/flavianv\">@flavianv</a>) and Argyris Zymnis (<a href=\"https://twitter.com/argyris\">@argyris</a>). </p><p>Follow <a href=\"https://twitter.com/scalding\">@scalding</a> on Twitter to stay in touch!</p><p>Posted by Chris Aniszczyk <a href=\"https://twitter.com/cra\">@cra</a><br />
Manager, Open Source</p><a href=\"\"></a>" "http://www.blogger.com/feeds/5340805191653517637/posts/default/4925259586341921648" (20576 36566) old 17 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-4925259586341921648") (published nil "2012-09-24T09:48:00.000-07:00") (updated nil "2012-09-24T09:48:22.177-07:00") (title ((type . "text")) "Scalding 0.8.0 and Algebird") (content ((type . "html")) "<p>Earlier this year we open sourced <a href=\"https://github.com/twitter/scalding\">Scalding</a>, a Scala API for <a href=\"http://www.cascading.org/\">Cascading</a> that makes it easy to write big data jobs in a syntax that’s simple and concise. We use Scalding heavily — for everything from custom ad targeting algorithms to PageRank on the Twitter graph. Since open sourcing Scalding, we’ve been improving our documentation by adding a <a href=\"https://github.com/twitter/scalding/wiki/Getting-Started\">Getting Started</a> guide and a <a href=\"https://github.com/twitter/scalding/wiki/Rosetta-Code\">Rosetta Code</a> page that contains several MapReduce tasks translated from other frameworks (e.g., Pig and Hadoop Streaming) into Scalding. </p><p>Today we are excited to tell you about the 0.8.0 release of Scalding.</p><h3>What's new</h3><p>There are a lot of <a href=\"https://github.com/twitter/scalding/blob/develop/CHANGES.md\">new features</a>, for example, Scalding now includes a <a href=\"https://github.com/twitter/scalding/wiki/Matrix-API-Reference\">type-safe Matrix API</a>. The Matrix API makes expressing matrix sums, products, and simple algorithms like cosine similarity trivial. The <a href=\"https://github.com/twitter/scalding/wiki/Type-safe-api-reference\">type-safe Pipe API</a> has some new functions and a few bug fixes.</p><p>In the familiar <a href=\"https://github.com/twitter/scalding/wiki/Fields-based-API-Reference\">Fields API</a>, we’ve added the ability to add type information to fields which allows scalding to pick up Ordering instances so that grouping on almost any scala collection becomes easy. There is now a function to estimate set size in groupBy: <a href=\"https://github.com/twitter/scalding/blob/develop/src/main/scala/com/twitter/scalding/ReduceOperations.scala#L62\">approxUniques</a> (a naive implementation requires two groupBys, but this function uses <a href=\"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.142.9475\">HyperLogLog</a>). Since many aggregations are simple transformations of existing Monoids (associative operations with a zero), we added mapPlusMap to simplify implementation of many reducing operations (<a href=\"https://github.com/twitter/scalding/blob/develop/src/main/scala/com/twitter/scalding/ReduceOperations.scala#L50\">count how many functions are implemented in terms of mapPlusMap</a>).</p><p>Cascading and scalding try to optimize your job to some degree, but in some cases for optimal performance, some hand-tuning is needed. This release adds three features to make that easier:<br />
<ul><li><a href=\"https://github.com/twitter/scalding/blob/develop/src/main/scala/com/twitter/scalding/RichPipe.scala#L253\">forceToDisk</a> forces a materialization and helps when you know the prior operation filters almost all data and should not be limited to just before a join or merge. </li>
<li>Map-side aggregation in Cascading is done in memory with a threshold on when to spill and poor tuning can result in performance issues or out of memory errors. To help alleviate these issues, we now expose a function in groupBy to specify the <a href=\"https://github.com/twitter/scalding/blob/develop/src/main/scala/com/twitter/scalding/GroupBuilder.scala#L91\">spillThreshold.</a></li>
<li>We make it easy for Scalding Jobs to control the Hadoop configuration by allowing <a href=\"https://github.com/twitter/scalding/blob/develop/src/main/scala/com/twitter/scalding/Job.scala#L98\">overriding</a> of the config.</li>
</ul></p><h3>Algebird</h3><p><a href=\"https://github.com/twitter/algebird\">Algebird</a> is our lightweight abstract algebra library for Scala and is targeted for building aggregation systems (such as <a href=\"https://github.com/nathanmarz/storm\">Storm</a>). It was originally developed as part of Scalding's Matrix API, but almost all of the common reduce operations we care about in Scalding turn out to be instances of Monoids. This common library gives Map-merge, Set-union, List-concatenation, primitive-type algebra, and some fancy Monoids such as HyperLogLog for set cardinality estimation. Algebird has no dependencies and should be easy to use from any scala project that is doing aggregation of data or data-structures.  For instance in the Algebird repo, type “sbt console” and then:</p><p><pre>scala> import com.twitter.algebird.Operators._
import com.twitter.algebird.Operators._</pre></p><p><pre>scala> Map(1 -> 3, 2 -> 5, 3 -> 7, 5 -> 1) + Map(1 -> 1, 2 -> 1)
res0: scala.collection.immutable.Map[Int,Int] = Map(1 -> 4, 2 -> 6, 3 -> 7, 5 -> 1)</pre></p><p><pre>scala> Set(1,2,3) + Set(3,4,5)
res1: scala.collection.immutable.Set[Int] = Set(5, 1, 2, 3, 4)</pre></p><p><pre>scala> List(1,2,3) + List(3,4,5)
res2: List[Int] = List(1, 2, 3, 3, 4, 5)</pre></p><p><pre>scala> Map(1 -> 3, 2 -> 4, 3 -> 1) * Map(2 -> 2)
res3: scala.collection.immutable.Map[Int,Int] = Map(2 -> 8)</pre></p><p><pre>scala> Map(1 -> Set(2,3), 2 -> Set(1)) + Map(2 -> Set(2,3))
res4: scala.collection.immutable.Map[Int,scala.collection.immutable.Set[Int]] = Map(1 -> Set(2, 3), 2 -> Set(1, 2, 3))</pre></p><h3>Future work</h3><p>We are thrilled to see industry recognition of Scalding; the project has received a <a href=\"http://www.infoworld.com/slideshow/65089/bossie-awards-2012-the-best-open-source-databases-202354#slide3\">Bossie Award</a> and there’s a community building around Scalding, with adopters like Etsy and eBay using it in production. In the near future, we are looking at adding optimized skew joins, refactoring the code base into smaller components and using Thrift and Protobuf lzo compressed data. On the whole, we look forward to improving documentation and nurturing a community around Scalding as we approach a 1.0 release.</p><p>If you’d like to help work on any features or have any bug fixes, we’re always looking for contributions. Just submit a pull request to say hello or reach out to us on the <a href=\"https://groups.google.com/forum/?fromgroups#!forum/cascading-user\">mailing list</a>. If you find something missing or broken, report it in the <a href=\"https://github.com/twitter/scalding/issues\">issue tracker</a>.</p><h3>Acknowledgements</h3><p>Scalding and Algebird are built by a community. We’d like to acknowledge the following folks who contributed to the project: Oscar Boykin (<a href=\"https://twitter.com/posco\">@posco</a>), Avi Bryant (<a href=\"https://twitter.com/avibryant\">@avibryant</a>), Edwin Chen (<a href=\"https://twitter.com/echen\">@echen</a>), Sam Ritchie (<a href=\"https://twitter.com/sritchie\">@sritchie</a>), Flavian Vasile (<a href=\"https://twitter.com/flavianv\">@flavianv</a>) and Argyris Zymnis (<a href=\"https://twitter.com/argyris\">@argyris</a>). </p><p>Follow <a href=\"https://twitter.com/scalding\">@scalding</a> on Twitter to stay in touch!</p><p>Posted by Chris Aniszczyk <a href=\"https://twitter.com/cra\">@cra</a><br />
Manager, Open Source</p><a href=\"\"></a>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/4925259586341921648"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/4925259586341921648"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/09/scalding-080-and-algebird.html") (title . "Scalding 0.8.0 and Algebird"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))))) ("Joining the Linux Foundation" "<p>Today Twitter officially joins the Linux Foundation (<a href=\"https://twitter.com/linuxfoundation\">@linuxfoundation</a>), the nonprofit consortium dedicated to protecting and promoting the growth of the Linux operating system. <br />
</p><blockquote class=\"twitter-tweet\"><p>happy 21st birthday to <a href=\"https://twitter.com/search/?q=%23linux\"><s>#</s><b>linux</b></a>, we're proud to support the <a href=\"https://twitter.com/linuxfoundation\"><s>@</s><b>linuxfoundation</b></a> <a href=\"http://t.co/sJQxwdtF\" title=\"http://www.wired.com/thisdayintech/2009/08/0825-torvalds-starts-linux/\">wired.com/thisdayintech/…</a></p>&mdash; Twitter Open Source (@TwitterOSS) <a href=\"https://twitter.com/TwitterOSS/status/239413692314300417\" data-datetime=\"2012-08-25T17:27:26+00:00\">August 25, 2012</a></blockquote><script src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><br />
<p>We have tens of thousands machines running all types of services that run a tweaked version of Linux. One reason we support Linux is that open source development lets us control our destiny — we are able to innovate faster given the flexibility to customize based on our needs. We also love the large, stable and mature development community with whom we can collaborate to move the state of the kernel forward.  If you look at the latest <a href=\"http://go.linuxfoundation.org/who-writes-linux-2012\">Linux Development Report</a>, there are more than 7,800 developers from 800 different companies contributing to make Linux better for everyone.</p><p>We use a couple different kernel versions of Linux and tend to favor stability. As of today, we are mainly on the 2.6.39 kernel release. We tweak the kernel by adding some patches such as enhanced core dump functionality, <a href=\"http://unionfs.filesystems.org/\">UnionFS</a> support and the ability to allow <a href=\"https://developers.google.com/speed/articles/tcp_initcwnd_paper.pdf\">TCP congestion window</a> to be set on a socket basis.</p><p>We expect to further customize the kernel to optimize it for our production environment and contribute some of the work upstream. If you’re interested in hacking on kernel performance at the scale of Twitter and participating in the Linux community, we’d love to <a href=\"mailto:opensource@twitter.com\">hear from you</a> and speak with you at <a href=\"http://events.linuxfoundation.org/events/linuxcon\">LinuxCon</a> this week.</p><p>And of course, we wish Linux a <a href=\"https://groups.google.com/forum/?fromgroups=#!msg/comp.os.minix/dlNtH7RRrGA/SwRavCzVE7gJ\">happy 21st birthday</a>.</p><p>Posted by Chris Aniszczyk (<a href=\"https://twitter.com/cra\">@cra</a>), Manager of Open Source </p>" "http://www.blogger.com/feeds/5340805191653517637/posts/default/8363723829931580072" (20539 50698) old 18 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-8363723829931580072") (published nil "2012-08-27T12:10:00.000-07:00") (updated nil "2012-08-27T12:10:02.534-07:00") (title ((type . "text")) "Joining the Linux Foundation") (content ((type . "html")) "<p>Today Twitter officially joins the Linux Foundation (<a href=\"https://twitter.com/linuxfoundation\">@linuxfoundation</a>), the nonprofit consortium dedicated to protecting and promoting the growth of the Linux operating system. <br />
</p><blockquote class=\"twitter-tweet\"><p>happy 21st birthday to <a href=\"https://twitter.com/search/?q=%23linux\"><s>#</s><b>linux</b></a>, we're proud to support the <a href=\"https://twitter.com/linuxfoundation\"><s>@</s><b>linuxfoundation</b></a> <a href=\"http://t.co/sJQxwdtF\" title=\"http://www.wired.com/thisdayintech/2009/08/0825-torvalds-starts-linux/\">wired.com/thisdayintech/…</a></p>&mdash; Twitter Open Source (@TwitterOSS) <a href=\"https://twitter.com/TwitterOSS/status/239413692314300417\" data-datetime=\"2012-08-25T17:27:26+00:00\">August 25, 2012</a></blockquote><script src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><br />
<p>We have tens of thousands machines running all types of services that run a tweaked version of Linux. One reason we support Linux is that open source development lets us control our destiny — we are able to innovate faster given the flexibility to customize based on our needs. We also love the large, stable and mature development community with whom we can collaborate to move the state of the kernel forward.  If you look at the latest <a href=\"http://go.linuxfoundation.org/who-writes-linux-2012\">Linux Development Report</a>, there are more than 7,800 developers from 800 different companies contributing to make Linux better for everyone.</p><p>We use a couple different kernel versions of Linux and tend to favor stability. As of today, we are mainly on the 2.6.39 kernel release. We tweak the kernel by adding some patches such as enhanced core dump functionality, <a href=\"http://unionfs.filesystems.org/\">UnionFS</a> support and the ability to allow <a href=\"https://developers.google.com/speed/articles/tcp_initcwnd_paper.pdf\">TCP congestion window</a> to be set on a socket basis.</p><p>We expect to further customize the kernel to optimize it for our production environment and contribute some of the work upstream. If you’re interested in hacking on kernel performance at the scale of Twitter and participating in the Linux community, we’d love to <a href=\"mailto:opensource@twitter.com\">hear from you</a> and speak with you at <a href=\"http://events.linuxfoundation.org/events/linuxcon\">LinuxCon</a> this week.</p><p>And of course, we wish Linux a <a href=\"https://groups.google.com/forum/?fromgroups=#!msg/comp.os.minix/dlNtH7RRrGA/SwRavCzVE7gJ\">happy 21st birthday</a>.</p><p>Posted by Chris Aniszczyk (<a href=\"https://twitter.com/cra\">@cra</a>), Manager of Open Source </p>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/8363723829931580072"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/8363723829931580072"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/08/joining-linux-foundation.html") (title . "Joining the Linux Foundation"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))))) ("How we spent our Summer of Code" "<p>For the first time, <a href=\"http://engineering.twitter.com/2012/05/summer-of-code-at-twitter.html\">Twitter participated</a> in the <a href=\"http://code.google.com/soc/\">Google Summer of Code</a> (GSoC) and we want to share news on the resulting open source activities. Unlike many GSoC participating organizations that focus on a single ecosystem, we have a variety of projects spanning multiple programming languages and communities. </p><blockquote class=\"twitter-tweet\"><p>it's \"pencils down\" for <a href=\"https://twitter.com/gsoc\"><s>@</s><b>gsoc</b></a>, thank you so much to our mentors and student interns <a href=\"https://twitter.com/kl_7\"><s>@</s><b>kl_7</b></a> <a href=\"https://twitter.com/fbru02\"><s>@</s><b>fbru02</b></a> <a href=\"https://twitter.com/rubeydoo\"><s>@</s><b>rubeydoo</b></a> for hacking with us this summer</p>&mdash; Twitter Open Source (@TwitterOSS) <a href=\"https://twitter.com/TwitterOSS/status/238707212116185088\" data-datetime=\"2012-08-23T18:40:08+00:00\">August 23, 2012</a></blockquote><script src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><br />
<p>We accepted three students to work on a few projects:<br />
<ul><li>Kirill Lashuk (<a href=\"https://twitter.com/intent/user?screen_name=KL_7\">@KL_7</a>) mentored by Cameron Dutro (<a href=\"https://twitter.com/intent/user?screen_name=camertron\">@camertron</a>) added more internationalization and localization capabilities to Ruby via the <a href=\"https://github.com/twitter/twitter-cldr-rb\">TwitterCLDR</a> project. Among other things, he added the NFKD normalization algorithm, better access to Unicode code points and Unicode Collation Algorithm support, contributed over 6100 total lines of code, countless resource files and prepared the project for a new version of Ruby. His work should help anyone in the Ruby community needing robust internationalization support for their application.</li>
<li>Federico Brubacher (<a href=\"https://twitter.com/intent/user?screen_name=fbru02\">@fbru02</a>) mentored by Nathan Marz (<a href=\"https://twitter.com/intent/user?screen_name=nathanmarz\">@nathanmarz</a>) spent time kick starting and adding machine learning capabilities (<a href=\"https://github.com/nathanmarz/storm-contrib/tree/storm-ml/storm-ml\">see the code</a>) to <a href=\"http://storm-project.net/\">Twitter Storm</a>.</li>
<li>Ruben Oanta (<a href=\"https://twitter.com/intent/user?screen_name=rubeydoo\">@rubeydoo</a>) mentored by Marius Eriksen (<a href=\"https://twitter.com/intent/user?screen_name=marius\">@marius</a>) wrote a MySQL client (<a href=\"https://github.com/twitter/finagle/pull/98/files\">see the code</a>) for our RPC system, <a href=\"http://twitter.github.com/finagle/\">Twitter Finagle</a>. It supports both the binary and text protocols, allowing us to use both regular queries as well as prepared statements. His work provides a great foundation for our database clients to make better use of all of our shared infrastructure. We were also thrilled to collaborate with Tumblr’s Blake Matheny (<a href=\"https://twitter.com/intent/user?screen_name=bmatheny\">@bmatheny</a>) on mentoring this project.</li>
</ul></p><p>As part of GSoC, students and mentoring organizations receive a stipend. We are donating our portion of the stipend to <a href=\"http://www.girlswhocode.com/\">Girls Who Code</a>, an organization <a href=\"http://blog.twitter.com/2012/06/working-with-girls-who-code.html\">we support</a> that introduces high school girls to software development. </p><p>We really enjoyed the opportunity to take part in Google Summer of Code. Thank you to our three students, mentors and to Google for the program, we look forward to next year.</p><p>- Chris Aniszczyk (<a href=\"https://twitter.com/intent/user?screen_name=cra\">@cra</a>), Manager of Open Source</p>" "http://www.blogger.com/feeds/5340805191653517637/posts/default/7784070147488545788" (20535 53457) old 19 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-7784070147488545788") (published nil "2012-08-24T12:06:00.000-07:00") (updated nil "2012-08-24T12:06:57.283-07:00") (title ((type . "text")) "How we spent our Summer of Code") (content ((type . "html")) "<p>For the first time, <a href=\"http://engineering.twitter.com/2012/05/summer-of-code-at-twitter.html\">Twitter participated</a> in the <a href=\"http://code.google.com/soc/\">Google Summer of Code</a> (GSoC) and we want to share news on the resulting open source activities. Unlike many GSoC participating organizations that focus on a single ecosystem, we have a variety of projects spanning multiple programming languages and communities. </p><blockquote class=\"twitter-tweet\"><p>it's \"pencils down\" for <a href=\"https://twitter.com/gsoc\"><s>@</s><b>gsoc</b></a>, thank you so much to our mentors and student interns <a href=\"https://twitter.com/kl_7\"><s>@</s><b>kl_7</b></a> <a href=\"https://twitter.com/fbru02\"><s>@</s><b>fbru02</b></a> <a href=\"https://twitter.com/rubeydoo\"><s>@</s><b>rubeydoo</b></a> for hacking with us this summer</p>&mdash; Twitter Open Source (@TwitterOSS) <a href=\"https://twitter.com/TwitterOSS/status/238707212116185088\" data-datetime=\"2012-08-23T18:40:08+00:00\">August 23, 2012</a></blockquote><script src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><br />
<p>We accepted three students to work on a few projects:<br />
<ul><li>Kirill Lashuk (<a href=\"https://twitter.com/intent/user?screen_name=KL_7\">@KL_7</a>) mentored by Cameron Dutro (<a href=\"https://twitter.com/intent/user?screen_name=camertron\">@camertron</a>) added more internationalization and localization capabilities to Ruby via the <a href=\"https://github.com/twitter/twitter-cldr-rb\">TwitterCLDR</a> project. Among other things, he added the NFKD normalization algorithm, better access to Unicode code points and Unicode Collation Algorithm support, contributed over 6100 total lines of code, countless resource files and prepared the project for a new version of Ruby. His work should help anyone in the Ruby community needing robust internationalization support for their application.</li>
<li>Federico Brubacher (<a href=\"https://twitter.com/intent/user?screen_name=fbru02\">@fbru02</a>) mentored by Nathan Marz (<a href=\"https://twitter.com/intent/user?screen_name=nathanmarz\">@nathanmarz</a>) spent time kick starting and adding machine learning capabilities (<a href=\"https://github.com/nathanmarz/storm-contrib/tree/storm-ml/storm-ml\">see the code</a>) to <a href=\"http://storm-project.net/\">Twitter Storm</a>.</li>
<li>Ruben Oanta (<a href=\"https://twitter.com/intent/user?screen_name=rubeydoo\">@rubeydoo</a>) mentored by Marius Eriksen (<a href=\"https://twitter.com/intent/user?screen_name=marius\">@marius</a>) wrote a MySQL client (<a href=\"https://github.com/twitter/finagle/pull/98/files\">see the code</a>) for our RPC system, <a href=\"http://twitter.github.com/finagle/\">Twitter Finagle</a>. It supports both the binary and text protocols, allowing us to use both regular queries as well as prepared statements. His work provides a great foundation for our database clients to make better use of all of our shared infrastructure. We were also thrilled to collaborate with Tumblr’s Blake Matheny (<a href=\"https://twitter.com/intent/user?screen_name=bmatheny\">@bmatheny</a>) on mentoring this project.</li>
</ul></p><p>As part of GSoC, students and mentoring organizations receive a stipend. We are donating our portion of the stipend to <a href=\"http://www.girlswhocode.com/\">Girls Who Code</a>, an organization <a href=\"http://blog.twitter.com/2012/06/working-with-girls-who-code.html\">we support</a> that introduces high school girls to software development. </p><p>We really enjoyed the opportunity to take part in Google Summer of Code. Thank you to our three students, mentors and to Google for the program, we look forward to next year.</p><p>- Chris Aniszczyk (<a href=\"https://twitter.com/intent/user?screen_name=cra\">@cra</a>), Manager of Open Source</p>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/7784070147488545788"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/7784070147488545788"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/08/how-we-spent-our-summer-of-code.html") (title . "How we spent our Summer of Code"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))))) ("Crowdsourced data analysis with Clockwork Raven" "<p>Today, we’re excited to open source <a href=\"http://twitter.github.com/clockworkraven/\">Clockwork Raven</a>, a web application that allows users to easily submit data to <a href=\"http://en.wikipedia.org/wiki/Amazon_Mechanical_Turk\">Mechanical Turk</a> for manual review and then analyze that data. Clockwork Raven steps in to do what algorithms cannot: it sends your data analysis tasks to real people and gets fast, cheap and accurate results. We use Clockwork Raven to gather tens of thousands of judgments from Mechanical Turk users every week.</p><h3>Motivation</h3><p>We’re huge fans of human evaluation at Twitter and how it can aid data analysis. In the past, we’ve used systems like Mechanical Turk and CrowdFlower, as well as an internal system where we train dedicated reviewers and have them come in to our offices. However, as we scale up our usage of human evaluation, we needed a better system. This is why we built Clockwork Raven and designed it with several important goals in mind:<br />
<ul><li><b>Requires little technical skill to use</b>: The current Mechanical Turk web interface requires knowledge of HTML to do anything beyond very basic tasks.<br />
</li>
<li><b>Uniquely suited for our needs</b>: Many of our evaluations require us to embed tweets and timelines in the task. We wanted to create reusable components that would allow us to  easily add these widgets to our tasks.</li>
<li><b>Scalable</b>: Manually training reviews doesn’t scale as well as a system that crowd sources the work through Mechanical Turk.</li>
<li><b>Reliable</b>: We wanted controls over who’s allowed to complete our evaluations, so we can ensure we’re getting top-notch results.</li>
<li><b>Low barrier of entry</b>: We wanted a tool that everyone in the company could use to launch evaluations.</li>
<li><b>Integrated analysis</b>: We wanted a tool that would analyze the data we gather, in addition to provide the option to export a JSON or CSV to import into tools like R or a simple spreadsheet.</li>
</ul></p><h3>Features</h3><p>In Clockwork Raven, you create an evaluation by submitting a table of data (CSV or JSON). Each row of this table corresponds to a task that a human will complete. We build a template for the tasks in the Template Builder, then submit them to Mechanical Turk and Clockwork Raven tracks how many responses we’ve gotten. Once all the tasks are complete, we can import the results into Clockwork Raven where they’re presented in a configurable bar chart and can be exported to a number of data formats.</p><p>Here’s the features we’ve built into Clockwork Raven to address the goals above:<br />
<ul><li>Clockwork Raven has a simple drag-and-drop builder not unlike the form builder in Google Docs. We can create headers and text sections, add multiple-choice and free-response questions, and insert data from a column in the uploaded data. <br /><br />
<img src=\"http://twitter.github.com/clockworkraven/img/thumbs/template-builder.png\" /></li>
<li>The template builder has pre-built components for common items we need to put in our evaluations, like users and Tweets. It’s easy to build new components, so you can design your own. In the template builder, we can pass parameters (like the identifier of the Tweet we’re embedding) into the component. Here’s how we insert a tweet:<br /><br />
<img src=\"http://twitter.github.com/clockworkraven/img/thumbs/components.png\" /></li>
<li>Clockwork Raven submits jobs to Mechanical Turk. We can get back thousands of judgements in an hour or less. And because Mechanical Turk workers come from all over the world, we get results whenever we want them.</li>
<li>Clockwork Raven allows you to manage a list of Trusted Workers. We’ve found that having a hand-picked list of workers is the best way to get great results. We can expand our pool by opening up our tasks beyond our hand-picked set and choosing workers who are doing a great job with our tasks.</li>
<li>Clockwork Raven authenticates against any LDAP directory (or you can manage user accounts manually). That means that you can give a particular LDAP group at your organization access to Clockwork Raven, and they can log in with their own username and password. No shared accounts, and full accountability for who’s spending what. You can also give “unprivileged” access to some users, allowing them to try Clockwork Raven out and submit evaluations to the Mechanical Turk sandbox (which is free), but not allowing them to submit tasks that cost money without getting approval.</li>
<li>Clockwork Raven has a built-in data analysis tool that lets you chart your results across multiple dimensions of data and view individual results:<br /><br />
<img src=\"http://twitter.github.com/clockworkraven/img/thumbs/results.png\" /></li>
</ul></p><h3>Future Work</h3><p>We’re actively developing Clockwork Raven and improving it over time. Our target for the next release is a comprehensive REST API that works with JSON (possibly Thrift as well). We’re hoping this will allow us to build Clockwork Raven into our workflows, as well as enable its use for real-time human evaluation. We’re also working on better ways of managing workers, by automatically managing the group of trusted workers through qualification tasks and automated analysis of untrusted users’ work.</p><p>If you’d like to help work on these features, or have any bug fixes, other features, or documentation improvements, we’re always looking for contributions. Just submit a pull request to say hello or reach out to us on the <a href=\"https://groups.google.com/forum/?fromgroups#!forum/twitter-clockworkraven\">mailing list</a>. If you find something missing or broken, report it in the <a href=\"https://github.com/twitter/clockworkraven/issues\">issue tracker</a>.</p><h3>Acknowledgements</h3><p>Clockwork Raven was primarily authored by Ben Weissmann (<a href=\"https://twitter.com/benweissmann\">@benweissmann</a>). In addition, we’d like to acknowledge the following folks who contributed to the project: Edwin Chen (<a href=\"https://twitter.com/echen\">@echen</a>) and Dave Buchfuhrer (<a href=\"https://twitter.com/daveFNbuck\">@daveFNbuck</a>).</p><p>Follow <a href=\"https://twitter.com/clockworkraven\">@clockworkraven</a> on Twitter to stay in touch!</p><p>- Chris Aniszczyk, Manager of Open Source (<a href=\"https://twitter.com/clockworkraven\">@cra</a>)</p>" "http://www.blogger.com/feeds/5340805191653517637/posts/default/3558478185343378834" (20525 9966) old 20 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-3558478185343378834") (published nil "2012-08-16T09:59:00.000-07:00") (updated nil "2012-08-16T09:59:26.370-07:00") (title ((type . "text")) "Crowdsourced data analysis with Clockwork Raven") (content ((type . "html")) "<p>Today, we’re excited to open source <a href=\"http://twitter.github.com/clockworkraven/\">Clockwork Raven</a>, a web application that allows users to easily submit data to <a href=\"http://en.wikipedia.org/wiki/Amazon_Mechanical_Turk\">Mechanical Turk</a> for manual review and then analyze that data. Clockwork Raven steps in to do what algorithms cannot: it sends your data analysis tasks to real people and gets fast, cheap and accurate results. We use Clockwork Raven to gather tens of thousands of judgments from Mechanical Turk users every week.</p><h3>Motivation</h3><p>We’re huge fans of human evaluation at Twitter and how it can aid data analysis. In the past, we’ve used systems like Mechanical Turk and CrowdFlower, as well as an internal system where we train dedicated reviewers and have them come in to our offices. However, as we scale up our usage of human evaluation, we needed a better system. This is why we built Clockwork Raven and designed it with several important goals in mind:<br />
<ul><li><b>Requires little technical skill to use</b>: The current Mechanical Turk web interface requires knowledge of HTML to do anything beyond very basic tasks.<br />
</li>
<li><b>Uniquely suited for our needs</b>: Many of our evaluations require us to embed tweets and timelines in the task. We wanted to create reusable components that would allow us to  easily add these widgets to our tasks.</li>
<li><b>Scalable</b>: Manually training reviews doesn’t scale as well as a system that crowd sources the work through Mechanical Turk.</li>
<li><b>Reliable</b>: We wanted controls over who’s allowed to complete our evaluations, so we can ensure we’re getting top-notch results.</li>
<li><b>Low barrier of entry</b>: We wanted a tool that everyone in the company could use to launch evaluations.</li>
<li><b>Integrated analysis</b>: We wanted a tool that would analyze the data we gather, in addition to provide the option to export a JSON or CSV to import into tools like R or a simple spreadsheet.</li>
</ul></p><h3>Features</h3><p>In Clockwork Raven, you create an evaluation by submitting a table of data (CSV or JSON). Each row of this table corresponds to a task that a human will complete. We build a template for the tasks in the Template Builder, then submit them to Mechanical Turk and Clockwork Raven tracks how many responses we’ve gotten. Once all the tasks are complete, we can import the results into Clockwork Raven where they’re presented in a configurable bar chart and can be exported to a number of data formats.</p><p>Here’s the features we’ve built into Clockwork Raven to address the goals above:<br />
<ul><li>Clockwork Raven has a simple drag-and-drop builder not unlike the form builder in Google Docs. We can create headers and text sections, add multiple-choice and free-response questions, and insert data from a column in the uploaded data. <br /><br />
<img src=\"http://twitter.github.com/clockworkraven/img/thumbs/template-builder.png\" /></li>
<li>The template builder has pre-built components for common items we need to put in our evaluations, like users and Tweets. It’s easy to build new components, so you can design your own. In the template builder, we can pass parameters (like the identifier of the Tweet we’re embedding) into the component. Here’s how we insert a tweet:<br /><br />
<img src=\"http://twitter.github.com/clockworkraven/img/thumbs/components.png\" /></li>
<li>Clockwork Raven submits jobs to Mechanical Turk. We can get back thousands of judgements in an hour or less. And because Mechanical Turk workers come from all over the world, we get results whenever we want them.</li>
<li>Clockwork Raven allows you to manage a list of Trusted Workers. We’ve found that having a hand-picked list of workers is the best way to get great results. We can expand our pool by opening up our tasks beyond our hand-picked set and choosing workers who are doing a great job with our tasks.</li>
<li>Clockwork Raven authenticates against any LDAP directory (or you can manage user accounts manually). That means that you can give a particular LDAP group at your organization access to Clockwork Raven, and they can log in with their own username and password. No shared accounts, and full accountability for who’s spending what. You can also give “unprivileged” access to some users, allowing them to try Clockwork Raven out and submit evaluations to the Mechanical Turk sandbox (which is free), but not allowing them to submit tasks that cost money without getting approval.</li>
<li>Clockwork Raven has a built-in data analysis tool that lets you chart your results across multiple dimensions of data and view individual results:<br /><br />
<img src=\"http://twitter.github.com/clockworkraven/img/thumbs/results.png\" /></li>
</ul></p><h3>Future Work</h3><p>We’re actively developing Clockwork Raven and improving it over time. Our target for the next release is a comprehensive REST API that works with JSON (possibly Thrift as well). We’re hoping this will allow us to build Clockwork Raven into our workflows, as well as enable its use for real-time human evaluation. We’re also working on better ways of managing workers, by automatically managing the group of trusted workers through qualification tasks and automated analysis of untrusted users’ work.</p><p>If you’d like to help work on these features, or have any bug fixes, other features, or documentation improvements, we’re always looking for contributions. Just submit a pull request to say hello or reach out to us on the <a href=\"https://groups.google.com/forum/?fromgroups#!forum/twitter-clockworkraven\">mailing list</a>. If you find something missing or broken, report it in the <a href=\"https://github.com/twitter/clockworkraven/issues\">issue tracker</a>.</p><h3>Acknowledgements</h3><p>Clockwork Raven was primarily authored by Ben Weissmann (<a href=\"https://twitter.com/benweissmann\">@benweissmann</a>). In addition, we’d like to acknowledge the following folks who contributed to the project: Edwin Chen (<a href=\"https://twitter.com/echen\">@echen</a>) and Dave Buchfuhrer (<a href=\"https://twitter.com/daveFNbuck\">@daveFNbuck</a>).</p><p>Follow <a href=\"https://twitter.com/clockworkraven\">@clockworkraven</a> on Twitter to stay in touch!</p><p>- Chris Aniszczyk, Manager of Open Source (<a href=\"https://twitter.com/clockworkraven\">@cra</a>)</p>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3558478185343378834"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/3558478185343378834"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/08/crowdsourced-data-analysis-with.html") (title . "Crowdsourced data analysis with Clockwork Raven"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))))) ("Visualizing Hadoop with HDFS-DU" "<p>We are a heavy adopter of <a href=\"https://github.com/twitter/hdfs-du\">Apache Hadoop</a> with a large set of data that resides in its clusters, so it’s important for us to understand how these resources are utilized. At our July <a href=\"http://blog.twitter.com/2012/01/hack-week-twitter.html\">Hack Week</a>, we experimented with developing <a href=\"https://github.com/twitter/hdfs-du\">HDFS-DU</a> to provide us an interactive visualization of the underlying Hadoop Distributed File System (HDFS). The project aims to monitor different snapshots for the entire HDFS system in an interactive way, showing the size of the folders and the rate at which the size changes. It can also effectively identify efficient and inefficient file storage and highlight nodes in the file system where this is happening.</p><p>HDFS-DU provides the following in a web user interface:<br />
<ul><li>A TreeMap visualization where each node is a folder in HDFS. The area of each node can be relative to the size or number of descendents</li>
<li>A tree visualization showing the topology of the file system</li>
</ul></p><p>HDFS-DU is built using the following front-end technologies:<br />
<ul><li><a href=\"http://d3js.org/\">D3.js</a>: for tree visualization</li>
<li><a href=\"http://thejit.org/\">JavaScript InfoVis Toolkit</a>: for TreeMap visualization</li>
</ul></p><h3>Details</h3><p>Below is a screenshot of the HDFS-DU user interface (directory names scrubbed). The user interface is made up of two linked visualizations. The left visualization is a TreeMap and shows parent-child relationships through containment. The right visualization is a tree layout, which displays two levels of depth from the current selected node in the file system. The tree visualization displays extra information for each node on hover.</p><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://1.bp.blogspot.com/-4VPTuVaxVpk/UCFYwAIdpmI/AAAAAAAAAK8/72tbXz3Nd9I/s1600/1.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"352\" width=\"400\" src=\"http://1.bp.blogspot.com/-4VPTuVaxVpk/UCFYwAIdpmI/AAAAAAAAAK8/72tbXz3Nd9I/s400/1.png\" /></a></div><p>You can drill down on the TreeMap by clicking on a node, this would create the same effect as clicking on any tree node. There are two possible layouts for the TreeMap. The default one encodes file size in the area of each node. The second one encodes number of descendents in the area of each node. In the second view it's interesting to spot nodes where storage is inefficient.</p><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://2.bp.blogspot.com/-qSpx6IiGlpc/UCFY-h3c13I/AAAAAAAAALI/eVHAfwuSKA4/s1600/2.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"309\" width=\"400\" src=\"http://2.bp.blogspot.com/-qSpx6IiGlpc/UCFY-h3c13I/AAAAAAAAALI/eVHAfwuSKA4/s400/2.png\" /></a></div><br />
<h3>Future Work</h3><p>This project was created at our July Hack Week and we still consider it beta but useful software. In the future, we would love to improve the front-end client and create a new back-end for a different runtime environment. On the front end, the directory browser, currently on the right, is poorly suited to the task of showing the directory structure.  A view which looks more like a traditional filesystem browser would be more immediately recognizable and make better use of space (it is likely that a javascript file browser exists and could be used instead).  Also, the integration between the current file browser and the TreeMap needs improvement.</p><p>We initially envisioned the TreeMap as a <a href=\"http://en.wikipedia.org/wiki/Voronoi_diagram\">Voronoi TreeMap</a>, however our current implementation of that code ran too slowly to be practical.  We would love to get the Voronoi TreeMap code to work fast enough. We would also like to add the option to use different values to size and color the TreeMap areas.  For example, change in size, creation time, last access time, frequency of access.</p><h3>Acknowledgements</h3><p>HDFS-DU was primarily authored by Travis Crawford (<a href=\"https://twitter.com/tc/\">@tc</a>), Nicolas Garcia Belmonte (<a href=\"https://twitter.com/philogb\">@philogb</a>) and Robert Harris (<a href=\"https://twitter.com/trebor\">@trebor</a>). Given that this is a young project, we always appreciate bug fixes, features and documentation improvements. Feel free to fork the project and send us a pull request on GitHub to say hello. Finally, if you’re interested in visualization and distributed file systems like Hadoop, we’re always looking for engineers to <a href=\"https://twitter.com/jobs\">join the flock.</a></p><p>Follow <a href=\"https://twitter.com/hdfsdu\">@hdfsdu</a> on Twitter to stay in touch!</p><p>- Chris Aniszczyk, Manager of Open Source (<a href=\"https://twitter.com/cra\">@cra</a>)</p>" "http://www.blogger.com/feeds/5340805191653517637/posts/default/1108671060552687033" (20513 23095) old 21 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-1108671060552687033") (published nil "2012-08-07T11:06:00.000-07:00") (updated nil "2012-08-07T11:11:03.800-07:00") (title ((type . "text")) "Visualizing Hadoop with HDFS-DU") (content ((type . "html")) "<p>We are a heavy adopter of <a href=\"https://github.com/twitter/hdfs-du\">Apache Hadoop</a> with a large set of data that resides in its clusters, so it’s important for us to understand how these resources are utilized. At our July <a href=\"http://blog.twitter.com/2012/01/hack-week-twitter.html\">Hack Week</a>, we experimented with developing <a href=\"https://github.com/twitter/hdfs-du\">HDFS-DU</a> to provide us an interactive visualization of the underlying Hadoop Distributed File System (HDFS). The project aims to monitor different snapshots for the entire HDFS system in an interactive way, showing the size of the folders and the rate at which the size changes. It can also effectively identify efficient and inefficient file storage and highlight nodes in the file system where this is happening.</p><p>HDFS-DU provides the following in a web user interface:<br />
<ul><li>A TreeMap visualization where each node is a folder in HDFS. The area of each node can be relative to the size or number of descendents</li>
<li>A tree visualization showing the topology of the file system</li>
</ul></p><p>HDFS-DU is built using the following front-end technologies:<br />
<ul><li><a href=\"http://d3js.org/\">D3.js</a>: for tree visualization</li>
<li><a href=\"http://thejit.org/\">JavaScript InfoVis Toolkit</a>: for TreeMap visualization</li>
</ul></p><h3>Details</h3><p>Below is a screenshot of the HDFS-DU user interface (directory names scrubbed). The user interface is made up of two linked visualizations. The left visualization is a TreeMap and shows parent-child relationships through containment. The right visualization is a tree layout, which displays two levels of depth from the current selected node in the file system. The tree visualization displays extra information for each node on hover.</p><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://1.bp.blogspot.com/-4VPTuVaxVpk/UCFYwAIdpmI/AAAAAAAAAK8/72tbXz3Nd9I/s1600/1.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"352\" width=\"400\" src=\"http://1.bp.blogspot.com/-4VPTuVaxVpk/UCFYwAIdpmI/AAAAAAAAAK8/72tbXz3Nd9I/s400/1.png\" /></a></div><p>You can drill down on the TreeMap by clicking on a node, this would create the same effect as clicking on any tree node. There are two possible layouts for the TreeMap. The default one encodes file size in the area of each node. The second one encodes number of descendents in the area of each node. In the second view it's interesting to spot nodes where storage is inefficient.</p><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://2.bp.blogspot.com/-qSpx6IiGlpc/UCFY-h3c13I/AAAAAAAAALI/eVHAfwuSKA4/s1600/2.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"309\" width=\"400\" src=\"http://2.bp.blogspot.com/-qSpx6IiGlpc/UCFY-h3c13I/AAAAAAAAALI/eVHAfwuSKA4/s400/2.png\" /></a></div><br />
<h3>Future Work</h3><p>This project was created at our July Hack Week and we still consider it beta but useful software. In the future, we would love to improve the front-end client and create a new back-end for a different runtime environment. On the front end, the directory browser, currently on the right, is poorly suited to the task of showing the directory structure.  A view which looks more like a traditional filesystem browser would be more immediately recognizable and make better use of space (it is likely that a javascript file browser exists and could be used instead).  Also, the integration between the current file browser and the TreeMap needs improvement.</p><p>We initially envisioned the TreeMap as a <a href=\"http://en.wikipedia.org/wiki/Voronoi_diagram\">Voronoi TreeMap</a>, however our current implementation of that code ran too slowly to be practical.  We would love to get the Voronoi TreeMap code to work fast enough. We would also like to add the option to use different values to size and color the TreeMap areas.  For example, change in size, creation time, last access time, frequency of access.</p><h3>Acknowledgements</h3><p>HDFS-DU was primarily authored by Travis Crawford (<a href=\"https://twitter.com/tc/\">@tc</a>), Nicolas Garcia Belmonte (<a href=\"https://twitter.com/philogb\">@philogb</a>) and Robert Harris (<a href=\"https://twitter.com/trebor\">@trebor</a>). Given that this is a young project, we always appreciate bug fixes, features and documentation improvements. Feel free to fork the project and send us a pull request on GitHub to say hello. Finally, if you’re interested in visualization and distributed file systems like Hadoop, we’re always looking for engineers to <a href=\"https://twitter.com/jobs\">join the flock.</a></p><p>Follow <a href=\"https://twitter.com/hdfsdu\">@hdfsdu</a> on Twitter to stay in touch!</p><p>- Chris Aniszczyk, Manager of Open Source (<a href=\"https://twitter.com/cra\">@cra</a>)</p>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/1108671060552687033"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/1108671060552687033"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/08/visualizing-hadoop-with-hdfs-du.html") (title . "Visualizing Hadoop with HDFS-DU"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://1.bp.blogspot.com/-4VPTuVaxVpk/UCFYwAIdpmI/AAAAAAAAAK8/72tbXz3Nd9I/s72-c/1.png") (height . "72") (width . "72"))))) ("Trident: a high-level abstraction for realtime computation" "<p>Trident is a new high-level abstraction for doing realtime computing on top of <a href=\"http://storm-project.net/\">Twitter Storm</a>, available in <a href=\"http://storm-project.net/downloads.html\">Storm 0.8.0</a> (released today). It allows you to seamlessly mix high throughput (millions of messages per second), stateful stream processing with low latency distributed querying. If you're familiar with high level batch processing tools like <a href=\"http://pig.apache.org/\">Pig</a> or <a href=\"http://www.cascading.org/\">Cascading</a>, the concepts of Trident will be very familiar - Trident has joins, aggregations, grouping, functions, and filters. In addition to these, Trident adds primitives for doing stateful, incremental processing on top of any database or persistence store. Trident has consistent, exactly-once semantics, so it is easy to reason about Trident topologies.</p><p>We're really excited about Trident and believe it is a major step forward in Big Data processing. It builds upon Storm's foundation to make realtime computation as easy as batch computation.</p><h2>Example</h2><p>Let's look at an illustrative example of Trident. This example will do two things: </p><ol><li><p>Compute streaming word count from an input stream of sentences</p></li>
<li><p>Implement queries to get the sum of the counts for a list of words</p></li>
</ol><p>For the purposes of illustration, this example will read an infinite stream of sentences from the following source:</p><script src=\"https://gist.github.com/3234617.js?file=gistfile1.java\"></script><br />
<p>This spout cycles through that set of sentences over and over to produce the sentence stream. Here's the code to do the streaming word count part of the computation:</p><script src=\"https://gist.github.com/3234621.js?file=gistfile1.java\"></script><br />
<p>Let's go through the code line by line. First a TridentTopology object is created, which exposes the interface for constructing Trident computations. TridentTopology has a method called newStream that creates a new stream of data in the topology reading from an input source. In this case, the input source is just the FixedBatchSpout defined from before. Input sources can also be queue brokers like Kestrel or Kafka. Trident keeps track of a small amount of state for each input source (metadata about what it has consumed) in Zookeeper, and the \"spout1\" string here specifies the node in Zookeeper where Trident should keep that metadata.</p><p>Trident processes the stream as small batches of tuples. For example, the incoming stream of sentences might be divided into batches like so:</p><p><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-dvyMvMMVyQg/UBqwN1OQnoI/AAAAAAAAAKQ/uaYoI0UH9fU/s1600/batched-stream.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"240\" width=\"400\" src=\"http://4.bp.blogspot.com/-dvyMvMMVyQg/UBqwN1OQnoI/AAAAAAAAAKQ/uaYoI0UH9fU/s400/batched-stream.png\" /></a></div></p><p>Generally the size of those small batches will be on the order of thousands or millions of tuples, depending on your incoming throughput.</p><p>Trident provides a fully fledged batch processing API to process those small batches. The API is very similar to what you see in high level abstractions for Hadoop like Pig or Cascading: you can do group by's, joins, aggregations, run functions, run filters, and so on. Of course, processing each small batch in isolation isn't that interesting, so Trident provides functions for doing aggregations across batches and persistently storing those aggregations - whether in memory, in Memcached, in Cassandra, or some other store. Finally, Trident has first-class functions for querying sources of realtime state. That state could be updated by Trident (like in this example), or it could be an independent source of state.</p><p>Back to the example, the spout emits a stream containing one field called \"sentence\". The next line of the topology definition applies the Split function to each tuple in the stream, taking the \"sentence\" field and splitting it into words. Each sentence tuple creates potentially many word tuples - for instance, the sentence \"the cow jumped over the moon\" creates six \"word\" tuples. Here's the definition of Split:<br />
</p><script src=\"https://gist.github.com/3234623.js?file=gistfile1.java\"></script><br />
<p>As you can see, it's really simple. It simply grabs the sentence, splits it on whitespace, and emits a tuple for each word.</p><p>The rest of the topology computes word count and keeps the results persistently stored. First the stream is grouped by the \"word\" field. Then, each group is persistently aggregated using the Count aggregator. The persistentAggregate function knows how to store and update the results of the aggregation in a source of state. In this example, the word counts are kept in memory, but this can be trivially swapped to use Memcached, Cassandra, or any other persistent store. Swapping this topology to store counts in Memcached is as simple as replacing the persistentAggregate line with this (using <a href=\"https://github.com/nathanmarz/trident-memcached\">trident-memcached</a>), where the \"serverLocations\" variable is a list of host/ports for the Memcached cluster:</p><script src=\"https://gist.github.com/3234632.js?file=gistfile1.java\"></script><br />
<p>The values stored by persistentAggregate represents the aggregation of all batches ever emitted by the stream.</p><p>One of the cool things about Trident is that it has fully fault-tolerant, exactly-once processing semantics. This makes it easy to reason about your realtime processing. Trident persists state in a way so that if failures occur and retries are necessary, it won't perform multiple updates to the database for the same source data.</p><p>The persistentAggregate method transforms a Stream into a TridentState object. In this case the TridentState object represents all the word counts. We will use this TridentState object to implement the distributed query portion of the computation.</p><p>The next part of the topology implements a low latency distributed query on the word counts. The query takes as input a whitespace separated list of words and return the sum of the counts for those words. These queries are executed just like normal RPC calls, except they are parallelized in the background. Here's an example of how you might invoke one of these queries:</p><script src=\"https://gist.github.com/3234636.js?file=gistfile1.java\"></script><br />
<p>As you can see, it looks just like a regular remote procedure call (RPC), except it's executing in parallel across a Storm cluster. The latency for small queries like this are typically around 10ms. More intense DRPC queries can take longer of course, although the latency largely depends on how many resources you have allocated for the computation.</p><p>The implementation of the distributed query portion of the topology looks like this:<br />
</p><script src=\"https://gist.github.com/3234638.js?file=gistfile1.java\"></script><br />
<p>The same TridentTopology object is used to create the DRPC stream, and the function is named \"words\". The function name corresponds to the function name given in the first argument of execute when using a DRPCClient.</p><p>Each DRPC request is treated as its own little batch processing job that takes as input a single tuple representing the request. The tuple contains one field called \"args\" that contains the argument provided by the client. In this case, the argument is a whitespace separated list of words.</p><p>First, the Split function is used to split the arguments for the request into its constituent words. The stream is grouped by \"word\", and the stateQuery operator is used to query the TridentState object that the first part of the topology generated. stateQuery takes in a source of state - in this case, the word counts computed by the other portion of the topology - and a function for querying that state. In this case, the MapGet function is invoked, which gets the count for each word. Since the DRPC stream is grouped the exact same way as the TridentState was (by the \"word\" field), each word query is routed to the exact partition of the TridentState object that manages updates for that word.</p><p>Next, words that didn't have a count are filtered out via the FilterNull filter and the counts are summed using the Sum aggregator to get the result. Then, Trident automatically sends the result back to the waiting client.</p><p>Trident is intelligent about how it executes a topology to maximize performance. There's two interesting things happening automatically in this topology:</p><ol><li><p>Operations that read from or write to state (like persistentAggregate and stateQuery) automatically batch operations to that state. So if there's 20 updates that need to be made to the database for the current batch of processing, rather than do 20 read requests and 20 write requests to the database, Trident will automatically batch up the reads and writes, doing only 1 read request and 1 write request (and in many cases, you can use caching in your State implementation to eliminate the read request). So you get the best of both words of convenience - being able to express your computation in terms of what should be done with each tuple - and performance.</p></li>
<li><p>Trident aggregators are heavily optimized. Rather than transfer all tuples for a group to the same machine and then run the aggregator, Trident will do partial aggregations when possible before sending tuples over the network. For example, the Count aggregator computes the count on each partition, sends the partial count over the network, and then sums together all the partial counts to get the total count. This technique is similar to the use of combiners in MapReduce.</p></li>
</ol><p>Let's look at another example of Trident.</p><h2>Reach</h2><p>The next example is a pure DRPC topology that computes the reach of a URL on Twitter on demand. Reach is the number of unique people exposed to a URL on Twitter. To compute reach, you need to fetch all the people who ever tweeted a URL, fetch all the followers of all those people, unique that set of followers, and that count that uniqued set. Computing reach is too intense for a single machine - it can require thousands of database calls and tens of millions of tuples. With Storm and Trident, it's easy to parallelize the computation of each step across a cluster.</p><p>This topology will read from two sources of state. One database maps URLs to a list of people who tweeted that URL. The other database maps a person to a list of followers for that person. The topology definition looks like this:</p><script src=\"https://gist.github.com/3234642.js?file=gistfile1.java\"></script><br />
<p>The topology creates TridentState objects representing each external database using the newStaticState method. These can then be queried in the topology. Like all sources of state, queries to these databases will be automatically batched for maximum efficiency.</p><p>The topology definition is straightforward - it's just a simple batch processing job. First, the urlToTweeters database is queried to get the list of people who tweeted the URL for this request. That returns a list, so the ExpandList function is invoked to create a tuple for each tweeter.</p><p>Next, the followers for each tweeter must be fetched. It's important that this step be parallelized, so shuffle is invoked to evenly distribute the tweeters among all workers for the topology. Then, the followers database is queried to get the list of followers for each tweeter. You can see that this portion of the topology is given a large parallelism since this is the most intense portion of the computation.</p><p>Next, the set of followers is uniqued and counted. This is done in two steps. First a \"group by\" is done on the batch by \"follower\", running the \"One\" aggregator on each group. The \"One\" aggregator simply emits a single tuple containing the number one for each group. Then, the ones are summed together to get the unique count of the followers set. Here's the definition of the \"One\" aggregator:</p><script src=\"https://gist.github.com/3234645.js?file=gistfile1.java\"></script><br />
<p>This is a \"combiner aggregator\", which knows how to do partial aggregations before transferring tuples over the network to maximize efficiency. Sum is also defined as a combiner aggregator, so the global sum done at the end of the topology will be very efficient.</p><p>Let's now look at Trident in more detail.</p><h2>Fields and tuples</h2><p>The Trident data model is the TridentTuple which is a named list of values. During a topology, tuples are incrementally built up through a sequence of operations. Operations generally take in a set of input fields and emit a set of \"function fields\". The input fields are used to select a subset of the tuple as input to the operation, while the \"function fields\" name the fields emitted by the operation.<br />
</p><p>Consider this example. Suppose you have a stream called \"stream\" that contains the fields \"x\", \"y\", and \"z\". To run a filter MyFilter that takes in \"y\" as input, you would say:<br />
</p><script src=\"https://gist.github.com/3234647.js?file=gistfile1.java\"></script><br />
<p>Suppose the implementation of MyFilter is this:<br />
</p><script src=\"https://gist.github.com/3234650.js?file=gistfile1.java\"></script><br />
<p>This will keep all tuples whose \"y\" field is less than 10. The TridentTuple given as input to MyFilter will only contain the \"y\" field. Note that Trident is able to project a subset of a tuple extremely efficiently when selecting the input fields: the projection is essentially free.<br />
</p><p>Let's now look at how \"function fields\" work. Suppose you had this function:<br />
</p><script src=\"https://gist.github.com/3234652.js?file=gistfile1.java\"></script><br />
<p>This function takes two numbers as input and emits two new values: the addition of the numbers and the multiplication of the numbers. Suppose you had a stream with the fields \"x\", \"y\", and \"z\". You would use this function like this:<br />
</p><script src=\"https://gist.github.com/3234653.js?file=gistfile1.java\"></script><br />
<p>The output of functions is additive: the fields are added to the input tuple. So the output of this each call would contain tuples with the five fields \"x\", \"y\", \"z\", \"added\", and \"multiplied\". \"added\" corresponds to the first value emitted by AddAndMultiply, while \"multiplied\" corresponds to the second value.<br />
</p><p>With aggregators, on the other hand, the function fields replace the input tuples. So if you had a stream containing the fields \"val1\" and \"val2\", and you did this:<br />
</p><script src=\"https://gist.github.com/3234656.js?file=gistfile1.java\"></script><br />
<p>The output stream would only contain a single tuple with a single field called \"sum\", representing the sum of all \"val2\" fields in that batch.<br />
</p><p>With grouped streams, the output will contain the grouping fields followed by the fields emitted by the aggregator. For example:<br />
</p><script src=\"https://gist.github.com/3234661.js?file=gistfile1.java\"></script><br />
<p>In this example, the output will contain the fields \"val1\" and \"sum\".<br />
</p><h2>State</h2><p>A key problem to solve with realtime computation is how to manage state so that updates are idempotent in the face of failures and retries. It's impossible to eliminate failures, so when a node dies or something else goes wrong, batches need to be retried. The question is - how do you do state updates (whether external databases or state internal to the topology) so that it's like each message was processed only once?<br />
</p><p>This is a tricky problem, and can be illustrated with the following example. Suppose that you're doing a count aggregation of your stream and want to store the running count in a database. If you store only the count in the database and it's time to apply a state update for a batch, there's no way to know if you applied that state update before. The batch could have been attempted before, succeeded in updating the database, and then failed at a later step. Or the batch could have been attempted before and failed to update the database. You just don't know.<br />
</p><p>Trident solves this problem by doing two things:<br />
</p><ol><li><p>Each batch is given a unique id called the \"transaction id\". If a batch is retried it will have the exact same transaction id.</p></li>
<li><p>State updates are ordered among batches. That is, the state updates for batch 3 won't be applied until the state updates for batch 2 have succeeded.</p></li>
</ol><p>With these two primitives, you can achieve exactly-once semantics with your state updates. Rather than store just the count in the database, what you can do instead is store the transaction id with the count in the database as an atomic value. Then, when updating the count, you can just compare the transaction id in the database with the transaction id for the current batch. If they're the same, you skip the update - because of the strong ordering, you know for sure that the value in the database incorporates the current batch. If they're different, you increment the count.<br />
</p><p>Of course, you don't have to do this logic manually in your topologies. This logic is wrapped by the State abstraction and done automatically. Nor is your State object required to implement the transaction id trick: if you don't want to pay the cost of storing the transaction id in the database, you don't have to. In that case the State will have at-least-once-processing semantics in the case of failures (which may be fine for your application). You can read more about how to implement a State and the various fault-tolerance tradeoffs possible <a href=\"https://github.com/nathanmarz/storm/wiki/Trident-state\">in this doc</a>.<br />
</p><p>A State is allowed to use whatever strategy it wants to store state. So it could store state in an external database or it could keep the state in-memory but backed by HDFS (like how HBase works). State's are not required to hold onto state forever. For example, you could have an in-memory State implementation that only keeps the last X hours of data available and drops anything older. Take a look at the implementation of the <a href=\"https://github.com/nathanmarz/trident-memcached\">Memcached integration</a> for an example State implementation.<br />
</p><h2>Execution of Trident topologies</h2><p>Trident topologies compile down into as efficient of a Storm topology as possible. Tuples are only sent over the network when a repartitioning of the data is required, such as if you do a groupBy or a shuffle. So if you had this Trident topology:<br />
</p><p><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-LZD5mUEkC2s/UBqwZbpKT9I/AAAAAAAAAKc/-2eKlRrAt_Y/s1600/trident-to-storm1.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"260\" width=\"400\" src=\"http://4.bp.blogspot.com/-LZD5mUEkC2s/UBqwZbpKT9I/AAAAAAAAAKc/-2eKlRrAt_Y/s400/trident-to-storm1.png\" /></a></div></p><p>It would compile into Storm spouts/bolts like this:<br />
</p><p><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://1.bp.blogspot.com/-WpJ9YiaCn7c/UBqwpnK6cpI/AAAAAAAAAKo/2tV2bXfgzEE/s1600/trident-to-storm2.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"259\" width=\"400\" src=\"http://1.bp.blogspot.com/-WpJ9YiaCn7c/UBqwpnK6cpI/AAAAAAAAAKo/2tV2bXfgzEE/s400/trident-to-storm2.png\" /></a></div></p><p>As you can see, Trident colocates operations within the same bolt as much as possible.<br />
</p><h2>Conclusion</h2><p>Trident makes realtime computation elegant. You've seen how high throughput stream processing, state manipulation, and low-latency querying can be seamlessly intermixed via Trident's API. Trident lets you express your realtime computations in a natural way while still getting maximal performance. To get started with Trident, take a look at these <a href=\"https://github.com/nathanmarz/storm-starter/tree/master/src/jvm/storm/starter/trident\">sample Trident topologies</a> and the <a href=\"https://github.com/nathanmarz/storm/wiki/Documentation\">Trident documentation</a>.<br />
</p><p>- Nathan Marz, Software Engineer (<a href=\"https://twitter.com/nathanmarz\">@nathanmarz</a>)<br />
</p>" "http://www.blogger.com/feeds/5340805191653517637/posts/default/1884593817993851033" (20506 46058) old 22 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-1884593817993851033") (published nil "2012-08-02T10:00:00.000-07:00") (updated nil "2012-08-02T10:07:54.477-07:00") (title ((type . "text")) "Trident: a high-level abstraction for realtime computation") (content ((type . "html")) "<p>Trident is a new high-level abstraction for doing realtime computing on top of <a href=\"http://storm-project.net/\">Twitter Storm</a>, available in <a href=\"http://storm-project.net/downloads.html\">Storm 0.8.0</a> (released today). It allows you to seamlessly mix high throughput (millions of messages per second), stateful stream processing with low latency distributed querying. If you're familiar with high level batch processing tools like <a href=\"http://pig.apache.org/\">Pig</a> or <a href=\"http://www.cascading.org/\">Cascading</a>, the concepts of Trident will be very familiar - Trident has joins, aggregations, grouping, functions, and filters. In addition to these, Trident adds primitives for doing stateful, incremental processing on top of any database or persistence store. Trident has consistent, exactly-once semantics, so it is easy to reason about Trident topologies.</p><p>We're really excited about Trident and believe it is a major step forward in Big Data processing. It builds upon Storm's foundation to make realtime computation as easy as batch computation.</p><h2>Example</h2><p>Let's look at an illustrative example of Trident. This example will do two things: </p><ol><li><p>Compute streaming word count from an input stream of sentences</p></li>
<li><p>Implement queries to get the sum of the counts for a list of words</p></li>
</ol><p>For the purposes of illustration, this example will read an infinite stream of sentences from the following source:</p><script src=\"https://gist.github.com/3234617.js?file=gistfile1.java\"></script><br />
<p>This spout cycles through that set of sentences over and over to produce the sentence stream. Here's the code to do the streaming word count part of the computation:</p><script src=\"https://gist.github.com/3234621.js?file=gistfile1.java\"></script><br />
<p>Let's go through the code line by line. First a TridentTopology object is created, which exposes the interface for constructing Trident computations. TridentTopology has a method called newStream that creates a new stream of data in the topology reading from an input source. In this case, the input source is just the FixedBatchSpout defined from before. Input sources can also be queue brokers like Kestrel or Kafka. Trident keeps track of a small amount of state for each input source (metadata about what it has consumed) in Zookeeper, and the \"spout1\" string here specifies the node in Zookeeper where Trident should keep that metadata.</p><p>Trident processes the stream as small batches of tuples. For example, the incoming stream of sentences might be divided into batches like so:</p><p><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-dvyMvMMVyQg/UBqwN1OQnoI/AAAAAAAAAKQ/uaYoI0UH9fU/s1600/batched-stream.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"240\" width=\"400\" src=\"http://4.bp.blogspot.com/-dvyMvMMVyQg/UBqwN1OQnoI/AAAAAAAAAKQ/uaYoI0UH9fU/s400/batched-stream.png\" /></a></div></p><p>Generally the size of those small batches will be on the order of thousands or millions of tuples, depending on your incoming throughput.</p><p>Trident provides a fully fledged batch processing API to process those small batches. The API is very similar to what you see in high level abstractions for Hadoop like Pig or Cascading: you can do group by's, joins, aggregations, run functions, run filters, and so on. Of course, processing each small batch in isolation isn't that interesting, so Trident provides functions for doing aggregations across batches and persistently storing those aggregations - whether in memory, in Memcached, in Cassandra, or some other store. Finally, Trident has first-class functions for querying sources of realtime state. That state could be updated by Trident (like in this example), or it could be an independent source of state.</p><p>Back to the example, the spout emits a stream containing one field called \"sentence\". The next line of the topology definition applies the Split function to each tuple in the stream, taking the \"sentence\" field and splitting it into words. Each sentence tuple creates potentially many word tuples - for instance, the sentence \"the cow jumped over the moon\" creates six \"word\" tuples. Here's the definition of Split:<br />
</p><script src=\"https://gist.github.com/3234623.js?file=gistfile1.java\"></script><br />
<p>As you can see, it's really simple. It simply grabs the sentence, splits it on whitespace, and emits a tuple for each word.</p><p>The rest of the topology computes word count and keeps the results persistently stored. First the stream is grouped by the \"word\" field. Then, each group is persistently aggregated using the Count aggregator. The persistentAggregate function knows how to store and update the results of the aggregation in a source of state. In this example, the word counts are kept in memory, but this can be trivially swapped to use Memcached, Cassandra, or any other persistent store. Swapping this topology to store counts in Memcached is as simple as replacing the persistentAggregate line with this (using <a href=\"https://github.com/nathanmarz/trident-memcached\">trident-memcached</a>), where the \"serverLocations\" variable is a list of host/ports for the Memcached cluster:</p><script src=\"https://gist.github.com/3234632.js?file=gistfile1.java\"></script><br />
<p>The values stored by persistentAggregate represents the aggregation of all batches ever emitted by the stream.</p><p>One of the cool things about Trident is that it has fully fault-tolerant, exactly-once processing semantics. This makes it easy to reason about your realtime processing. Trident persists state in a way so that if failures occur and retries are necessary, it won't perform multiple updates to the database for the same source data.</p><p>The persistentAggregate method transforms a Stream into a TridentState object. In this case the TridentState object represents all the word counts. We will use this TridentState object to implement the distributed query portion of the computation.</p><p>The next part of the topology implements a low latency distributed query on the word counts. The query takes as input a whitespace separated list of words and return the sum of the counts for those words. These queries are executed just like normal RPC calls, except they are parallelized in the background. Here's an example of how you might invoke one of these queries:</p><script src=\"https://gist.github.com/3234636.js?file=gistfile1.java\"></script><br />
<p>As you can see, it looks just like a regular remote procedure call (RPC), except it's executing in parallel across a Storm cluster. The latency for small queries like this are typically around 10ms. More intense DRPC queries can take longer of course, although the latency largely depends on how many resources you have allocated for the computation.</p><p>The implementation of the distributed query portion of the topology looks like this:<br />
</p><script src=\"https://gist.github.com/3234638.js?file=gistfile1.java\"></script><br />
<p>The same TridentTopology object is used to create the DRPC stream, and the function is named \"words\". The function name corresponds to the function name given in the first argument of execute when using a DRPCClient.</p><p>Each DRPC request is treated as its own little batch processing job that takes as input a single tuple representing the request. The tuple contains one field called \"args\" that contains the argument provided by the client. In this case, the argument is a whitespace separated list of words.</p><p>First, the Split function is used to split the arguments for the request into its constituent words. The stream is grouped by \"word\", and the stateQuery operator is used to query the TridentState object that the first part of the topology generated. stateQuery takes in a source of state - in this case, the word counts computed by the other portion of the topology - and a function for querying that state. In this case, the MapGet function is invoked, which gets the count for each word. Since the DRPC stream is grouped the exact same way as the TridentState was (by the \"word\" field), each word query is routed to the exact partition of the TridentState object that manages updates for that word.</p><p>Next, words that didn't have a count are filtered out via the FilterNull filter and the counts are summed using the Sum aggregator to get the result. Then, Trident automatically sends the result back to the waiting client.</p><p>Trident is intelligent about how it executes a topology to maximize performance. There's two interesting things happening automatically in this topology:</p><ol><li><p>Operations that read from or write to state (like persistentAggregate and stateQuery) automatically batch operations to that state. So if there's 20 updates that need to be made to the database for the current batch of processing, rather than do 20 read requests and 20 write requests to the database, Trident will automatically batch up the reads and writes, doing only 1 read request and 1 write request (and in many cases, you can use caching in your State implementation to eliminate the read request). So you get the best of both words of convenience - being able to express your computation in terms of what should be done with each tuple - and performance.</p></li>
<li><p>Trident aggregators are heavily optimized. Rather than transfer all tuples for a group to the same machine and then run the aggregator, Trident will do partial aggregations when possible before sending tuples over the network. For example, the Count aggregator computes the count on each partition, sends the partial count over the network, and then sums together all the partial counts to get the total count. This technique is similar to the use of combiners in MapReduce.</p></li>
</ol><p>Let's look at another example of Trident.</p><h2>Reach</h2><p>The next example is a pure DRPC topology that computes the reach of a URL on Twitter on demand. Reach is the number of unique people exposed to a URL on Twitter. To compute reach, you need to fetch all the people who ever tweeted a URL, fetch all the followers of all those people, unique that set of followers, and that count that uniqued set. Computing reach is too intense for a single machine - it can require thousands of database calls and tens of millions of tuples. With Storm and Trident, it's easy to parallelize the computation of each step across a cluster.</p><p>This topology will read from two sources of state. One database maps URLs to a list of people who tweeted that URL. The other database maps a person to a list of followers for that person. The topology definition looks like this:</p><script src=\"https://gist.github.com/3234642.js?file=gistfile1.java\"></script><br />
<p>The topology creates TridentState objects representing each external database using the newStaticState method. These can then be queried in the topology. Like all sources of state, queries to these databases will be automatically batched for maximum efficiency.</p><p>The topology definition is straightforward - it's just a simple batch processing job. First, the urlToTweeters database is queried to get the list of people who tweeted the URL for this request. That returns a list, so the ExpandList function is invoked to create a tuple for each tweeter.</p><p>Next, the followers for each tweeter must be fetched. It's important that this step be parallelized, so shuffle is invoked to evenly distribute the tweeters among all workers for the topology. Then, the followers database is queried to get the list of followers for each tweeter. You can see that this portion of the topology is given a large parallelism since this is the most intense portion of the computation.</p><p>Next, the set of followers is uniqued and counted. This is done in two steps. First a \"group by\" is done on the batch by \"follower\", running the \"One\" aggregator on each group. The \"One\" aggregator simply emits a single tuple containing the number one for each group. Then, the ones are summed together to get the unique count of the followers set. Here's the definition of the \"One\" aggregator:</p><script src=\"https://gist.github.com/3234645.js?file=gistfile1.java\"></script><br />
<p>This is a \"combiner aggregator\", which knows how to do partial aggregations before transferring tuples over the network to maximize efficiency. Sum is also defined as a combiner aggregator, so the global sum done at the end of the topology will be very efficient.</p><p>Let's now look at Trident in more detail.</p><h2>Fields and tuples</h2><p>The Trident data model is the TridentTuple which is a named list of values. During a topology, tuples are incrementally built up through a sequence of operations. Operations generally take in a set of input fields and emit a set of \"function fields\". The input fields are used to select a subset of the tuple as input to the operation, while the \"function fields\" name the fields emitted by the operation.<br />
</p><p>Consider this example. Suppose you have a stream called \"stream\" that contains the fields \"x\", \"y\", and \"z\". To run a filter MyFilter that takes in \"y\" as input, you would say:<br />
</p><script src=\"https://gist.github.com/3234647.js?file=gistfile1.java\"></script><br />
<p>Suppose the implementation of MyFilter is this:<br />
</p><script src=\"https://gist.github.com/3234650.js?file=gistfile1.java\"></script><br />
<p>This will keep all tuples whose \"y\" field is less than 10. The TridentTuple given as input to MyFilter will only contain the \"y\" field. Note that Trident is able to project a subset of a tuple extremely efficiently when selecting the input fields: the projection is essentially free.<br />
</p><p>Let's now look at how \"function fields\" work. Suppose you had this function:<br />
</p><script src=\"https://gist.github.com/3234652.js?file=gistfile1.java\"></script><br />
<p>This function takes two numbers as input and emits two new values: the addition of the numbers and the multiplication of the numbers. Suppose you had a stream with the fields \"x\", \"y\", and \"z\". You would use this function like this:<br />
</p><script src=\"https://gist.github.com/3234653.js?file=gistfile1.java\"></script><br />
<p>The output of functions is additive: the fields are added to the input tuple. So the output of this each call would contain tuples with the five fields \"x\", \"y\", \"z\", \"added\", and \"multiplied\". \"added\" corresponds to the first value emitted by AddAndMultiply, while \"multiplied\" corresponds to the second value.<br />
</p><p>With aggregators, on the other hand, the function fields replace the input tuples. So if you had a stream containing the fields \"val1\" and \"val2\", and you did this:<br />
</p><script src=\"https://gist.github.com/3234656.js?file=gistfile1.java\"></script><br />
<p>The output stream would only contain a single tuple with a single field called \"sum\", representing the sum of all \"val2\" fields in that batch.<br />
</p><p>With grouped streams, the output will contain the grouping fields followed by the fields emitted by the aggregator. For example:<br />
</p><script src=\"https://gist.github.com/3234661.js?file=gistfile1.java\"></script><br />
<p>In this example, the output will contain the fields \"val1\" and \"sum\".<br />
</p><h2>State</h2><p>A key problem to solve with realtime computation is how to manage state so that updates are idempotent in the face of failures and retries. It's impossible to eliminate failures, so when a node dies or something else goes wrong, batches need to be retried. The question is - how do you do state updates (whether external databases or state internal to the topology) so that it's like each message was processed only once?<br />
</p><p>This is a tricky problem, and can be illustrated with the following example. Suppose that you're doing a count aggregation of your stream and want to store the running count in a database. If you store only the count in the database and it's time to apply a state update for a batch, there's no way to know if you applied that state update before. The batch could have been attempted before, succeeded in updating the database, and then failed at a later step. Or the batch could have been attempted before and failed to update the database. You just don't know.<br />
</p><p>Trident solves this problem by doing two things:<br />
</p><ol><li><p>Each batch is given a unique id called the \"transaction id\". If a batch is retried it will have the exact same transaction id.</p></li>
<li><p>State updates are ordered among batches. That is, the state updates for batch 3 won't be applied until the state updates for batch 2 have succeeded.</p></li>
</ol><p>With these two primitives, you can achieve exactly-once semantics with your state updates. Rather than store just the count in the database, what you can do instead is store the transaction id with the count in the database as an atomic value. Then, when updating the count, you can just compare the transaction id in the database with the transaction id for the current batch. If they're the same, you skip the update - because of the strong ordering, you know for sure that the value in the database incorporates the current batch. If they're different, you increment the count.<br />
</p><p>Of course, you don't have to do this logic manually in your topologies. This logic is wrapped by the State abstraction and done automatically. Nor is your State object required to implement the transaction id trick: if you don't want to pay the cost of storing the transaction id in the database, you don't have to. In that case the State will have at-least-once-processing semantics in the case of failures (which may be fine for your application). You can read more about how to implement a State and the various fault-tolerance tradeoffs possible <a href=\"https://github.com/nathanmarz/storm/wiki/Trident-state\">in this doc</a>.<br />
</p><p>A State is allowed to use whatever strategy it wants to store state. So it could store state in an external database or it could keep the state in-memory but backed by HDFS (like how HBase works). State's are not required to hold onto state forever. For example, you could have an in-memory State implementation that only keeps the last X hours of data available and drops anything older. Take a look at the implementation of the <a href=\"https://github.com/nathanmarz/trident-memcached\">Memcached integration</a> for an example State implementation.<br />
</p><h2>Execution of Trident topologies</h2><p>Trident topologies compile down into as efficient of a Storm topology as possible. Tuples are only sent over the network when a repartitioning of the data is required, such as if you do a groupBy or a shuffle. So if you had this Trident topology:<br />
</p><p><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-LZD5mUEkC2s/UBqwZbpKT9I/AAAAAAAAAKc/-2eKlRrAt_Y/s1600/trident-to-storm1.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"260\" width=\"400\" src=\"http://4.bp.blogspot.com/-LZD5mUEkC2s/UBqwZbpKT9I/AAAAAAAAAKc/-2eKlRrAt_Y/s400/trident-to-storm1.png\" /></a></div></p><p>It would compile into Storm spouts/bolts like this:<br />
</p><p><div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://1.bp.blogspot.com/-WpJ9YiaCn7c/UBqwpnK6cpI/AAAAAAAAAKo/2tV2bXfgzEE/s1600/trident-to-storm2.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"259\" width=\"400\" src=\"http://1.bp.blogspot.com/-WpJ9YiaCn7c/UBqwpnK6cpI/AAAAAAAAAKo/2tV2bXfgzEE/s400/trident-to-storm2.png\" /></a></div></p><p>As you can see, Trident colocates operations within the same bolt as much as possible.<br />
</p><h2>Conclusion</h2><p>Trident makes realtime computation elegant. You've seen how high throughput stream processing, state manipulation, and low-latency querying can be seamlessly intermixed via Trident's API. Trident lets you express your realtime computations in a natural way while still getting maximal performance. To get started with Trident, take a look at these <a href=\"https://github.com/nathanmarz/storm-starter/tree/master/src/jvm/storm/starter/trident\">sample Trident topologies</a> and the <a href=\"https://github.com/nathanmarz/storm/wiki/Documentation\">Trident documentation</a>.<br />
</p><p>- Nathan Marz, Software Engineer (<a href=\"https://twitter.com/nathanmarz\">@nathanmarz</a>)<br />
</p>") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/1884593817993851033"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/1884593817993851033"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/08/trident-high-level-abstraction-for.html") (title . "Trident: a high-level abstraction for realtime computation"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://4.bp.blogspot.com/-dvyMvMMVyQg/UBqwN1OQnoI/AAAAAAAAAKQ/uaYoI0UH9fU/s72-c/batched-stream.png") (height . "72") (width . "72"))))) ("TwitterCLDR: Improving Internationalization Support in Ruby" "<p>We recently open sourced <a href =\"https://github.com/twitter/twitter-cldr-rb\">TwitterCLDR</a> under the Apache Public License 2.0. TwitterCLDR is an <a href=\"http://site.icu-project.org\">“ICU level”</a> internationalization library for Ruby that supports dates, times, numbers, currencies, world languages, sorting, text normalization, time spans, plurals, and unicode code point data. By sharing our code with the community we hope to collaborate together and improve internationalization support for websites all over the world. If your company is considering supporting multiple languages, then you can try TwitterCLDR to help your internationalization efforts.</p><h3>Motivation</h3><p>Here’s a test. Say this date out loud: <i>2/1/2012</i></p><p>If you said, “February first, 2012”, you’re probably an American. If you said, “January second, 2012”, you’re probably of European or possibly Asian descent. If you said, “January 12, 1902”, you’re probably a computer. The point is that as humans, we almost never think about formatting dates, plurals, lists, and the like. If you’re creating a platform available around the world, however, these kinds of minutiae make a big difference to users.</p><p>The <a href=\"http://www.unicode.org/consortium/consort.html\">Unicode Consortium</a> publishes and maintains a bunch of data regarding formatting dates, numbers, lists, and more, called the <a href=\"http://cldr.unicode.org\">Common Locale Data Repository (CLDR)</a>. IBM maintains International Components for Unicode (ICU), a library that uses the Unicode Consortium’s data to make it easier for programmers to use. However, this library is targeted at Java and C/C++ developers and not Ruby programmers, which is one of the programming languages used at Twitter. For example, Ruby and TwitterCLDR helps power our <a href=\"http://translate.twttr.com/welcome\">Translation Center</a>. TwitterCLDR provides a way to use the same CLDR data that Java uses, but in a Ruby environment. Hence, formatting dates, times, numbers, currencies and plurals should now be much easier for the typical Rubyist. Let’s go over some real world examples.</p><h2>Example Code</h2><p><b>Dates, Numbers, and Currencies</b></p><p>Let’s format a date in Spanish (es):<br />
<pre>$> DateTime.now.localize(:es).to_full_s
$> \"lunes, 12 de diciembre de 2011 21:44:57 UTC -0800\"</pre></p><p>Too long?  Make it shorter:<br />
<pre>$> DateTime.now.localize(:es).to_short_s
$> \"12/12/11 21:44\" </pre></p><p>Built in support for relative times lets you do this:<br />
<pre>$> (DateTime.now - 1).localize(:en).ago.to_s
$> \"1 day ago\"
$> (DateTime.now + 1).localize(:en).until.to_s
$> \"In 1 day\"</pre></p><p>Number formatting is easy:<br />
<pre>$> 1337.localize(:en).to_s
$> \"1,337\"
$> 1337.localize(:fr).to_s
$> \"1 337\"</pre></p><p>We’ve got you covered for currencies and decimals too:<br />
<pre>$> 1337.localize(:es).to_currency.to_s(:currency => \"EUR\")
$> \"1.337,00 €\"
$> 1337.localize(:es).to_decimal.to_s(:precision => 3)
$> \"1.337,000\"</pre></p><p>Currency data?  Absolutely:<br />
<pre>$> TwitterCldr::Shared::Currencies.for_country(\"Canada\")
$> { :currency => \"Dollar\", :symbol => \"$\", :code => \"CAD\" }</pre></p><p><b>Plurals</b></p><p>Get the plural rule for a number:<br />
<pre>$> TwitterCldr::Formatters::Plurals::Rules.rule_for(1, :ru)
$> :one
$> TwitterCldr::Formatters::Plurals::Rules.rule_for(3, :ru)
$> :few
$> TwitterCldr::Formatters::Plurals::Rules.rule_for(10, :ru)
$> :many</pre></p><p>Embed plurals right in your translatable phrases using JSON syntax:<br />
<pre>$> str = 'there %<{ \"horse_count\": { \"one\": \"is one horse\", \"other\": \"are %{horse_count} horses\" } }> in the barn'
$> str.localize % { :horse_count => 3 }
$> \"there are 3 horses in the barn\"</pre></p><p><b>Unicode Data</b></p><p>Get attributes for any Unicode code point:<br />
<pre>$> code_point = TwitterCldr::Shared::CodePoint.for_hex(\"1F3E9\")
$> code_point.name
$> \"LOVE HOTEL\"
$> code_point.category
$> \"So\"</pre></p><p>Normalize strings using Unicode’s standard algorithms (NFD, NFKD, NFC, or NFKC):<br />
<pre>$> \"español\".localize.code_points
$> [\"0065\", \"0073\", \"0070\", \"0061\", \"00F1\", \"006F\", \"006C\"]
$> \"español\".localize.normalize(:using => :NFKD).code_points
$> [\"0065\", \"0073\", \"0070\", \"0061\", \"006E\", \"0303\", \"006F\", \"006C\"]</pre></p><p><b>Sorting (Collation)</b></p><p>TwitterCLDR includes a pure Ruby, from-scratch implementation of the <a href=\"http://unicode.org/reports/tr10/\">Unicode Collation Algorithm</a> (with tailoring) that enables locale-aware sorting capabilities.</p><p>Alphabetize a list using regular Ruby sort:<br />
<pre>$> [\"Art\", \"Wasa\", \"Älg\", \"Ved\"].sort
$> [\"Art\", \"Ved\", \"Wasa\", \"Älg\"]</pre></p><p>Alphabetize a list using TwitterCLDR’s locale-aware sort:<br />
<pre>$> [\"Art\", \"Wasa\", \"Älg\", \"Ved\"].localize(:de).sort.to_a
$> [\"Älg\", \"Art\", \"Ved\", \"Wasa\"]</pre></p><p>NOTE: Most of these methods can be customized to your liking.</p><h3>JavaScript Support</h3><p>What good is all this internationalization support in Ruby if I can’t expect the same output on the client side too? To bridge the gap between the client and server sides, TwitterCLDR also contains a JavaScript implementation (known as twitter-cldr-js) whose compiled files are maintained in a <a href=\"https://github.com/twitter/twitter-cldr-js\">separate GitHub repo</a>.  At the moment, twitter-cldr-js supports dates, times, relative times, and plural rules.  We’re working on expanding its capabilities, so stay tuned.</p><h3>Future Work</h3><p>In the future, we hope to add even more internationalization capabilities to TwitterCLDR, including Rails integration, phone number and postal code validation, support for Unicode characters in Ruby 1.8 strings and regular expressions, and the ability to translate timezone names via the TZInfo gem and ActiveSupport. We would love to have the community use TwitterCLDR and help us improve the code to reach everyone in the world.</p><h3>Acknowledgements</h3><p>Twitter CLDR was primarily authored by Cameron Dutro (<a href=\"https://twitter.com/camertron\">@camertron</a>).  In addition, we’d like to acknowledge the following folks who contributed to the project either directly or indirectly: Kirill Lashuk (<a href=\"https://twitter.com/kl_7\">@kl_7</a>), Nico Sallembien (<a href=\"https://twitter.com/nsallembien\">@nsallembien</a>), Sumit Shah (<a href=\"https://twitter.com/omnidactyl\">@omnidactyl</a>), Katsuya Noguchi, Engineer (<a href=\"https://twitter.com/kn\">@kn</a>), Timothy Andrew (<a href=\"https://twitter.com/timothyandrew\">@timothyandrew</a>) and Kristian Freeman (<a href=\"https://twitter.com/imkmf\">@imkmf</a>).</p><br />
- Chris Aniszczyk, Manager of Open Source (<a href=\"https://twitter.com/cra\">@cra</a>)<br />" "http://www.blogger.com/feeds/5340805191653517637/posts/default/2058782037128621168" (20506 47671) old 23 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-2058782037128621168") (published nil "2012-08-01T11:43:00.001-07:00") (updated nil "2012-08-02T10:34:47.870-07:00") (title ((type . "text")) "TwitterCLDR: Improving Internationalization Support in Ruby") (content ((type . "html")) "<p>We recently open sourced <a href =\"https://github.com/twitter/twitter-cldr-rb\">TwitterCLDR</a> under the Apache Public License 2.0. TwitterCLDR is an <a href=\"http://site.icu-project.org\">“ICU level”</a> internationalization library for Ruby that supports dates, times, numbers, currencies, world languages, sorting, text normalization, time spans, plurals, and unicode code point data. By sharing our code with the community we hope to collaborate together and improve internationalization support for websites all over the world. If your company is considering supporting multiple languages, then you can try TwitterCLDR to help your internationalization efforts.</p><h3>Motivation</h3><p>Here’s a test. Say this date out loud: <i>2/1/2012</i></p><p>If you said, “February first, 2012”, you’re probably an American. If you said, “January second, 2012”, you’re probably of European or possibly Asian descent. If you said, “January 12, 1902”, you’re probably a computer. The point is that as humans, we almost never think about formatting dates, plurals, lists, and the like. If you’re creating a platform available around the world, however, these kinds of minutiae make a big difference to users.</p><p>The <a href=\"http://www.unicode.org/consortium/consort.html\">Unicode Consortium</a> publishes and maintains a bunch of data regarding formatting dates, numbers, lists, and more, called the <a href=\"http://cldr.unicode.org\">Common Locale Data Repository (CLDR)</a>. IBM maintains International Components for Unicode (ICU), a library that uses the Unicode Consortium’s data to make it easier for programmers to use. However, this library is targeted at Java and C/C++ developers and not Ruby programmers, which is one of the programming languages used at Twitter. For example, Ruby and TwitterCLDR helps power our <a href=\"http://translate.twttr.com/welcome\">Translation Center</a>. TwitterCLDR provides a way to use the same CLDR data that Java uses, but in a Ruby environment. Hence, formatting dates, times, numbers, currencies and plurals should now be much easier for the typical Rubyist. Let’s go over some real world examples.</p><h2>Example Code</h2><p><b>Dates, Numbers, and Currencies</b></p><p>Let’s format a date in Spanish (es):<br />
<pre>$> DateTime.now.localize(:es).to_full_s
$> \"lunes, 12 de diciembre de 2011 21:44:57 UTC -0800\"</pre></p><p>Too long?  Make it shorter:<br />
<pre>$> DateTime.now.localize(:es).to_short_s
$> \"12/12/11 21:44\" </pre></p><p>Built in support for relative times lets you do this:<br />
<pre>$> (DateTime.now - 1).localize(:en).ago.to_s
$> \"1 day ago\"
$> (DateTime.now + 1).localize(:en).until.to_s
$> \"In 1 day\"</pre></p><p>Number formatting is easy:<br />
<pre>$> 1337.localize(:en).to_s
$> \"1,337\"
$> 1337.localize(:fr).to_s
$> \"1 337\"</pre></p><p>We’ve got you covered for currencies and decimals too:<br />
<pre>$> 1337.localize(:es).to_currency.to_s(:currency => \"EUR\")
$> \"1.337,00 €\"
$> 1337.localize(:es).to_decimal.to_s(:precision => 3)
$> \"1.337,000\"</pre></p><p>Currency data?  Absolutely:<br />
<pre>$> TwitterCldr::Shared::Currencies.for_country(\"Canada\")
$> { :currency => \"Dollar\", :symbol => \"$\", :code => \"CAD\" }</pre></p><p><b>Plurals</b></p><p>Get the plural rule for a number:<br />
<pre>$> TwitterCldr::Formatters::Plurals::Rules.rule_for(1, :ru)
$> :one
$> TwitterCldr::Formatters::Plurals::Rules.rule_for(3, :ru)
$> :few
$> TwitterCldr::Formatters::Plurals::Rules.rule_for(10, :ru)
$> :many</pre></p><p>Embed plurals right in your translatable phrases using JSON syntax:<br />
<pre>$> str = 'there %<{ \"horse_count\": { \"one\": \"is one horse\", \"other\": \"are %{horse_count} horses\" } }> in the barn'
$> str.localize % { :horse_count => 3 }
$> \"there are 3 horses in the barn\"</pre></p><p><b>Unicode Data</b></p><p>Get attributes for any Unicode code point:<br />
<pre>$> code_point = TwitterCldr::Shared::CodePoint.for_hex(\"1F3E9\")
$> code_point.name
$> \"LOVE HOTEL\"
$> code_point.category
$> \"So\"</pre></p><p>Normalize strings using Unicode’s standard algorithms (NFD, NFKD, NFC, or NFKC):<br />
<pre>$> \"español\".localize.code_points
$> [\"0065\", \"0073\", \"0070\", \"0061\", \"00F1\", \"006F\", \"006C\"]
$> \"español\".localize.normalize(:using => :NFKD).code_points
$> [\"0065\", \"0073\", \"0070\", \"0061\", \"006E\", \"0303\", \"006F\", \"006C\"]</pre></p><p><b>Sorting (Collation)</b></p><p>TwitterCLDR includes a pure Ruby, from-scratch implementation of the <a href=\"http://unicode.org/reports/tr10/\">Unicode Collation Algorithm</a> (with tailoring) that enables locale-aware sorting capabilities.</p><p>Alphabetize a list using regular Ruby sort:<br />
<pre>$> [\"Art\", \"Wasa\", \"Älg\", \"Ved\"].sort
$> [\"Art\", \"Ved\", \"Wasa\", \"Älg\"]</pre></p><p>Alphabetize a list using TwitterCLDR’s locale-aware sort:<br />
<pre>$> [\"Art\", \"Wasa\", \"Älg\", \"Ved\"].localize(:de).sort.to_a
$> [\"Älg\", \"Art\", \"Ved\", \"Wasa\"]</pre></p><p>NOTE: Most of these methods can be customized to your liking.</p><h3>JavaScript Support</h3><p>What good is all this internationalization support in Ruby if I can’t expect the same output on the client side too? To bridge the gap between the client and server sides, TwitterCLDR also contains a JavaScript implementation (known as twitter-cldr-js) whose compiled files are maintained in a <a href=\"https://github.com/twitter/twitter-cldr-js\">separate GitHub repo</a>.  At the moment, twitter-cldr-js supports dates, times, relative times, and plural rules.  We’re working on expanding its capabilities, so stay tuned.</p><h3>Future Work</h3><p>In the future, we hope to add even more internationalization capabilities to TwitterCLDR, including Rails integration, phone number and postal code validation, support for Unicode characters in Ruby 1.8 strings and regular expressions, and the ability to translate timezone names via the TZInfo gem and ActiveSupport. We would love to have the community use TwitterCLDR and help us improve the code to reach everyone in the world.</p><h3>Acknowledgements</h3><p>Twitter CLDR was primarily authored by Cameron Dutro (<a href=\"https://twitter.com/camertron\">@camertron</a>).  In addition, we’d like to acknowledge the following folks who contributed to the project either directly or indirectly: Kirill Lashuk (<a href=\"https://twitter.com/kl_7\">@kl_7</a>), Nico Sallembien (<a href=\"https://twitter.com/nsallembien\">@nsallembien</a>), Sumit Shah (<a href=\"https://twitter.com/omnidactyl\">@omnidactyl</a>), Katsuya Noguchi, Engineer (<a href=\"https://twitter.com/kn\">@kn</a>), Timothy Andrew (<a href=\"https://twitter.com/timothyandrew\">@timothyandrew</a>) and Kristian Freeman (<a href=\"https://twitter.com/imkmf\">@imkmf</a>).</p><br />
- Chris Aniszczyk, Manager of Open Source (<a href=\"https://twitter.com/cra\">@cra</a>)<br />") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/2058782037128621168"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/2058782037128621168"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/08/twittercldr-improving.html") (title . "TwitterCLDR: Improving Internationalization Support in Ruby"))) (author nil (name nil "Twitter") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))))) ("Caching with Twemcache" "<b><i>Update - July 11, 2012, 9:45am<br />
</i></b><br />
<i>We want to correct an error regarding the slab calcification problem we mentioned in the original post. This problem only applied to our v1.4.4 fork of Memcached; this correction is reflected below. The recent Memcached version has addressed some of these problems. </i><br />
<br />
We built <a href=\"http://github.com/twitter/twemcache\">Twemcache</a> because we needed a more robust and manageable version of Memcached, suitable for our large-scale production environment. Today, we are open-sourcing Twemcache under the New BSD license. As one of the largest adopters of <a href=\"http://memcached.org/\">Memcached</a>, a popular open source caching system, we have used Memcached over the years to help us scale our ever-growing traffic. Today, we have hundreds of dedicated cache servers keeping over 20TB of data from over 30 services in-memory, including crucial data such as user information and Tweets. Collectively these servers handle almost 2 trillion queries on any given day (that’s more than 23 million queries per second). As we continued to grow, we needed a more robust and manageable version of Memcached suitable for our large scale production environment. <br />
<br />
We have been running Twemcache in production for more than a year and a half. Twemcache is based on a fork of Memcached v1.4.4 that is <b>heavily modified</b> to improve maintainability and help us monitor our cache servers better. We improved performance, removed code that we didn’t find necessary, refactored large source files and added observability related features. The following sections will provide more details on why we did this and what those new features are.<br />
<br />
<b><span style=\"font-size: large;\">Motivation</span></b><br />
<br />
Almost all of our cache use cases fall into two categories:<br />
<br />
<ul><li>as an <b>optimization for disk</b> where cache is used as the in-memory serving layer to shed load from databases.</li>
<li>as an <b>optimization for cpu</b> where cache is used as a buffer to store items that are expensive to recompute.</li>
</ul><br />
An example of these two optimizations is “caching of Tweets”. All Tweets are persisted to disk when they are created, but most Tweets requested by users need to be served out of memory for performance reasons. We use Twemcache to store recent and frequently accessed Tweets, as an optimization for disk. When a Tweet shows up in a particular client, it takes a particular presentation - rendered Tweet - which has other metadata like number of retweets, favorites etc. We also use Twemcache to store the recently rendered Tweets, as an optimization for cpu. <br />
<br />
To effectively address the use cases mentioned above, it's extremely important that caches are <b>always available</b> and have <b>predictable performance</b> with respect to item hit rate even when operating at full capacity. Caches should also be able to <b>adapt to changing item sizes on-the-fly</b> as application data size grows or shrinks over time. Finally, it is critical to have <b>observability into caches</b> to monitor the health and effectiveness of our cache clusters. It turns out that all these problems are interrelated because adapting to changing item sizes usually requires a cache reconfiguration — which impacts availability and predictability. Twemcache tries to address these needs with the help of the following features:<br />
<br />
<b>Random Eviction<br />
</b><br />
The v1.4.4 implementation of Memcached, which Twemcache is based on, suffers from a problem we call <i>slab calcification</i>. In Memcached, a slab can only store items of a given maximum size and once a slab has been allocated to a slab class, it cannot be reassigned to another slab class. In other words, slabs once allocated are locked to their respective slab classes. This is the crux of the slab calcification problem. When items grow or shrink in size, new slabs must be to allocated to store them. Over time, when caches reach full memory capacity, to store newer items we must rely on evicting existing items in the same slab class. If the newer items are of a size with no slabs allocated, write requests may fail completely. Meanwhile, slabs allocated to a different slab class may sit idle. Slab calcification leads to loss of capacity and efficiency. <br />
<br />
To solve this problem without resorting to periodically restarting the server instances, we introduced a new eviction strategy called <i>random eviction</i>. In this strategy, when a new item needs to be inserted and it cannot be accommodated by the space occupied by an expired item or the available free memory, we’ll simply pick a random slab from the list of all allocated slabs, evict all items within that slab, and reallocate it to the slab class that fits the new item. <br />
<br />
It turns out that this feature is quite powerful for two reasons:<br />
<br />
<ul><li>Cache servers can now gracefully move on-the-fly from one slab size to another for a given application. This enables our cache servers to adapt to changing item sizes and have a predictable long term hit rate by caching an application’s active working set of items.</li>
<li>Application developers don’t have to worry about reconfiguring their cache server when they add or delete fields from their cache item structures or if their item size grows over time.</li>
</ul><br />
By providing a stable hit rate, random eviction prevents performance degradation due to data pattern change and system instability associated with restarts. The <a href=\"http://www.youtube.com/watch?v=EtROv2or8SE&amp;feature=youtu.be&amp;hd=1\">video</a> below illustrates how over time Twemcache is able to adapt to a shifting size pattern and still remain effective.<br />
<br />
<iframe width=\"560\" height=\"315\" src=\"http://www.youtube.com/embed/EtROv2or8SE\" frameborder=\"0\" allowfullscreen></iframe><br />
<br />
<b>Lock-less Stats Collection</b><br />
<br />
Cache observability enables us to monitor the health of our cache clusters and ensure that applications are using them effectively. To address this need, we redesigned the Memcached stats module. Similar to the findings in Facebook’s <a href=\"https://www.facebook.com/note.php?note_id=39391378919\">attempt to scale Memcached</a>, we found that the global statistics lock was a main contention point.  <br />
<br />
This motivated us to use an updater-aggregator model of thread synchronization, in which worker threads always update thread-local metrics, and a background aggregator thread asynchronously collects metrics from all threads periodically holding only one thread-local lock at a time. Once aggregated, stats polling comes for free. Removing a global lock reduces the time Twemcache spends in a unresponsive state. There is a slight trade-off between how up-to-date stats are and how much burden stats collection puts on the system. However, the difference in total mutex wait time between aggregating once and 100 times per second is under 20%, and the impact on performance is totally predictable and thread-local. On top of making stats collection scalable, we also systematically reviewed the metrics, and came up with a more comprehensive list of metrics: Memcached provides 48 global metrics, 18 slab metrics and 10 item stats; Twemcache, on the other hand, provides 74 global metrics and 39 slab metrics. We merged item metrics into slab metrics to further simplify stats collection.<br />
<br />
<b>Asynchronous Command Logger<br />
</b><br />
When using Memcached, one of the hardest problems we faced was the hit-rate and memory-footprint trade-off - the sweet spot for achieving the desired performance gain with reasonable resources, as it is typically not possible to keep the entire data set in memory. To pinpoint the minimum memory requirement for a given hit rate, we needed a way to systematically analyze an application's data access pattern. To address this need, we implemented a new feature called command logger in Twemcache. When turned on, each worker thread will record a time stamped command header as well as return status, as shown below:<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-DiHbJIMfYik/T_yEi1a6wEI/AAAAAAAAAWs/fDWInSdbjLo/s1600/klogger_samples.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"56\" width=\"400\" src=\"http://4.bp.blogspot.com/-DiHbJIMfYik/T_yEi1a6wEI/AAAAAAAAAWs/fDWInSdbjLo/s400/klogger_samples.png\" /></a></div><br />
Each line of the command log gives precise information on the client, the time when a request was received, the command header including the command, key, flags and data length, a return code, and reply message length. In fact, the only thing missing is the item value itself, which turns out to be unimportant for our analysis.<br />
<br />
The command logger supports lockless read/write into ring buffers. Each worker thread logs into a thread-local buffer as they process incoming queries, and a background thread asynchronously dumps buffer contents to either a file or a socket. Thus the overhead on worker threads is minimal and so would not affect the service availability. The logger has been tested to log at about 100k requests-per-second. To control the speed of log generation, the command logger also supports sampling. Once we know what keys are accessed, the way they are accessed, and their return status, we can perform offline data analysis to estimate optimal working set size, item heat map, etc.<br />
<br />
<b><span style=\"font-size: large;\">Future work</span></b><br />
<br />
Twemcache is the result of our effort to turn Memcached into a reliable building block in Twitter’s data infrastructure. We kept the simplicity of the Memcached protocol intact, but made the service more dependable and more informative with Twemcache, without sacrificing performance. While we initially focused on the challenging goal of making Memcached work extremely well within the Twitter infrastructure, we look forward to sharing our code and ideas with the Memcached community in the long term. <br />
<br />
In the near future, we plan to evolve Twemcache in the open, address the hashtable lock contention issue that would further improve scalability, support more eviction strategies, support bootstrapping the cache from disk and provide a complete set of real-time data analysis tools. To view the source code and share feedback, please visit the <a href=\"https://github.com/twitter/twemcache\">Twemcache GitHub page</a>. You can also follow Twemcache's Twitter account (@<a href=\"https://twitter.com/twemcache\">Twemcache</a>) for updates. We would love to hear any ideas you have in improving Twemcache via pull requests or issues. Or better yet, why not consider joining the flock (@<a href=\"https://twitter.com/jointheflock\">jointheflock</a>) if you want to help build a world class caching system? <br />
<br />
<b><span style=\"font-size: large;\">Other work: Twemproxy</span></b><br />
<br />
Twemcache is one of the building blocks that comprise the caching system at Twitter. Another fundamental building block in our caching system is <a href=\"https://github.com/twitter/twemproxy\">Twemproxy</a>, a proxy for memcached protocol that we recently open sourced. Twemproxy minimizes the connections to our backend caching servers and enables us to scale horizontally. Furthermore, we are also actively developing the client side of our caching system on top of the Twitter <a href=\"https://github.com/twitter/finagle\">Finagle</a> stack.<br />
<br />
<b><span style=\"font-size: large;\">Acknowledgements</span></b><br />
<br />
Twemcache was primarily engineered by Manju Rajashekhar (@<a href=\"http://twitter.com/manju\">manju</a>) and Yao Yue (@<a href=\"http://twitter.com/thinkingfish\">thinkingfish</a>).  In addition, we’d like to acknowledge the following folks who contributed to the project either directly or indirectly and its deployment and maintenance in our datacenters: Anirudh Srinivas  (@<a href=\"http://twitter.com/asrin\">asrin</a>), David Lam (@<a href=\"http://twitter.com/kkdlam\">kkdlam</a>), Krishna Gade (@<a href=\"http://twitter.com/krishnagade\">krishnagade</a>), Joshua Coats (@<a href=\"http://twitter.com/shu\">shu</a>), Owen Vallis (@<a href=\"http://twitter.com/o_e_bert\">o_e_bert</a>), Rob Benson (@<a href=\"http://twitter.com/rgbenson\">rgbenson</a>), Brandon Mitchell (@<a href=\"http://twitter.com/bitbckt\">bitbckt</a>) and Xin Xiang (@<a href=\"http://twitter.com/xiangxin72\">xiangxin72</a>).<br />
<br />
- Chris Aniszczyk, Manager of Open Source (@<a href=\"http://twitter.com/cra\">cra</a>)" "http://www.blogger.com/feeds/5340805191653517637/posts/default/6094938499221070180" (20477 44652) old 24 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-6094938499221070180") (published nil "2012-07-10T13:15:00.000-07:00") (updated nil "2012-07-11T09:48:44.970-07:00") (title ((type . "text")) "Caching with Twemcache") (content ((type . "html")) "<b><i>Update - July 11, 2012, 9:45am<br />
</i></b><br />
<i>We want to correct an error regarding the slab calcification problem we mentioned in the original post. This problem only applied to our v1.4.4 fork of Memcached; this correction is reflected below. The recent Memcached version has addressed some of these problems. </i><br />
<br />
We built <a href=\"http://github.com/twitter/twemcache\">Twemcache</a> because we needed a more robust and manageable version of Memcached, suitable for our large-scale production environment. Today, we are open-sourcing Twemcache under the New BSD license. As one of the largest adopters of <a href=\"http://memcached.org/\">Memcached</a>, a popular open source caching system, we have used Memcached over the years to help us scale our ever-growing traffic. Today, we have hundreds of dedicated cache servers keeping over 20TB of data from over 30 services in-memory, including crucial data such as user information and Tweets. Collectively these servers handle almost 2 trillion queries on any given day (that’s more than 23 million queries per second). As we continued to grow, we needed a more robust and manageable version of Memcached suitable for our large scale production environment. <br />
<br />
We have been running Twemcache in production for more than a year and a half. Twemcache is based on a fork of Memcached v1.4.4 that is <b>heavily modified</b> to improve maintainability and help us monitor our cache servers better. We improved performance, removed code that we didn’t find necessary, refactored large source files and added observability related features. The following sections will provide more details on why we did this and what those new features are.<br />
<br />
<b><span style=\"font-size: large;\">Motivation</span></b><br />
<br />
Almost all of our cache use cases fall into two categories:<br />
<br />
<ul><li>as an <b>optimization for disk</b> where cache is used as the in-memory serving layer to shed load from databases.</li>
<li>as an <b>optimization for cpu</b> where cache is used as a buffer to store items that are expensive to recompute.</li>
</ul><br />
An example of these two optimizations is “caching of Tweets”. All Tweets are persisted to disk when they are created, but most Tweets requested by users need to be served out of memory for performance reasons. We use Twemcache to store recent and frequently accessed Tweets, as an optimization for disk. When a Tweet shows up in a particular client, it takes a particular presentation - rendered Tweet - which has other metadata like number of retweets, favorites etc. We also use Twemcache to store the recently rendered Tweets, as an optimization for cpu. <br />
<br />
To effectively address the use cases mentioned above, it's extremely important that caches are <b>always available</b> and have <b>predictable performance</b> with respect to item hit rate even when operating at full capacity. Caches should also be able to <b>adapt to changing item sizes on-the-fly</b> as application data size grows or shrinks over time. Finally, it is critical to have <b>observability into caches</b> to monitor the health and effectiveness of our cache clusters. It turns out that all these problems are interrelated because adapting to changing item sizes usually requires a cache reconfiguration — which impacts availability and predictability. Twemcache tries to address these needs with the help of the following features:<br />
<br />
<b>Random Eviction<br />
</b><br />
The v1.4.4 implementation of Memcached, which Twemcache is based on, suffers from a problem we call <i>slab calcification</i>. In Memcached, a slab can only store items of a given maximum size and once a slab has been allocated to a slab class, it cannot be reassigned to another slab class. In other words, slabs once allocated are locked to their respective slab classes. This is the crux of the slab calcification problem. When items grow or shrink in size, new slabs must be to allocated to store them. Over time, when caches reach full memory capacity, to store newer items we must rely on evicting existing items in the same slab class. If the newer items are of a size with no slabs allocated, write requests may fail completely. Meanwhile, slabs allocated to a different slab class may sit idle. Slab calcification leads to loss of capacity and efficiency. <br />
<br />
To solve this problem without resorting to periodically restarting the server instances, we introduced a new eviction strategy called <i>random eviction</i>. In this strategy, when a new item needs to be inserted and it cannot be accommodated by the space occupied by an expired item or the available free memory, we’ll simply pick a random slab from the list of all allocated slabs, evict all items within that slab, and reallocate it to the slab class that fits the new item. <br />
<br />
It turns out that this feature is quite powerful for two reasons:<br />
<br />
<ul><li>Cache servers can now gracefully move on-the-fly from one slab size to another for a given application. This enables our cache servers to adapt to changing item sizes and have a predictable long term hit rate by caching an application’s active working set of items.</li>
<li>Application developers don’t have to worry about reconfiguring their cache server when they add or delete fields from their cache item structures or if their item size grows over time.</li>
</ul><br />
By providing a stable hit rate, random eviction prevents performance degradation due to data pattern change and system instability associated with restarts. The <a href=\"http://www.youtube.com/watch?v=EtROv2or8SE&amp;feature=youtu.be&amp;hd=1\">video</a> below illustrates how over time Twemcache is able to adapt to a shifting size pattern and still remain effective.<br />
<br />
<iframe width=\"560\" height=\"315\" src=\"http://www.youtube.com/embed/EtROv2or8SE\" frameborder=\"0\" allowfullscreen></iframe><br />
<br />
<b>Lock-less Stats Collection</b><br />
<br />
Cache observability enables us to monitor the health of our cache clusters and ensure that applications are using them effectively. To address this need, we redesigned the Memcached stats module. Similar to the findings in Facebook’s <a href=\"https://www.facebook.com/note.php?note_id=39391378919\">attempt to scale Memcached</a>, we found that the global statistics lock was a main contention point.  <br />
<br />
This motivated us to use an updater-aggregator model of thread synchronization, in which worker threads always update thread-local metrics, and a background aggregator thread asynchronously collects metrics from all threads periodically holding only one thread-local lock at a time. Once aggregated, stats polling comes for free. Removing a global lock reduces the time Twemcache spends in a unresponsive state. There is a slight trade-off between how up-to-date stats are and how much burden stats collection puts on the system. However, the difference in total mutex wait time between aggregating once and 100 times per second is under 20%, and the impact on performance is totally predictable and thread-local. On top of making stats collection scalable, we also systematically reviewed the metrics, and came up with a more comprehensive list of metrics: Memcached provides 48 global metrics, 18 slab metrics and 10 item stats; Twemcache, on the other hand, provides 74 global metrics and 39 slab metrics. We merged item metrics into slab metrics to further simplify stats collection.<br />
<br />
<b>Asynchronous Command Logger<br />
</b><br />
When using Memcached, one of the hardest problems we faced was the hit-rate and memory-footprint trade-off - the sweet spot for achieving the desired performance gain with reasonable resources, as it is typically not possible to keep the entire data set in memory. To pinpoint the minimum memory requirement for a given hit rate, we needed a way to systematically analyze an application's data access pattern. To address this need, we implemented a new feature called command logger in Twemcache. When turned on, each worker thread will record a time stamped command header as well as return status, as shown below:<br />
<br />
<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"http://4.bp.blogspot.com/-DiHbJIMfYik/T_yEi1a6wEI/AAAAAAAAAWs/fDWInSdbjLo/s1600/klogger_samples.png\" imageanchor=\"1\" style=\"margin-left:1em; margin-right:1em\"><img border=\"0\" height=\"56\" width=\"400\" src=\"http://4.bp.blogspot.com/-DiHbJIMfYik/T_yEi1a6wEI/AAAAAAAAAWs/fDWInSdbjLo/s400/klogger_samples.png\" /></a></div><br />
Each line of the command log gives precise information on the client, the time when a request was received, the command header including the command, key, flags and data length, a return code, and reply message length. In fact, the only thing missing is the item value itself, which turns out to be unimportant for our analysis.<br />
<br />
The command logger supports lockless read/write into ring buffers. Each worker thread logs into a thread-local buffer as they process incoming queries, and a background thread asynchronously dumps buffer contents to either a file or a socket. Thus the overhead on worker threads is minimal and so would not affect the service availability. The logger has been tested to log at about 100k requests-per-second. To control the speed of log generation, the command logger also supports sampling. Once we know what keys are accessed, the way they are accessed, and their return status, we can perform offline data analysis to estimate optimal working set size, item heat map, etc.<br />
<br />
<b><span style=\"font-size: large;\">Future work</span></b><br />
<br />
Twemcache is the result of our effort to turn Memcached into a reliable building block in Twitter’s data infrastructure. We kept the simplicity of the Memcached protocol intact, but made the service more dependable and more informative with Twemcache, without sacrificing performance. While we initially focused on the challenging goal of making Memcached work extremely well within the Twitter infrastructure, we look forward to sharing our code and ideas with the Memcached community in the long term. <br />
<br />
In the near future, we plan to evolve Twemcache in the open, address the hashtable lock contention issue that would further improve scalability, support more eviction strategies, support bootstrapping the cache from disk and provide a complete set of real-time data analysis tools. To view the source code and share feedback, please visit the <a href=\"https://github.com/twitter/twemcache\">Twemcache GitHub page</a>. You can also follow Twemcache's Twitter account (@<a href=\"https://twitter.com/twemcache\">Twemcache</a>) for updates. We would love to hear any ideas you have in improving Twemcache via pull requests or issues. Or better yet, why not consider joining the flock (@<a href=\"https://twitter.com/jointheflock\">jointheflock</a>) if you want to help build a world class caching system? <br />
<br />
<b><span style=\"font-size: large;\">Other work: Twemproxy</span></b><br />
<br />
Twemcache is one of the building blocks that comprise the caching system at Twitter. Another fundamental building block in our caching system is <a href=\"https://github.com/twitter/twemproxy\">Twemproxy</a>, a proxy for memcached protocol that we recently open sourced. Twemproxy minimizes the connections to our backend caching servers and enables us to scale horizontally. Furthermore, we are also actively developing the client side of our caching system on top of the Twitter <a href=\"https://github.com/twitter/finagle\">Finagle</a> stack.<br />
<br />
<b><span style=\"font-size: large;\">Acknowledgements</span></b><br />
<br />
Twemcache was primarily engineered by Manju Rajashekhar (@<a href=\"http://twitter.com/manju\">manju</a>) and Yao Yue (@<a href=\"http://twitter.com/thinkingfish\">thinkingfish</a>).  In addition, we’d like to acknowledge the following folks who contributed to the project either directly or indirectly and its deployment and maintenance in our datacenters: Anirudh Srinivas  (@<a href=\"http://twitter.com/asrin\">asrin</a>), David Lam (@<a href=\"http://twitter.com/kkdlam\">kkdlam</a>), Krishna Gade (@<a href=\"http://twitter.com/krishnagade\">krishnagade</a>), Joshua Coats (@<a href=\"http://twitter.com/shu\">shu</a>), Owen Vallis (@<a href=\"http://twitter.com/o_e_bert\">o_e_bert</a>), Rob Benson (@<a href=\"http://twitter.com/rgbenson\">rgbenson</a>), Brandon Mitchell (@<a href=\"http://twitter.com/bitbckt\">bitbckt</a>) and Xin Xiang (@<a href=\"http://twitter.com/xiangxin72\">xiangxin72</a>).<br />
<br />
- Chris Aniszczyk, Manager of Open Source (@<a href=\"http://twitter.com/cra\">cra</a>)") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6094938499221070180"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6094938499221070180"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/07/caching-with-twemcache.html") (title . "Caching with Twemcache"))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))) (media:thumbnail ((xmlns:media . "http://search.yahoo.com/mrss/") (url . "http://img.youtube.com/vi/EtROv2or8SE/default.jpg") (height . "72") (width . "72"))))) ("Building and profiling high performance systems with Iago" "<a href=\"http://twitter.github.com/iago\">Iago</a> is a load generator that we created to help us test services before they encounter production traffic. While there are many load generators available in the open source and commercial software worlds, Iago provides us with capabilities that are uniquely suited for Twitter’s environment and the precise degree to which we need to test our services. <br />
<br />
There are three main properties that make Iago a good fit for Twitter:<br />
<br />
<ul><li><b>High performance:</b> In order to reach the highest levels of performance, your load generator must be equally performant. It must generate traffic in a very precise and predictable way to minimize variance between test runs and allow comparisons to be made between development iterations. Additionally, testing systems to failure is an important part of capacity planning, and it requires you to generate load significantly in excess of expected production traffic.</li>
<li><b>Multi-protocol:</b> Modelling a system as complex as Twitter can be difficult, but it’s made easier by decomposing it into component services. Once decomposed, each piece can be tested in isolation; this requires your load generator to speak each service’s protocol. Twitter has in excess of 100 such services, and Iago can and has tested most of them due to its built-in support for the protocols we use, including HTTP, Thrift and several others.</li>
<li><b>Extensible:</b> Iago is designed first and foremost for engineers. It assumes that the person building the system will also be interested in validating its performance and will know best how to do so. As such, it’s designed from the ground up to be extensible – making it easy to generate new traffic types, over new protocols and with individualized traffic sources. It is also provides sensible defaults for common use cases, while allowing for extensive configuration without writing code if that’s your preference.</li>
</ul><br />
<br />
Iago is the load generator we always wished we had. Now that we’ve built it, we want to share it with others who might need it to solve similar problems. Iago is now open sourced at <a href=\"https://github.com/twitter/iago\">GitHub</a> under the Apache Public License 2.0 and we are happy to accept any feedback (or pull requests) the open source community might have.<br />
<br />
<b>How does Iago work?</b><br />
<br />
Iago’s <a href=\"https://github.com/twitter/iago\">documentation</a> goes into more detail, but it is written in Scala and is designed to be extended by anyone writing code for the JVM platform. Non-blocking requests are generated at a specified rate, using an underlying, configurable statistical distribution (the default is to model a <a href=\"http://en.wikipedia.org/wiki/Poisson_Process\">Poisson Process</a>). The request rate can be varied as appropriate – for instance to warm up caches before handling full production load. In general the focus is on the arrival rate aspect of <a href=\"http://en.wikipedia.org/wiki/Little%27s_Law\">Little’s Law</a>, instead of concurrent users, which is allowed to float as appropriate given service latency. This greatly enhances the ability to compare multiple test runs and protects against service regressions inducing load generator slow down.<br />
<br />
In short, Iago strives to model a system where requests arrive independently of your service’s ability to handle them. This is as opposed to load generators which model closed systems where users will patiently handle whatever latency you give them. This distinction allows us to closely mimic failure modes that we would encounter in production.<br />
<br />
Part of achieving high performance is the ability to scale horizontally. Unsurprisingly, Iago is no different from the systems we test with it. A single instance of Iago is composed of cooperating processes that can generate ~10K RPS provided a number of requirements are met including factors such as size of payload, the response time of the system under test, the number of ephemeral sockets available, and the rate you can actually generate messages your protocol requires. Despite this complexity, with horizontal scaling Iago is used to routinely test systems at Twitter with well over 200K RPS. We do this internally using our <a href=\"http://incubator.apache.org/mesos/\">Apache Mesos grid</a> computing infrastructure, but Iago can adapt to any system that supports creating multiple JVM processes that can discover each other using <a href=\"http://zookeeper.apache.org/\">Apache Zookeeper</a>.<br />
<br />
<b>Iago at Twitter<br />
</b><br />
Iago has been used at Twitter throughout our stack, from our core database interfaces, storage sub-systems and domain logic, up to the systems accepting front end web requests. We routinely evaluate new hardware with it, have extended it to support correctness testing at scale and use it to test highly specific endpoints such as the new <a href=\"http://blog.twitter.com/2012/06/tailored-trends-bring-you-closer.html\">tailored trends</a>, personalized search, and Discovery releases. We’ve used it to model anticipated load for large events as well as the overall growth of our system over time. It’s also good for providing background traffic while other tests are running, simply to provide the correct mix of usage that we will encounter in production.<br />
<br />
<b>Acknowledgements &amp; Future Work<br />
</b><br />
Iago was primarily authored by James Waldrop (<a href=\"https://twitter.com/hivetheory\">@hivetheory</a>), but as with any such engineering effort a large number of people have contributed. A special thanks go out to the Finagle team, Marius Eriksen (<a href=\"https://twitter.com/marius\">@marius</a>), Arya Asemanfar (<a href=\"https://twitter.com/a_a\">@a_a</a>), Evan Meagher (<a href=\"https://twitter.com/evanm\">@evanm</a>), Trisha Quan (<a href=\"https://twitter.com/trisha\">@trisha</a>) and Stephan Zuercher (<a href=\"https://twitter.com/zuercher\">@zuercher</a>) for being tireless consumers as well as contributors to the project. Furthermore, we’d like to thank Raffi Krikorian (<a href=\"https://twitter.com/raffi\">@raffi</a>) and Dave Loftesness (<a href=\"https://twitter.com/dloft\">@dloft</a>) for originally envisioning and spearheading the effort to create Iago.<br />
<br />
To view the Iago source code and participate in the creation and development of our roadmap, please visit <a href=\"https://github.com/twitter/iago\">Iago</a> on GitHub. If you have any further questions, we suggest joining the <a href=\"https://groups.google.com/forum/?fromgroups#!forum/iago-users\">mailing list</a> and following <a href=\"https://twitter.com/iagoloadgen\">@iagoloadgen</a>. If you’re at the Velocity Conference this week in San Francisco, please swing by our <a href=\"http://velocityconf.com/velocity2012/public/schedule/detail/26222\">office hours</a> to learn more about Iago. <br />
<br />
- Chris Aniszczyk, Manager of Open Source (<a href=\"https://twitter.com/cra\">@cra</a>)" "http://www.blogger.com/feeds/5340805191653517637/posts/default/6638353306900912486" (20456 44838) old 25 nil nil ((id nil "tag:blogger.com,1999:blog-5340805191653517637.post-6638353306900912486") (published nil "2012-06-25T11:17:00.000-07:00") (updated nil "2012-06-25T11:34:14.376-07:00") (title ((type . "text")) "Building and profiling high performance systems with Iago") (content ((type . "html")) "<a href=\"http://twitter.github.com/iago\">Iago</a> is a load generator that we created to help us test services before they encounter production traffic. While there are many load generators available in the open source and commercial software worlds, Iago provides us with capabilities that are uniquely suited for Twitter’s environment and the precise degree to which we need to test our services. <br />
<br />
There are three main properties that make Iago a good fit for Twitter:<br />
<br />
<ul><li><b>High performance:</b> In order to reach the highest levels of performance, your load generator must be equally performant. It must generate traffic in a very precise and predictable way to minimize variance between test runs and allow comparisons to be made between development iterations. Additionally, testing systems to failure is an important part of capacity planning, and it requires you to generate load significantly in excess of expected production traffic.</li>
<li><b>Multi-protocol:</b> Modelling a system as complex as Twitter can be difficult, but it’s made easier by decomposing it into component services. Once decomposed, each piece can be tested in isolation; this requires your load generator to speak each service’s protocol. Twitter has in excess of 100 such services, and Iago can and has tested most of them due to its built-in support for the protocols we use, including HTTP, Thrift and several others.</li>
<li><b>Extensible:</b> Iago is designed first and foremost for engineers. It assumes that the person building the system will also be interested in validating its performance and will know best how to do so. As such, it’s designed from the ground up to be extensible – making it easy to generate new traffic types, over new protocols and with individualized traffic sources. It is also provides sensible defaults for common use cases, while allowing for extensive configuration without writing code if that’s your preference.</li>
</ul><br />
<br />
Iago is the load generator we always wished we had. Now that we’ve built it, we want to share it with others who might need it to solve similar problems. Iago is now open sourced at <a href=\"https://github.com/twitter/iago\">GitHub</a> under the Apache Public License 2.0 and we are happy to accept any feedback (or pull requests) the open source community might have.<br />
<br />
<b>How does Iago work?</b><br />
<br />
Iago’s <a href=\"https://github.com/twitter/iago\">documentation</a> goes into more detail, but it is written in Scala and is designed to be extended by anyone writing code for the JVM platform. Non-blocking requests are generated at a specified rate, using an underlying, configurable statistical distribution (the default is to model a <a href=\"http://en.wikipedia.org/wiki/Poisson_Process\">Poisson Process</a>). The request rate can be varied as appropriate – for instance to warm up caches before handling full production load. In general the focus is on the arrival rate aspect of <a href=\"http://en.wikipedia.org/wiki/Little%27s_Law\">Little’s Law</a>, instead of concurrent users, which is allowed to float as appropriate given service latency. This greatly enhances the ability to compare multiple test runs and protects against service regressions inducing load generator slow down.<br />
<br />
In short, Iago strives to model a system where requests arrive independently of your service’s ability to handle them. This is as opposed to load generators which model closed systems where users will patiently handle whatever latency you give them. This distinction allows us to closely mimic failure modes that we would encounter in production.<br />
<br />
Part of achieving high performance is the ability to scale horizontally. Unsurprisingly, Iago is no different from the systems we test with it. A single instance of Iago is composed of cooperating processes that can generate ~10K RPS provided a number of requirements are met including factors such as size of payload, the response time of the system under test, the number of ephemeral sockets available, and the rate you can actually generate messages your protocol requires. Despite this complexity, with horizontal scaling Iago is used to routinely test systems at Twitter with well over 200K RPS. We do this internally using our <a href=\"http://incubator.apache.org/mesos/\">Apache Mesos grid</a> computing infrastructure, but Iago can adapt to any system that supports creating multiple JVM processes that can discover each other using <a href=\"http://zookeeper.apache.org/\">Apache Zookeeper</a>.<br />
<br />
<b>Iago at Twitter<br />
</b><br />
Iago has been used at Twitter throughout our stack, from our core database interfaces, storage sub-systems and domain logic, up to the systems accepting front end web requests. We routinely evaluate new hardware with it, have extended it to support correctness testing at scale and use it to test highly specific endpoints such as the new <a href=\"http://blog.twitter.com/2012/06/tailored-trends-bring-you-closer.html\">tailored trends</a>, personalized search, and Discovery releases. We’ve used it to model anticipated load for large events as well as the overall growth of our system over time. It’s also good for providing background traffic while other tests are running, simply to provide the correct mix of usage that we will encounter in production.<br />
<br />
<b>Acknowledgements &amp; Future Work<br />
</b><br />
Iago was primarily authored by James Waldrop (<a href=\"https://twitter.com/hivetheory\">@hivetheory</a>), but as with any such engineering effort a large number of people have contributed. A special thanks go out to the Finagle team, Marius Eriksen (<a href=\"https://twitter.com/marius\">@marius</a>), Arya Asemanfar (<a href=\"https://twitter.com/a_a\">@a_a</a>), Evan Meagher (<a href=\"https://twitter.com/evanm\">@evanm</a>), Trisha Quan (<a href=\"https://twitter.com/trisha\">@trisha</a>) and Stephan Zuercher (<a href=\"https://twitter.com/zuercher\">@zuercher</a>) for being tireless consumers as well as contributors to the project. Furthermore, we’d like to thank Raffi Krikorian (<a href=\"https://twitter.com/raffi\">@raffi</a>) and Dave Loftesness (<a href=\"https://twitter.com/dloft\">@dloft</a>) for originally envisioning and spearheading the effort to create Iago.<br />
<br />
To view the Iago source code and participate in the creation and development of our roadmap, please visit <a href=\"https://github.com/twitter/iago\">Iago</a> on GitHub. If you have any further questions, we suggest joining the <a href=\"https://groups.google.com/forum/?fromgroups#!forum/iago-users\">mailing list</a> and following <a href=\"https://twitter.com/iagoloadgen\">@iagoloadgen</a>. If you’re at the Velocity Conference this week in San Francisco, please swing by our <a href=\"http://velocityconf.com/velocity2012/public/schedule/detail/26222\">office hours</a> to learn more about Iago. <br />
<br />
- Chris Aniszczyk, Manager of Open Source (<a href=\"https://twitter.com/cra\">@cra</a>)") (link ((rel . "edit") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6638353306900912486"))) (link ((rel . "self") (type . "application/atom+xml") (href . "http://www.blogger.com/feeds/5340805191653517637/posts/default/6638353306900912486"))) (link ((rel . "alternate") (type . "text/html") (href . "http://engineering.twitter.com/2012/06/building-and-profiling-high-performance.html") (title . "Building and profiling high performance systems with Iago"))) (author nil (name nil "twitter") (uri nil "http://www.blogger.com/profile/06995209890972686945") (email nil "noreply@blogger.com") (gd:image ((rel . "http://schemas.google.com/g/2005#thumbnail") (width . "16") (height . "16") (src . "http://img2.blogblog.com/img/b16-rounded.gif")))))))